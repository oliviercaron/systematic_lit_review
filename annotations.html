<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Olivier Caron">
<meta name="author" content="Christophe Benavent">
<meta name="dcterms.date" content="2023-10-05">

<title>Systematic literature review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="annotations_files/libs/clipboard/clipboard.min.js"></script>
<script src="annotations_files/libs/quarto-html/quarto.js"></script>
<script src="annotations_files/libs/quarto-html/popper.min.js"></script>
<script src="annotations_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="annotations_files/libs/quarto-html/anchor.min.js"></script>
<link href="annotations_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="annotations_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="annotations_files/libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="annotations_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="annotations_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="annotations_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="annotations_files/libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">

<script src="annotations_files/libs/core-js-2.5.3/shim.min.js"></script>
<script src="annotations_files/libs/react-17.0.0/react.min.js"></script>
<script src="annotations_files/libs/react-17.0.0/react-dom.min.js"></script>
<script src="annotations_files/libs/reactwidget-1.0.0/react-tools.js"></script>
<script src="annotations_files/libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<link href="annotations_files/libs/reactable-0.4.4/reactable.css" rel="stylesheet">
<script src="annotations_files/libs/reactable-binding-0.4.4/reactable.js"></script>
<script src="annotations_files/libs/plotly-binding-4.10.2/plotly.js"></script>
<script src="annotations_files/libs/typedarray-0.1/typedarray.min.js"></script>
<script src="annotations_files/libs/jquery-3.5.1/jquery.min.js"></script>
<link href="annotations_files/libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="annotations_files/libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="annotations_files/libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="annotations_files/libs/plotly-main-2.11.1/plotly-latest.min.js"></script>


<link rel="stylesheet" href="styles.css">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Systematic literature review</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
            <p class="subtitle lead">Annotations</p>
                      </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author">Olivier Caron </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              Paris Dauphine - PSL
            </p>
        </div>
        <div class="quarto-title-meta-contents">
      <p class="author">Christophe Benavent </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              Paris Dauphine - PSL
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 5, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#libraries-and-loading-data" id="toc-libraries-and-loading-data" class="nav-link active" data-scroll-target="#libraries-and-loading-data"><span class="header-section-number">1</span> Libraries and loading data</a></li>
  <li><a href="#loading-data" id="toc-loading-data" class="nav-link" data-scroll-target="#loading-data"><span class="header-section-number">2</span> Loading data</a></li>
  <li><a href="#a-glimpse-of-data" id="toc-a-glimpse-of-data" class="nav-link" data-scroll-target="#a-glimpse-of-data"><span class="header-section-number">3</span> A glimpse of data</a></li>
  <li><a href="#a-first-word2vec-embeddings-analysis-skip-gram" id="toc-a-first-word2vec-embeddings-analysis-skip-gram" class="nav-link" data-scroll-target="#a-first-word2vec-embeddings-analysis-skip-gram"><span class="header-section-number">4</span> A first Word2Vec embeddings analysis (skip-gram)</a>
  <ul class="collapse">
  <li><a href="#lets-try-to-find-softwares-related-to-text-analysis-using-additions-of-word-embeddings" id="toc-lets-try-to-find-softwares-related-to-text-analysis-using-additions-of-word-embeddings" class="nav-link" data-scroll-target="#lets-try-to-find-softwares-related-to-text-analysis-using-additions-of-word-embeddings"><span class="header-section-number">4.1</span> Let’s try to find softwares related to text analysis using additions of word embeddings</a></li>
  </ul></li>
  <li><a href="#a-word2vec-embeddings-analysis-cbow" id="toc-a-word2vec-embeddings-analysis-cbow" class="nav-link" data-scroll-target="#a-word2vec-embeddings-analysis-cbow"><span class="header-section-number">5</span> A Word2Vec embeddings analysis (cbow)</a></li>
  <li><a href="#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing" id="toc-part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing" class="nav-link" data-scroll-target="#part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing"><span class="header-section-number">6</span> Part of speech tagging with UDPipe (<span class="citation" data-cites="straka-strakova-2017-tokenizing">Straka and Straková (2017)</span>)</a></li>
  <li><a href="#top-20-nouns-with-udpipe" id="toc-top-20-nouns-with-udpipe" class="nav-link" data-scroll-target="#top-20-nouns-with-udpipe"><span class="header-section-number">7</span> Top 20 nouns with UDPipe</a></li>
  <li><a href="#part-of-speech-tagging-with-trankit-nguyen2021trankit" id="toc-part-of-speech-tagging-with-trankit-nguyen2021trankit" class="nav-link" data-scroll-target="#part-of-speech-tagging-with-trankit-nguyen2021trankit"><span class="header-section-number">8</span> Part of speech tagging with Trankit (<span class="citation" data-cites="nguyen2021trankit">Nguyen et al. (2021)</span>)</a></li>
  <li><a href="#top-20-nouns-with-trankit" id="toc-top-20-nouns-with-trankit" class="nav-link" data-scroll-target="#top-20-nouns-with-trankit"><span class="header-section-number">9</span> Top 20 nouns with Trankit</a></li>
  <li><a href="#part-of-speech-tagging-with-stanza-qi2020stanza" id="toc-part-of-speech-tagging-with-stanza-qi2020stanza" class="nav-link" data-scroll-target="#part-of-speech-tagging-with-stanza-qi2020stanza"><span class="header-section-number">10</span> Part of speech tagging with Stanza (<span class="citation" data-cites="qi2020stanza">Qi et al. (2020)</span>)</a></li>
  <li><a href="#top-20-nouns-with-stanza" id="toc-top-20-nouns-with-stanza" class="nav-link" data-scroll-target="#top-20-nouns-with-stanza"><span class="header-section-number">11</span> Top 20 nouns with Stanza</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="libraries-and-loading-data" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="libraries-and-loading-data"><span class="header-section-number">1</span> Libraries and loading data</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(word2vec)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(text)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(udpipe)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(text2vec)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reactable)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>num_cores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>(<span class="at">logical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>num_cores</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">'Number of logical cores to use when training Word2vec model: '</span>, num_cores, <span class="st">'</span><span class="sc">\n</span><span class="st">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Number of logical cores to use when training Word2vec model:  12 </code></pre>
</div>
</div>
</section>
<section id="loading-data" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="loading-data"><span class="header-section-number">2</span> Loading data</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="annotated-cell-3"><pre class="sourceCode r code-annotation-code code-with-copy"><code class="sourceCode r"><span id="annotated-cell-3-1"><a href="#annotated-cell-3-1" aria-hidden="true" tabindex="-1"></a>list_articles <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">"nlp_full_data_final_18-08-2023.csv"</span>, <span class="at">encoding =</span> <span class="st">"UTF-8"</span>) <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-2"><a href="#annotated-cell-3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">"entry_number"</span> <span class="ot">=</span> <span class="dv">1</span>)</span>
<span id="annotated-cell-3-3"><a href="#annotated-cell-3-3" aria-hidden="true" tabindex="-1"></a>list_references <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">"nlp_references_final_18-08-2023.csv"</span>, <span class="at">encoding =</span> <span class="st">"UTF-8"</span>) <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-4"><a href="#annotated-cell-3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">"citing_art"</span> <span class="ot">=</span> <span class="dv">1</span>)</span>
<span id="annotated-cell-3-5"><a href="#annotated-cell-3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_articles) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"</span><span class="sc">\\</span><span class="st">.+"</span>, <span class="st">"_"</span>, <span class="fu">colnames</span>(list_articles))</span>
<span id="annotated-cell-3-6"><a href="#annotated-cell-3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_articles) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"^[[:punct:]]+|[[:punct:]]+$"</span>, <span class="st">""</span>, <span class="fu">colnames</span>(list_articles))</span>
<span id="annotated-cell-3-7"><a href="#annotated-cell-3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_references) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"</span><span class="sc">\\</span><span class="st">.+"</span>, <span class="st">"_"</span>, <span class="fu">colnames</span>(list_references))</span>
<span id="annotated-cell-3-8"><a href="#annotated-cell-3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_references) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"^[[:punct:]]+|[[:punct:]]+$"</span>, <span class="st">""</span>, <span class="fu">colnames</span>(list_references))</span>
<span id="annotated-cell-3-9"><a href="#annotated-cell-3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-3-10"><a href="#annotated-cell-3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-3-11"><a href="#annotated-cell-3-11" aria-hidden="true" tabindex="-1"></a>data_embeddings <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-12"><a href="#annotated-cell-3-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(entry_number, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-13"><a href="#annotated-cell-3-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(marketing <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-14"><a href="#annotated-cell-3-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">"year"</span> <span class="ot">=</span> <span class="fu">substr</span>(prism_coverDate, <span class="dv">7</span>, <span class="dv">10</span>)) <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-15"><a href="#annotated-cell-3-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">keywords =</span> <span class="fu">str_replace_all</span>(authkeywords, <span class="st">"</span><span class="sc">\\</span><span class="st">|"</span>, <span class="st">""</span>)) <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-16"><a href="#annotated-cell-3-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">keywords =</span> <span class="fu">str_squish</span>(keywords)) <span class="sc">%&gt;%</span></span>
<span id="annotated-cell-3-17"><a href="#annotated-cell-3-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">"combined_text"</span> <span class="ot">=</span> <span class="fu">paste0</span>(dc_title,<span class="st">". "</span>, dc_description, <span class="st">". "</span>, keywords))</span>
<span id="annotated-cell-3-18"><a href="#annotated-cell-3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-3-19"><a href="#annotated-cell-3-19" aria-hidden="true" tabindex="-1"></a><span class="co">#write.csv(data_embeddings,"data_for_embeddings.csv")</span></span>
<span id="annotated-cell-3-20"><a href="#annotated-cell-3-20" aria-hidden="true" tabindex="-1"></a><span class="co">#data_embeddings &lt;- read.csv("data_for_embeddings.csv")</span></span>
<span id="annotated-cell-3-21"><a href="#annotated-cell-3-21" aria-hidden="true" tabindex="-1"></a><span class="co">#embeddings &lt;- read.csv("embeddings_bge.csv")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="a-glimpse-of-data" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="a-glimpse-of-data"><span class="header-section-number">3</span> A glimpse of data</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>data_embeddings <span class="sc">%&gt;%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(entry_number, dc_creator, combined_text, year)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  entry_number            dc_creator
1            1             Loupos P.
2            2    Krefeld-Schwalb A.
3            3            Kronrod A.
4            4            Chang H.H.
5            5 Dobrucalı Yelkenci B.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            combined_text
1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                What reviews foretell about opening weekend box office revenue: the harbinger of failure effect in the movie industry. We empirically investigate the harbinger of failure phenomenon in the motion picture industry by analyzing the pre-release reviews written on movies by film critics. We find that harbingers of failure do exist. Their positive (negative) pre-release movie reviews provide a strong predictive signal that the movie will turn out to be a flop (success). This signal persists even for the top critic category, which usually consists of professional critics, indicating that having expertise in a professional domain does not necessarily lead to correct predictions. Our findings challenge the current belief that positive reviews always help enhance box office revenue and shed new light on the influencer-predictor hypothesis. We further analyze the writing style of harbingers and provide new insights into their personality traits and cognitive biases.. Harbingers of failure Movies Preference heterogeneity Reviews Text analytics
2              Tighter nets for smaller fishes? Mapping the development of statistical practices in consumer research between 2008 and 2020. During the last decade, confidence in many social sciences, including consumer research, has been undermined by doubts about the replicability of empirical research findings. These doubts have led to increased calls to improve research practices and adopt new measures to increase the replicability of published work from various stakeholders such as funding agencies, journals, and scholars themselves. Despite these demands, it is unclear to which the research published in the leading consumer research journals has adhered to these calls for change. This article provides the first systematic empirical analysis of this question by surveying three crucial statistics of published consumer research over time: sample sizes, effect sizes, and the distribution of published p values. The authors compile a hand-coded sample of N = 258 articles published between 2008 and 2020 in the Journal of Consumer Psychology, the Journal of Consumer Research, and the Journal of Marketing Research. An automated text analysis across all publications in these three journals corroborates the representativeness of the hand-coded sample. Results reveal a substantial increase in sample sizes above and beyond the use of online samples along with a decrease in reported effect sizes. Effect and samples sizes are highly correlated which at least partially explains the reduction in reported effect sizes.. Experimental research methods False-positive results Review
3 Been There, Done That: How Episodic and Semantic Memory Affects the Language of Authentic and Fictitious Reviews. This article suggests a theory-driven approach to address the managerial problem of distinguishing between real and fake reviews. Building on memory research and linguistics, we predict that when recollecting an authentic experience in a product review, people rely to a greater extent on episodic memory. By contrast, when writing a fictitious review, people do not have episodic memory available to them. Therefore, they must rely to a greater extent on semantic memory. We suggest that reliance on these different memory types is reflected in the language used in authentic and fictitious reviews. We develop predictions about five linguistic features characterizing authentic versus fictitious reviews. We test our predictions via a multi-method approach, combining computational linguistics, experimental design, and machine learning. We employ a large-scale experiment to derive a dataset of reviews, as well as two datasets containing reviews from online platforms. We also test whether an algorithm relying on our theory-driven linguistic features is context independent, relative to other benchmark algorithms, and shows better cross-domain performance when tested across datasets. By developing a theory that extends memory and psycholinguistics research to the realm of word of mouth, this work contributes to our understanding of how authentic and fictitious reviews are created.. fake reviews lie detection linguistic features machine learning memory text analysis
4                                                                                                                                                                                                                                                                           More Voices Persuade: The Attentional Benefits of Voice Numerosity. The authors posit that in an initial exposure to a broadcast video, hearing different voices narrate (in succession) a persuasive message encourages consumers’ attention and processing of the message, thereby facilitating persuasion; this is referred to as the voice numerosity effect. Across four studies (plus validation and replication studies)—including two large-scale, real-world data sets (with more than 11,000 crowdfunding videos and over 3.6 million customer transactions, and more than 1,600 video ads) and two controlled experiments (with over 1,800 participants)—the results provide support for the hypothesized effect. The effect (1) has consequential, economic implications in a real-world marketplace, (2) is more pronounced when the message is easier to comprehend, (3) is more pronounced when consumers have the capacity to process the ad message, and (4) is mediated by the favorability of consumers’ cognitive responses. The authors demonstrate the use of machine learning, text mining, and natural language processing to process and analyze unstructured (multimedia) data. Theoretical and marketing implications are discussed.. advertising crowdfunding marketing communications persuasion sensory marketing videos voice voice numerosity
5                                                                                                                                                                                                                                                                                                                                                                                                      Online complaint handling: a&nbsp;text&nbsp;analytics-based classification framework. Purpose: This study aims to both identify content-based and interaction-based online consumer complaint types and predict complaint types according to the complaint magnitude rooted in complainants' personality traits, emotion, Twitter usage activity, as well as complaint's sentiment polarity, and interaction rate. Design/methodology/approach: In total, 297,000 complaint tweets were collected from Twitter, featuring over 220,000 consumer profiles and over 24 million user tweets. The obtained data were analyzed via two-step machine learning approach. Findings: This study proposes a set of content and profile features that can be employed for determining complaint types and reveals the relationship between content features, profile features and online complaint type. Originality/value: This study proposes a novel model for identifying types of online complaints, offering a set of content and profile features that can be used for predicting complaint type, and therefore introduces a flexible approach for enhancing online complaint management.. Complaint handling Machine learning Social CRM Text analytics Twitter
  year
1 2023
2 2023
3 2023
4 2023
5 2023</code></pre>
</div>
</div>
</section>
<section id="a-first-word2vec-embeddings-analysis-skip-gram" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="a-first-word2vec-embeddings-analysis-skip-gram"><span class="header-section-number">4</span> A first Word2Vec embeddings analysis (skip-gram)</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">word2vec</span>(<span class="at">x =</span> <span class="fu">tolower</span>(data_embeddings<span class="sc">$</span>combined_text),</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">type =</span> <span class="st">"skip-gram"</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">dim =</span> <span class="dv">500</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">iter =</span> <span class="dv">250</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">min_count =</span> <span class="dv">3</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">hs =</span> <span class="dv">1</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">verbose=</span><span class="dv">10</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">stopwords =</span> <span class="fu">stopwords</span>(<span class="st">"english"</span>),</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>                  <span class="at">window =</span> <span class="st">"7"</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>                  <span class="at">threads =</span> num_cores)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>embedding <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="lets-try-to-find-softwares-related-to-text-analysis-using-additions-of-word-embeddings" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="lets-try-to-find-softwares-related-to-text-analysis-using-additions-of-word-embeddings"><span class="header-section-number">4.1</span> Let’s try to find softwares related to text analysis using additions of word embeddings</h3>
<div class="panel-center panel-grid">
<div class="g-col-24 g-col-lg-20 g-start-lg-2">
<div class="cell panel-center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#addition of the wordd embeddings "text", "analysis" and "software"</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>embedding_text <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="fu">c</span>(<span class="st">"text"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>embedding_analysis <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="fu">c</span>(<span class="st">"analysis"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>embedding_software <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="fu">c</span>(<span class="st">"software"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>embedding_text_software <span class="ot">&lt;-</span> embedding_text <span class="sc">+</span> embedding_analysis <span class="sc">+</span> embedding_software</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>lookslike <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, embedding_text_software, <span class="at">type =</span> <span class="st">"nearest"</span>, <span class="at">top_n =</span> <span class="dv">200</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">text.similarity =</span> <span class="fu">round</span>(text.similarity, <span class="dv">2</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(text.term, text.similarity)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(lookslike, <span class="at">searchable =</span> <span class="cn">TRUE</span>, <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">maxWidth =</span> <span class="dv">200</span>,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">sortable =</span> <span class="cn">TRUE</span>,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">resizable =</span> <span class="cn">TRUE</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div class="reactable html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-a7074dc0abf5b49b7dea" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a7074dc0abf5b49b7dea">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"text.term":["mining","interview","using","liwc","automated","auto","incident","based","adopts","leximancer","creates","sentiment","analyzed","scopus","analytics","package","vosviewer","program","content","maps","employing","soft","approach","papers","visualizing","diction","political","inherent","thematic","pls","citation","heterogeneous","variables","deriving","viewer","pennebaker","relational","dimensions","correlation","version","word","themes","youtube","user","ten","intelligence","theme","equation","top","processed","disruptive","dirichlet","magazine","visualization","print","lens","literature","per","performed","anova","articles","processing","data","30","explicit","lda","similarities","www","200","marketing","analysed","collected","abstracts","modelling","image","latent","35","level","course’","600","nvivo","investigation","staying","blog","python","hidden","structural","namely","assessing","natural","employee","uses","mapping","demonstrated","availability","reliably","characterize","etc","identify","n","report","multiple","travel","shared","perform","artificial","database","village","total","hashtag","bibliometric","beauty","21","secondary","simple","“cognitive–affective–conative”","learning","usability","quantified","former","cmo’s","successfully","tm","science","step","cluster","ended","netnography","analyse","enabled","novel","author","massive","tools","allocation","conduct","deal","boundary","tier","ctrip","towards","150","undertaken","component","platform","phone","conducting","utility","care","programming","diaspora","segmentation","estate","reasoning","41","analyze","shares","major","lingual","instagram","determine","pipeline","evolution","technique","private","engineered","account","possibility","linking","moving","identification","employed","interviews","authors’","computer","two","hypotheses","audience’s","critical","combined","comprised","emergence","bodies","frequent","track","nlp","tourist","hubris","language","computerised","schools","links","capable","2019","weight","tool","least","third","catalogue","analyses"],"text.similarity":[0.83,0.66,0.65,0.65,0.64,0.64,0.61,0.61,0.61,0.6,0.6,0.59,0.59,0.59,0.59,0.59,0.59,0.58,0.58,0.57,0.57,0.57,0.56,0.56,0.55,0.54,0.54,0.54,0.54,0.54,0.53,0.53,0.53,0.53,0.53,0.53,0.52,0.52,0.52,0.52,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.48,0.48,0.48,0.48,0.47,0.47,0.47,0.47,0.47,0.47,0.47,0.47,0.47,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.46,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.45,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.44,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.43,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42,0.42]},"columns":[{"id":"text.term","name":"text.term","type":"character","sortable":true,"resizable":true,"maxWidth":200},{"id":"text.similarity","name":"text.similarity","type":"numeric","sortable":true,"resizable":true,"maxWidth":200}],"searchable":true,"dataKey":"ab9b7ee6d40cb705710b62256990488e"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> lookslike <span class="sc">%&gt;%</span> <span class="fu">top_n</span>(<span class="dv">20</span>, text.similarity) <span class="sc">%&gt;%</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> text.similarity, <span class="at">y =</span> <span class="fu">reorder</span>(text.term, text.similarity))) <span class="sc">+</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"similarity score"</span>,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 similarity scores with 'text'+'analysis'+'software' embeddings"</span> ) <span class="sc">+</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-8957457734a4860dc9b6" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-8957457734a4860dc9b6">{"x":{"data":[{"x":[0.82999999999999996,0.66000000000000003,0.65000000000000002,0.65000000000000002,0.64000000000000001,0.64000000000000001,0.60999999999999999,0.60999999999999999,0.60999999999999999,0.59999999999999998,0.59999999999999998,0.58999999999999997,0.58999999999999997,0.58999999999999997,0.58999999999999997,0.58999999999999997,0.58999999999999997,0.57999999999999996,0.57999999999999996,0.56999999999999995,0.56999999999999995,0.56999999999999995],"y":[22,21,20,19,18,17,16,15,14,13,12,10,7,9,6,8,11,5,4,2,1,3],"text":["text.similarity: 0.83<br />reorder(text.term, text.similarity): mining","text.similarity: 0.66<br />reorder(text.term, text.similarity): interview","text.similarity: 0.65<br />reorder(text.term, text.similarity): using","text.similarity: 0.65<br />reorder(text.term, text.similarity): liwc","text.similarity: 0.64<br />reorder(text.term, text.similarity): automated","text.similarity: 0.64<br />reorder(text.term, text.similarity): auto","text.similarity: 0.61<br />reorder(text.term, text.similarity): incident","text.similarity: 0.61<br />reorder(text.term, text.similarity): based","text.similarity: 0.61<br />reorder(text.term, text.similarity): adopts","text.similarity: 0.60<br />reorder(text.term, text.similarity): leximancer","text.similarity: 0.60<br />reorder(text.term, text.similarity): creates","text.similarity: 0.59<br />reorder(text.term, text.similarity): sentiment","text.similarity: 0.59<br />reorder(text.term, text.similarity): analyzed","text.similarity: 0.59<br />reorder(text.term, text.similarity): scopus","text.similarity: 0.59<br />reorder(text.term, text.similarity): analytics","text.similarity: 0.59<br />reorder(text.term, text.similarity): package","text.similarity: 0.59<br />reorder(text.term, text.similarity): vosviewer","text.similarity: 0.58<br />reorder(text.term, text.similarity): program","text.similarity: 0.58<br />reorder(text.term, text.similarity): content","text.similarity: 0.57<br />reorder(text.term, text.similarity): maps","text.similarity: 0.57<br />reorder(text.term, text.similarity): employing","text.similarity: 0.57<br />reorder(text.term, text.similarity): soft"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(65,105,225,1)","opacity":1,"size":5.6692913385826778,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(65,105,225,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":43.762557077625573,"r":7.3059360730593621,"b":40.182648401826491,"l":69.406392694063939},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"title":{"text":"Top 20 similarity scores with 'text'+'analysis'+'software' embeddings","font":{"color":"rgba(0,0,0,1)","family":"","size":17.534246575342465},"x":0.5,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.55699999999999994,0.84299999999999997],"tickmode":"array","ticktext":["0.60","0.65","0.70","0.75","0.80"],"tickvals":[0.60000000000000009,0.65000000000000002,0.70000000000000007,0.75,0.80000000000000004],"categoryorder":"array","categoryarray":["0.60","0.65","0.70","0.75","0.80"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"similarity score","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.40000000000000002,22.600000000000001],"tickmode":"array","ticktext":["employing","maps","soft","content","program","analytics","analyzed","package","scopus","sentiment","vosviewer","creates","leximancer","adopts","based","incident","auto","automated","liwc","using","interview","mining"],"tickvals":[1,2,3,4,5,6.0000000000000009,7,8,9,10,11,12,12.999999999999998,14.000000000000002,15.000000000000002,16,17,18,19,20,21,22],"categoryorder":"array","categoryarray":["employing","maps","soft","content","program","analytics","analyzed","package","scopus","sentiment","vosviewer","creates","leximancer","adopts","based","incident","auto","automated","liwc","using","interview","mining"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"34b46d6827d2":{"x":{},"y":{},"type":"scatter"}},"cur_data":"34b46d6827d2","visdat":{"34b46d6827d2":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="a-word2vec-embeddings-analysis-cbow" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="a-word2vec-embeddings-analysis-cbow"><span class="header-section-number">5</span> A Word2Vec embeddings analysis (cbow)</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>modelcbow <span class="ot">&lt;-</span> <span class="fu">word2vec</span>(<span class="at">x =</span> <span class="fu">tolower</span>(data_embeddings<span class="sc">$</span>combined_text),</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">type =</span> <span class="st">"cbow"</span>,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">dim =</span> <span class="dv">500</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">iter =</span> <span class="dv">250</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>                  <span class="at">min_count =</span> <span class="dv">3</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>                  <span class="at">hs =</span> <span class="dv">1</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>                  <span class="at">verbose=</span><span class="dv">10</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>                  <span class="at">stopwords =</span> <span class="fu">stopwords</span>(<span class="st">"english"</span>),</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>                  <span class="at">window =</span> <span class="st">"7"</span>,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>                  <span class="at">threads =</span> num_cores)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>embedding1 <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(modelcbow)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co">#embedding &lt;- predict(modelcbow, c("mining"), type = "embedding")</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co">#embedding</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="panel-center panel-grid">
<div class="g-col-24 g-col-lg-20 g-start-lg-2">
<div class="cell panel-center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#addition of the wordd embeddings "text", "analysis" and "software"</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>embedding_text <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, <span class="fu">c</span>(<span class="st">"text"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>embedding_analysis <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, <span class="fu">c</span>(<span class="st">"analysis"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>embedding_software <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, <span class="fu">c</span>(<span class="st">"software"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>embedding_text_software <span class="ot">&lt;-</span> embedding_text <span class="sc">+</span> embedding_analysis <span class="sc">+</span> embedding_software</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>lookslike <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, embedding_text_software, <span class="at">type =</span> <span class="st">"nearest"</span>, <span class="at">top_n =</span> <span class="dv">200</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">text.similarity =</span> <span class="fu">round</span>(text.similarity, <span class="dv">2</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(text.term, text.similarity)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(lookslike, <span class="at">searchable =</span> <span class="cn">TRUE</span>, <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">maxWidth =</span> <span class="dv">200</span>,</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">sortable =</span> <span class="cn">TRUE</span>,</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">resizable =</span> <span class="cn">TRUE</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div class="reactable html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-f0d53de33d146fdfd58b" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-f0d53de33d146fdfd58b">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"text.term":["analysis","defects","continue","quantified","likes","allowing","describe","inherent","sets","young","grammatical","categories","judgments","night","explored","assistant","dictionaries","apply","directions","mediated","thanks","samples","mainland","minority","informational","moving","assessments","problematic","huge","nation","room","behavioural","effect","base","auto","lab","preference","clustering","scholarly","sponsoring","queries","net","ones","dimensional","user","exciting","paralanguage","performed","actionable","lingual","accurately","obtain","cars","recommend","entrepreneurship","involved","creativity","hubris","lstm","introduction","obtaining","13","users’","capacity","magazines","convolutional","selfie","macau","idea","concerning","pre","accessible","targeting","positivity","field","respective","showed","digitalization","plain","rated","position","agenda","assisted","thinking","facilitates","path","largest","discounting","called","news","artificial","massive","shares","advancement","versus","iii","found","scenario","second","mindful","evaluates","understanding","improvement","scoring","transaction","traveller","reflecting","water","model’s","scraped","term","languages","dynamics","false","landscape","generalizability","facing","done","content","shari‘ah","choices","tourist","extensive","world","generative","program","fill","lexicon","becoming","manageable","deploying","combines","connection","vulnerable","singapore","lobbying","india","reputation","available","said","first","database","150","throughout","ewom","nevertheless","tone","id","advocacy","dis","paper","leisure","still","approximately","summarize","income","depends","employed","networks","volume","informative","phrases","collectors","distributed","aided","focuses","contingent","explains","overcome","correspondence","ux","heavily","dirichlet","method","va","knowing","service","discovery","evaluate","logistic","critical","multidimensional","budget","course","quitting","high","netnography","editorial","incentivized","chapter","bids","focusing","customer","unintended","literatures","bri","facebook","gabek®","consume","capture"],"text.similarity":[0.99,0.71,0.7,0.7,0.7,0.69,0.68,0.67,0.67,0.66,0.65,0.64,0.64,0.63,0.63,0.63,0.63,0.63,0.63,0.63,0.62,0.61,0.61,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.6,0.59,0.59,0.59,0.59,0.59,0.58,0.58,0.58,0.58,0.58,0.58,0.58,0.58,0.57,0.57,0.57,0.57,0.57,0.57,0.57,0.57,0.57,0.57,0.57,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.56,0.55,0.55,0.55,0.55,0.55,0.55,0.55,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.54,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.53,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.52,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.51,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.49,0.48,0.48,0.48,0.48,0.48,0.48,0.48,0.48,0.48]},"columns":[{"id":"text.term","name":"text.term","type":"character","sortable":true,"resizable":true,"maxWidth":200},{"id":"text.similarity","name":"text.similarity","type":"numeric","sortable":true,"resizable":true,"maxWidth":200}],"searchable":true,"dataKey":"3c649ae4a69269403e5572635b7b4923"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> lookslike <span class="sc">%&gt;%</span> <span class="fu">top_n</span>(<span class="dv">20</span>, text.similarity) <span class="sc">%&gt;%</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> text.similarity, <span class="at">y =</span> <span class="fu">reorder</span>(text.term, text.similarity))) <span class="sc">+</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"similarity score"</span>,</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 similarity scores with 'text'+'analysis'+'software' embeddings"</span> ) <span class="sc">+</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-6244ef2db77f7f5ea353" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-6244ef2db77f7f5ea353">{"x":{"data":[{"x":[0.98999999999999999,0.70999999999999996,0.69999999999999996,0.69999999999999996,0.69999999999999996,0.68999999999999995,0.68000000000000005,0.67000000000000004,0.67000000000000004,0.66000000000000003,0.65000000000000002,0.64000000000000001,0.64000000000000001,0.63,0.63,0.63,0.63,0.63,0.63,0.63],"y":[20,19,16,18,17,15,14,12,13,11,10,8,9,7,5,2,3,1,4,6],"text":["text.similarity: 0.99<br />reorder(text.term, text.similarity): analysis","text.similarity: 0.71<br />reorder(text.term, text.similarity): defects","text.similarity: 0.70<br />reorder(text.term, text.similarity): continue","text.similarity: 0.70<br />reorder(text.term, text.similarity): quantified","text.similarity: 0.70<br />reorder(text.term, text.similarity): likes","text.similarity: 0.69<br />reorder(text.term, text.similarity): allowing","text.similarity: 0.68<br />reorder(text.term, text.similarity): describe","text.similarity: 0.67<br />reorder(text.term, text.similarity): inherent","text.similarity: 0.67<br />reorder(text.term, text.similarity): sets","text.similarity: 0.66<br />reorder(text.term, text.similarity): young","text.similarity: 0.65<br />reorder(text.term, text.similarity): grammatical","text.similarity: 0.64<br />reorder(text.term, text.similarity): categories","text.similarity: 0.64<br />reorder(text.term, text.similarity): judgments","text.similarity: 0.63<br />reorder(text.term, text.similarity): night","text.similarity: 0.63<br />reorder(text.term, text.similarity): explored","text.similarity: 0.63<br />reorder(text.term, text.similarity): assistant","text.similarity: 0.63<br />reorder(text.term, text.similarity): dictionaries","text.similarity: 0.63<br />reorder(text.term, text.similarity): apply","text.similarity: 0.63<br />reorder(text.term, text.similarity): directions","text.similarity: 0.63<br />reorder(text.term, text.similarity): mediated"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(65,105,225,1)","opacity":1,"size":5.6692913385826778,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(65,105,225,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":43.762557077625573,"r":7.3059360730593621,"b":40.182648401826491,"l":81.09589041095893},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"title":{"text":"Top 20 similarity scores with 'text'+'analysis'+'software' embeddings","font":{"color":"rgba(0,0,0,1)","family":"","size":17.534246575342465},"x":0.5,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.61199999999999999,1.008],"tickmode":"array","ticktext":["0.7","0.8","0.9","1.0"],"tickvals":[0.70000000000000007,0.80000000000000004,0.90000000000000013,1],"categoryorder":"array","categoryarray":["0.7","0.8","0.9","1.0"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"similarity score","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.40000000000000002,20.600000000000001],"tickmode":"array","ticktext":["apply","assistant","dictionaries","directions","explored","mediated","night","categories","judgments","grammatical","young","inherent","sets","describe","allowing","continue","likes","quantified","defects","analysis"],"tickvals":[1,2,3,4.0000000000000009,5,6.0000000000000009,7,8,9,10,11,12.000000000000002,13,14.000000000000002,15,16,17,18,19,20],"categoryorder":"array","categoryarray":["apply","assistant","dictionaries","directions","explored","mediated","night","categories","judgments","grammatical","young","inherent","sets","describe","allowing","continue","likes","quantified","defects","analysis"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"34b426f1a74":{"x":{},"y":{},"type":"scatter"}},"cur_data":"34b426f1a74","visdat":{"34b426f1a74":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</div>
</div>
<p>It seems that skip-gram performs better here. Skip-gram is better at capturing infrequent words, while CBOW is faster and has better representations for more frequent words. Also, skip-gram trains the context word from the center word, while CBOW trains the center word from the context word.</p>
<p>More simply:</p>
<ul>
<li><p>CBOW model tries to predict the missing word given a set of context words;</p></li>
<li><p>Skip-gram model tries to predict the other context missing words given a word.</p></li>
</ul>
</section>
<section id="part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="part-of-speech-tagging-with-udpipe-straka-strakova-2017-tokenizing"><span class="header-section-number">6</span> Part of speech tagging with UDPipe (<span class="citation" data-cites="straka-strakova-2017-tokenizing">Straka and Straková (<a href="#ref-straka-strakova-2017-tokenizing" role="doc-biblioref">2017</a>)</span>)</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">udpipe_download_model</span>(<span class="at">language =</span> <span class="st">"english"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>     language
1 english-ewt
                                                                                file_model
1 C:/Users/Olivier/Documents/GitHub/systematic_lit_review/english-ewt-ud-2.5-191206.udpipe
                                                                                                                                 url
1 https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.5/master/inst/udpipe-ud-2.5-191206/english-ewt-ud-2.5-191206.udpipe
  download_failed download_message
1           FALSE               OK</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>udmodel_english <span class="ot">&lt;-</span> <span class="fu">udpipe_load_model</span>(<span class="at">file =</span> <span class="st">"english-ewt-ud-2.5-191206.udpipe"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>t1<span class="ot">=</span><span class="fu">Sys.time</span>()</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>UD <span class="ot">&lt;-</span> <span class="fu">udpipe_annotate</span>(udmodel_english, <span class="at">x=</span>data_embeddings<span class="sc">$</span>combined_text, <span class="at">trace =</span><span class="dv">40</span>, <span class="at">parallel.cores =</span> <span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2023-10-05 12:50:03.110853 Annotating text fragment 1/405
2023-10-05 12:50:09.373121 Annotating text fragment 41/405
2023-10-05 12:50:16.183167 Annotating text fragment 81/405
2023-10-05 12:50:22.656233 Annotating text fragment 121/405
2023-10-05 12:50:30.043912 Annotating text fragment 161/405
2023-10-05 12:50:35.685606 Annotating text fragment 201/405
2023-10-05 12:50:41.69488 Annotating text fragment 241/405
2023-10-05 12:50:49.454242 Annotating text fragment 281/405
2023-10-05 12:50:55.895202 Annotating text fragment 321/405
2023-10-05 12:51:02.406167 Annotating text fragment 361/405
2023-10-05 12:51:08.52186 Annotating text fragment 401/405</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.time</span>()<span class="sc">-</span>t1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Time difference of 1.099979 mins</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>annotated_text <span class="ot">&lt;-</span> UD <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#write.csv(annotated_text,"annotated_udpipe.csv")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="top-20-nouns-with-udpipe" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="top-20-nouns-with-udpipe"><span class="header-section-number">7</span> Top 20 nouns with UDPipe</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>lemma <span class="ot">&lt;-</span> annotated_text <span class="sc">%&gt;%</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(upos <span class="sc">==</span> <span class="st">"NOUN"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(lemma) <span class="sc">%&gt;%</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">top_n</span>(<span class="dv">20</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(lemma, <span class="fu">aes</span>(<span class="at">x =</span> n, <span class="at">y =</span> <span class="fu">reorder</span>(lemma, n))) <span class="sc">+</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Lemma"</span>) <span class="sc">+</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 Most Frequent Nouns"</span>) <span class="sc">+</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-b17bd2138bd686a9a463" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-b17bd2138bd686a9a463">{"x":{"data":[{"x":[690,268,310,677,358,464,417,215,423,377,349,414,545,221,761,225,308,551,665,213],"y":[19,5,7,18,9,14,12,2,13,10,8,11,15,3,20,4,6,16,17,1],"text":["n: 690<br />reorder(lemma, n): analysis","n: 268<br />reorder(lemma, n): approach","n: 310<br />reorder(lemma, n): brand","n: 677<br />reorder(lemma, n): consumer","n: 358<br />reorder(lemma, n): content","n: 464<br />reorder(lemma, n): customer","n: 417<br />reorder(lemma, n): data","n: 215<br />reorder(lemma, n): information","n: 423<br />reorder(lemma, n): marketing","n: 377<br />reorder(lemma, n): media","n: 349<br />reorder(lemma, n): mining","n: 414<br />reorder(lemma, n): product","n: 545<br />reorder(lemma, n): research","n: 221<br />reorder(lemma, n): result","n: 761<br />reorder(lemma, n): review","n: 225<br />reorder(lemma, n): sentiment","n: 308<br />reorder(lemma, n): service","n: 551<br />reorder(lemma, n): study","n: 665<br />reorder(lemma, n): text","n: 213<br />reorder(lemma, n): value"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(65,105,225,1)","opacity":1,"size":5.6692913385826778,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(65,105,225,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":43.762557077625573,"r":7.3059360730593621,"b":40.182648401826491,"l":89.863013698630155},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"title":{"text":"Top 20 Most Frequent Nouns","font":{"color":"rgba(0,0,0,1)","family":"","size":17.534246575342465},"x":0.5,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[185.59999999999999,788.39999999999998],"tickmode":"array","ticktext":["200","400","600"],"tickvals":[200,400,600],"categoryorder":"array","categoryarray":["200","400","600"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"Frequency","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.40000000000000002,20.600000000000001],"tickmode":"array","ticktext":["value","information","result","sentiment","approach","service","brand","mining","content","media","product","data","marketing","customer","research","study","text","consumer","analysis","review"],"tickvals":[1,2,3,4.0000000000000009,5,6.0000000000000009,7,8,9,10,11,12.000000000000002,13,14.000000000000002,15,16,17,18,19,20],"categoryorder":"array","categoryarray":["value","information","result","sentiment","approach","service","brand","mining","content","media","product","data","marketing","customer","research","study","text","consumer","analysis","review"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"Lemma","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"34b4360363cd":{"x":{},"y":{},"type":"scatter"}},"cur_data":"34b4360363cd","visdat":{"34b4360363cd":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</section>
<section id="part-of-speech-tagging-with-trankit-nguyen2021trankit" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="part-of-speech-tagging-with-trankit-nguyen2021trankit"><span class="header-section-number">8</span> Part of speech tagging with Trankit (<span class="citation" data-cites="nguyen2021trankit">Nguyen et al. (<a href="#ref-nguyen2021trankit" role="doc-biblioref">2021</a>)</span>)</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trankit <span class="im">import</span> Pipeline</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> json_normalize</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data_for_embeddings.csv"</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize a pipeline for English</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> Pipeline(<span class="st">'english'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Loading pretrained XLM-Roberta, this may take a while...
Loading tokenizer for english
Loading tagger for english
Loading lemmatizer for english
Loading NER tagger for english
==================================================
Active language: english
==================================================</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#test = p.posdep(df.loc[:5]['combined_text'][1])</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co">#testdf = pd.DataFrame(pd.json_normalize(test['sentences'], 'tokens'))</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">#pos = p.posdep(all)</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame()  </span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">#part of speech tagging</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> df[<span class="st">'combined_text'</span>]:</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> p.posdep(text)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    pos_df <span class="op">=</span> pd.json_normalize(pos[<span class="st">'sentences'</span>], <span class="st">'tokens'</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> pd.concat([results,pos_df])</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">#lemmatization</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>results_lemma <span class="op">=</span> pd.DataFrame()  </span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> df[<span class="st">'combined_text'</span>]:</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>    lemma <span class="op">=</span> p.lemmatize(text)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    lemma_df <span class="op">=</span> pd.json_normalize(lemma[<span class="st">'sentences'</span>], <span class="st">'tokens'</span>)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>    results_lemma <span class="op">=</span> pd.concat([results_lemma,lemma_df])</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="co">#join both data frames</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>results_complete <span class="op">=</span> pd.concat([results, results_lemma[<span class="st">'text'</span>].rename(<span class="st">"lemma"</span>)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>results_complete[<span class="st">"lemma"</span>] <span class="op">=</span> results_complete[<span class="st">"text"</span>]</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co">#results_lemma.to_csv("lemmas_trankit.csv")</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="co">#results_complete.to_csv("annotated_trankit.csv")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="top-20-nouns-with-trankit" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="top-20-nouns-with-trankit"><span class="header-section-number">9</span> Top 20 nouns with Trankit</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data from the "results" DataFrame</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure that "results" contains the same columns as the original CSV file</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># (e.g., "upos" and "lemma")</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>results_complete <span class="op">=</span> pd.read_csv(<span class="st">"annotated_trankit.csv"</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter rows where 'upos' is equal to "NOUN"</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>noun_data <span class="op">=</span> results_complete[results_complete[<span class="st">'upos'</span>] <span class="op">==</span> <span class="st">'NOUN'</span>]</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Group by 'lemma' and count the number of occurrences</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>top_nouns <span class="op">=</span> noun_data[<span class="st">'lemma'</span>].value_counts().reset_index()</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>top_nouns.columns <span class="op">=</span> [<span class="st">'lemma'</span>, <span class="st">'n'</span>]</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>top_nouns <span class="op">=</span> top_nouns.head(<span class="dv">20</span>)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a chart using Plotly Express</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"fig"</span> <span class="kw">not</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> px.scatter(top_nouns, x<span class="op">=</span><span class="st">'n'</span>, y<span class="op">=</span><span class="st">'lemma'</span>, color<span class="op">=</span><span class="st">'lemma'</span>,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>                     labels<span class="op">=</span>{<span class="st">'n'</span>: <span class="st">'Frequency'</span>, <span class="st">'lemma'</span>: <span class="st">'Lemma'</span>},</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>                     title<span class="op">=</span><span class="st">'Top 20 Most Frequent Nouns'</span>)</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Customize the chart's style</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">12</span>, opacity<span class="op">=</span><span class="fl">0.6</span>),</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>                      selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>))</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(title_x<span class="op">=</span><span class="fl">0.5</span>, title_font<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">20</span>))</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(template<span class="op">=</span><span class="st">"plotly_white"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script src="https://cdn.plot.ly/plotly-2.18.2.min.js"></script>                <div id="14ba5575-931d-46d0-9cbb-b9494e26c6fb" class="plotly-graph-div" style="height:100%; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("14ba5575-931d-46d0-9cbb-b9494e26c6fb")) {                    Plotly.newPlot(                        "14ba5575-931d-46d0-9cbb-b9494e26c6fb",                        [{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"analysis","marker":{"color":"#636efa","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"analysis","orientation":"h","showlegend":true,"x":[681],"xaxis":"x","y":["analysis"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"text","marker":{"color":"#EF553B","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"text","orientation":"h","showlegend":true,"x":[598],"xaxis":"x","y":["text"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"research","marker":{"color":"#00cc96","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"research","orientation":"h","showlegend":true,"x":[546],"xaxis":"x","y":["research"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"reviews","marker":{"color":"#ab63fa","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"reviews","orientation":"h","showlegend":true,"x":[511],"xaxis":"x","y":["reviews"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"marketing","marker":{"color":"#FFA15A","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"marketing","orientation":"h","showlegend":true,"x":[464],"xaxis":"x","y":["marketing"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"study","marker":{"color":"#19d3f3","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"study","orientation":"h","showlegend":true,"x":[423],"xaxis":"x","y":["study"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"data","marker":{"color":"#FF6692","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"data","orientation":"h","showlegend":true,"x":[402],"xaxis":"x","y":["data"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"consumer","marker":{"color":"#B6E880","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"consumer","orientation":"h","showlegend":true,"x":[389],"xaxis":"x","y":["consumer"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"content","marker":{"color":"#FF97FF","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"content","orientation":"h","showlegend":true,"x":[384],"xaxis":"x","y":["content"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"mining","marker":{"color":"#FECB52","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"mining","orientation":"h","showlegend":true,"x":[367],"xaxis":"x","y":["mining"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"media","marker":{"color":"#636efa","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"media","orientation":"h","showlegend":true,"x":[360],"xaxis":"x","y":["media"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"consumers","marker":{"color":"#EF553B","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"consumers","orientation":"h","showlegend":true,"x":[326],"xaxis":"x","y":["consumers"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"brand","marker":{"color":"#00cc96","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"brand","orientation":"h","showlegend":true,"x":[293],"xaxis":"x","y":["brand"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"product","marker":{"color":"#ab63fa","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"product","orientation":"h","showlegend":true,"x":[279],"xaxis":"x","y":["product"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"customer","marker":{"color":"#FFA15A","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"customer","orientation":"h","showlegend":true,"x":[267],"xaxis":"x","y":["customer"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"approach","marker":{"color":"#19d3f3","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"approach","orientation":"h","showlegend":true,"x":[253],"xaxis":"x","y":["approach"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"review","marker":{"color":"#FF6692","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"review","orientation":"h","showlegend":true,"x":[239],"xaxis":"x","y":["review"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"service","marker":{"color":"#B6E880","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"service","orientation":"h","showlegend":true,"x":[216],"xaxis":"x","y":["service"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"information","marker":{"color":"#FF97FF","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"information","orientation":"h","showlegend":true,"x":[208],"xaxis":"x","y":["information"],"yaxis":"y","type":"scatter"},{"hovertemplate":"Lemma=%{y}<br>Frequency=%{x}<extra></extra>","legendgroup":"value","marker":{"color":"#FECB52","symbol":"circle","opacity":0.6,"size":12},"mode":"markers","name":"value","orientation":"h","showlegend":true,"x":[189],"xaxis":"x","y":["value"],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"Frequency"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"Lemma"},"categoryorder":"array","categoryarray":["value","information","service","review","approach","customer","product","brand","consumers","media","mining","content","consumer","data","study","marketing","reviews","research","text","analysis"]},"legend":{"title":{"text":"Lemma"},"tracegroupgap":0},"title":{"text":"Top 20 Most Frequent Nouns","font":{"size":20},"x":0.5}},                        {"responsive": true}                    )                };                            </script>        </div>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the chart</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.show()</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.write_html("top_20_nouns_trankit_python.html")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="part-of-speech-tagging-with-stanza-qi2020stanza" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="part-of-speech-tagging-with-stanza-qi2020stanza"><span class="header-section-number">10</span> Part of speech tagging with Stanza (<span class="citation" data-cites="qi2020stanza">Qi et al. (<a href="#ref-qi2020stanza" role="doc-biblioref">2020</a>)</span>)</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> stanza</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Stanza model</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> stanza.Pipeline(lang<span class="op">=</span><span class="st">'en'</span>, processors<span class="op">=</span><span class="st">'tokenize, mwt, pos, lemma, ner'</span>, use_gpu<span class="op">=</span><span class="va">True</span>, tokenize_pretokenized<span class="op">=</span><span class="va">False</span>, tokenize_no_ssplit<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>2023-10-05 12:54:15 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES

Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json:   0%|          | 0.00/30.1k [00:00&lt;?, ?B/s]
Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.0.json: 216kB [00:00, 12.0MB/s]                    
2023-10-05 12:54:15 WARNING: Can not find mwt: default from official model list. Ignoring it.
2023-10-05 12:54:16 INFO: Loading these models for language: en (English):
=========================
| Processor | Package   |
-------------------------
| tokenize  | combined  |
| pos       | combined  |
| lemma     | combined  |
| ner       | ontonotes |
=========================

2023-10-05 12:54:16 INFO: Using device: cuda
2023-10-05 12:54:16 INFO: Loading: tokenize
2023-10-05 12:54:16 INFO: Loading: pos
2023-10-05 12:54:16 INFO: Loading: lemma
2023-10-05 12:54:16 INFO: Loading: ner
2023-10-05 12:54:16 INFO: Done loading processors!</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the DataFrame from the CSV file</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data_for_embeddings.csv"</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty DataFrame to store annotated data</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>annotated_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> tqdm(df[<span class="st">'combined_text'</span>], desc<span class="op">=</span><span class="st">"Processing Texts"</span>):</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(text)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    dicts <span class="op">=</span> doc.to_dict()</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the dictionary into a temporary DataFrame</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    temp_df <span class="op">=</span> pd.DataFrame(dicts[<span class="dv">0</span>])</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Append data from the temporary DataFrame to annotated_df while ignoring the index</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>    annotated_df <span class="op">=</span> pd.concat([annotated_df, temp_df], ignore_index<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Processing Texts:   0%|          | 0/405 [00:00&lt;?, ?it/s]
Processing Texts:   0%|          | 1/405 [00:00&lt;04:50,  1.39it/s]
Processing Texts:   0%|          | 2/405 [00:01&lt;04:22,  1.54it/s]
Processing Texts:   1%|          | 3/405 [00:01&lt;04:03,  1.65it/s]
Processing Texts:   1%|          | 4/405 [00:02&lt;03:44,  1.79it/s]
Processing Texts:   1%|1         | 5/405 [00:02&lt;03:21,  1.98it/s]
Processing Texts:   1%|1         | 6/405 [00:02&lt;03:12,  2.07it/s]
Processing Texts:   2%|1         | 7/405 [00:03&lt;03:16,  2.03it/s]
Processing Texts:   2%|1         | 8/405 [00:03&lt;03:07,  2.12it/s]
Processing Texts:   2%|2         | 9/405 [00:04&lt;03:17,  2.00it/s]
Processing Texts:   2%|2         | 10/405 [00:04&lt;03:15,  2.02it/s]
Processing Texts:   3%|2         | 11/405 [00:05&lt;02:51,  2.29it/s]
Processing Texts:   3%|2         | 12/405 [00:05&lt;03:04,  2.13it/s]
Processing Texts:   3%|3         | 13/405 [00:06&lt;03:27,  1.89it/s]
Processing Texts:   3%|3         | 14/405 [00:06&lt;03:15,  2.00it/s]
Processing Texts:   4%|3         | 15/405 [00:07&lt;03:22,  1.92it/s]
Processing Texts:   4%|3         | 16/405 [00:07&lt;03:08,  2.07it/s]
Processing Texts:   4%|4         | 17/405 [00:08&lt;03:23,  1.90it/s]
Processing Texts:   4%|4         | 18/405 [00:08&lt;03:08,  2.05it/s]
Processing Texts:   5%|4         | 19/405 [00:09&lt;03:03,  2.10it/s]
Processing Texts:   5%|4         | 20/405 [00:09&lt;02:38,  2.43it/s]
Processing Texts:   5%|5         | 21/405 [00:10&lt;02:57,  2.16it/s]
Processing Texts:   5%|5         | 22/405 [00:10&lt;02:49,  2.26it/s]
Processing Texts:   6%|5         | 23/405 [00:10&lt;02:45,  2.31it/s]
Processing Texts:   6%|5         | 24/405 [00:11&lt;02:48,  2.26it/s]
Processing Texts:   6%|6         | 25/405 [00:11&lt;02:57,  2.14it/s]
Processing Texts:   6%|6         | 26/405 [00:12&lt;02:51,  2.21it/s]
Processing Texts:   7%|6         | 27/405 [00:13&lt;03:15,  1.93it/s]
Processing Texts:   7%|6         | 28/405 [00:13&lt;03:05,  2.03it/s]
Processing Texts:   7%|7         | 29/405 [00:14&lt;03:14,  1.94it/s]
Processing Texts:   7%|7         | 30/405 [00:14&lt;03:57,  1.58it/s]
Processing Texts:   8%|7         | 31/405 [00:15&lt;03:44,  1.67it/s]
Processing Texts:   8%|7         | 32/405 [00:16&lt;03:59,  1.56it/s]
Processing Texts:   8%|8         | 33/405 [00:16&lt;03:28,  1.78it/s]
Processing Texts:   8%|8         | 34/405 [00:17&lt;03:18,  1.87it/s]
Processing Texts:   9%|8         | 35/405 [00:17&lt;03:03,  2.01it/s]
Processing Texts:   9%|8         | 36/405 [00:17&lt;03:03,  2.02it/s]
Processing Texts:   9%|9         | 37/405 [00:18&lt;02:54,  2.11it/s]
Processing Texts:   9%|9         | 38/405 [00:18&lt;02:47,  2.19it/s]
Processing Texts:  10%|9         | 39/405 [00:19&lt;02:44,  2.23it/s]
Processing Texts:  10%|9         | 40/405 [00:19&lt;02:34,  2.37it/s]
Processing Texts:  10%|#         | 41/405 [00:20&lt;02:32,  2.38it/s]
Processing Texts:  10%|#         | 42/405 [00:20&lt;02:27,  2.47it/s]
Processing Texts:  11%|#         | 43/405 [00:20&lt;02:41,  2.25it/s]
Processing Texts:  11%|#         | 44/405 [00:21&lt;02:45,  2.19it/s]
Processing Texts:  11%|#1        | 45/405 [00:21&lt;02:49,  2.12it/s]
Processing Texts:  11%|#1        | 46/405 [00:22&lt;02:51,  2.09it/s]
Processing Texts:  12%|#1        | 47/405 [00:22&lt;02:55,  2.04it/s]
Processing Texts:  12%|#1        | 48/405 [00:23&lt;02:59,  1.99it/s]
Processing Texts:  12%|#2        | 49/405 [00:23&lt;02:53,  2.06it/s]
Processing Texts:  12%|#2        | 50/405 [00:24&lt;02:38,  2.24it/s]
Processing Texts:  13%|#2        | 51/405 [00:24&lt;02:55,  2.01it/s]
Processing Texts:  13%|#2        | 52/405 [00:25&lt;03:02,  1.93it/s]
Processing Texts:  13%|#3        | 53/405 [00:25&lt;02:55,  2.00it/s]
Processing Texts:  13%|#3        | 54/405 [00:26&lt;02:50,  2.06it/s]
Processing Texts:  14%|#3        | 55/405 [00:26&lt;02:43,  2.14it/s]
Processing Texts:  14%|#3        | 56/405 [00:27&lt;02:45,  2.11it/s]
Processing Texts:  14%|#4        | 57/405 [00:27&lt;02:47,  2.08it/s]
Processing Texts:  14%|#4        | 58/405 [00:28&lt;03:23,  1.70it/s]
Processing Texts:  15%|#4        | 59/405 [00:29&lt;03:42,  1.55it/s]
Processing Texts:  15%|#4        | 60/405 [00:30&lt;03:53,  1.48it/s]
Processing Texts:  15%|#5        | 61/405 [00:31&lt;04:26,  1.29it/s]
Processing Texts:  15%|#5        | 62/405 [00:31&lt;04:26,  1.29it/s]
Processing Texts:  16%|#5        | 63/405 [00:32&lt;03:54,  1.46it/s]
Processing Texts:  16%|#5        | 64/405 [00:33&lt;04:12,  1.35it/s]
Processing Texts:  16%|#6        | 65/405 [00:33&lt;03:39,  1.55it/s]
Processing Texts:  16%|#6        | 66/405 [00:34&lt;03:20,  1.69it/s]
Processing Texts:  17%|#6        | 67/405 [00:34&lt;03:10,  1.78it/s]
Processing Texts:  17%|#6        | 68/405 [00:35&lt;02:49,  1.98it/s]
Processing Texts:  17%|#7        | 69/405 [00:35&lt;02:33,  2.18it/s]
Processing Texts:  17%|#7        | 70/405 [00:35&lt;02:19,  2.40it/s]
Processing Texts:  18%|#7        | 71/405 [00:36&lt;02:27,  2.27it/s]
Processing Texts:  18%|#7        | 72/405 [00:36&lt;02:24,  2.31it/s]
Processing Texts:  18%|#8        | 73/405 [00:37&lt;02:31,  2.20it/s]
Processing Texts:  18%|#8        | 74/405 [00:37&lt;02:36,  2.11it/s]
Processing Texts:  19%|#8        | 75/405 [00:38&lt;02:51,  1.93it/s]
Processing Texts:  19%|#8        | 76/405 [00:38&lt;02:39,  2.07it/s]
Processing Texts:  19%|#9        | 77/405 [00:39&lt;02:27,  2.23it/s]
Processing Texts:  19%|#9        | 78/405 [00:39&lt;02:09,  2.52it/s]
Processing Texts:  20%|#9        | 79/405 [00:39&lt;02:15,  2.41it/s]
Processing Texts:  20%|#9        | 80/405 [00:40&lt;02:33,  2.11it/s]
Processing Texts:  20%|##        | 81/405 [00:40&lt;02:45,  1.96it/s]
Processing Texts:  20%|##        | 82/405 [00:41&lt;02:39,  2.03it/s]
Processing Texts:  20%|##        | 83/405 [00:41&lt;02:37,  2.05it/s]
Processing Texts:  21%|##        | 84/405 [00:42&lt;02:22,  2.26it/s]
Processing Texts:  21%|##        | 85/405 [00:42&lt;02:44,  1.94it/s]
Processing Texts:  21%|##1       | 86/405 [00:43&lt;03:15,  1.63it/s]
Processing Texts:  21%|##1       | 87/405 [00:44&lt;03:07,  1.69it/s]
Processing Texts:  22%|##1       | 88/405 [00:44&lt;02:47,  1.90it/s]
Processing Texts:  22%|##1       | 89/405 [00:45&lt;02:27,  2.14it/s]
Processing Texts:  22%|##2       | 90/405 [00:45&lt;02:21,  2.23it/s]
Processing Texts:  22%|##2       | 91/405 [00:45&lt;02:20,  2.23it/s]
Processing Texts:  23%|##2       | 92/405 [00:46&lt;02:33,  2.04it/s]
Processing Texts:  23%|##2       | 93/405 [00:46&lt;02:34,  2.02it/s]
Processing Texts:  23%|##3       | 94/405 [00:47&lt;02:40,  1.94it/s]
Processing Texts:  23%|##3       | 95/405 [00:47&lt;02:28,  2.09it/s]
Processing Texts:  24%|##3       | 96/405 [00:48&lt;02:24,  2.14it/s]
Processing Texts:  24%|##3       | 97/405 [00:48&lt;02:09,  2.38it/s]
Processing Texts:  24%|##4       | 98/405 [00:49&lt;02:04,  2.48it/s]
Processing Texts:  25%|##4       | 100/405 [00:49&lt;01:56,  2.61it/s]
Processing Texts:  25%|##4       | 101/405 [00:50&lt;02:01,  2.50it/s]
Processing Texts:  25%|##5       | 102/405 [00:51&lt;02:48,  1.80it/s]
Processing Texts:  25%|##5       | 103/405 [00:51&lt;02:32,  1.98it/s]
Processing Texts:  26%|##5       | 104/405 [00:51&lt;02:23,  2.10it/s]
Processing Texts:  26%|##5       | 105/405 [00:52&lt;02:18,  2.17it/s]
Processing Texts:  26%|##6       | 106/405 [00:52&lt;02:28,  2.01it/s]
Processing Texts:  26%|##6       | 107/405 [00:53&lt;03:01,  1.65it/s]
Processing Texts:  27%|##6       | 108/405 [00:54&lt;03:01,  1.64it/s]
Processing Texts:  27%|##6       | 109/405 [00:54&lt;02:40,  1.85it/s]
Processing Texts:  27%|##7       | 110/405 [00:55&lt;02:40,  1.84it/s]
Processing Texts:  27%|##7       | 111/405 [00:55&lt;02:24,  2.04it/s]
Processing Texts:  28%|##7       | 112/405 [00:56&lt;02:51,  1.71it/s]
Processing Texts:  28%|##7       | 113/405 [00:56&lt;02:27,  1.98it/s]
Processing Texts:  28%|##8       | 114/405 [00:57&lt;02:31,  1.91it/s]
Processing Texts:  28%|##8       | 115/405 [00:57&lt;02:35,  1.86it/s]
Processing Texts:  29%|##8       | 116/405 [00:58&lt;02:21,  2.04it/s]
Processing Texts:  29%|##8       | 117/405 [00:58&lt;02:27,  1.96it/s]
Processing Texts:  29%|##9       | 118/405 [00:59&lt;02:27,  1.94it/s]
Processing Texts:  29%|##9       | 119/405 [00:59&lt;02:38,  1.80it/s]
Processing Texts:  30%|##9       | 120/405 [01:00&lt;02:29,  1.91it/s]
Processing Texts:  30%|##9       | 121/405 [01:00&lt;02:26,  1.94it/s]
Processing Texts:  30%|###       | 122/405 [01:01&lt;02:30,  1.89it/s]
Processing Texts:  30%|###       | 123/405 [01:02&lt;02:36,  1.80it/s]
Processing Texts:  31%|###       | 124/405 [01:02&lt;02:25,  1.93it/s]
Processing Texts:  31%|###       | 125/405 [01:03&lt;02:25,  1.93it/s]
Processing Texts:  31%|###1      | 126/405 [01:03&lt;02:15,  2.06it/s]
Processing Texts:  31%|###1      | 127/405 [01:04&lt;02:31,  1.84it/s]
Processing Texts:  32%|###1      | 128/405 [01:04&lt;02:26,  1.89it/s]
Processing Texts:  32%|###1      | 129/405 [01:05&lt;02:26,  1.88it/s]
Processing Texts:  32%|###2      | 130/405 [01:05&lt;02:17,  2.00it/s]
Processing Texts:  32%|###2      | 131/405 [01:06&lt;02:20,  1.94it/s]
Processing Texts:  33%|###2      | 132/405 [01:06&lt;02:21,  1.93it/s]
Processing Texts:  33%|###2      | 133/405 [01:07&lt;02:23,  1.89it/s]
Processing Texts:  33%|###3      | 134/405 [01:07&lt;02:38,  1.71it/s]
Processing Texts:  33%|###3      | 135/405 [01:08&lt;02:34,  1.75it/s]
Processing Texts:  34%|###3      | 136/405 [01:08&lt;02:25,  1.85it/s]
Processing Texts:  34%|###3      | 137/405 [01:09&lt;02:16,  1.96it/s]
Processing Texts:  34%|###4      | 138/405 [01:10&lt;02:24,  1.84it/s]
Processing Texts:  34%|###4      | 139/405 [01:10&lt;02:25,  1.83it/s]
Processing Texts:  35%|###4      | 140/405 [01:11&lt;02:35,  1.71it/s]
Processing Texts:  35%|###4      | 141/405 [01:11&lt;02:25,  1.82it/s]
Processing Texts:  35%|###5      | 142/405 [01:12&lt;02:17,  1.91it/s]
Processing Texts:  35%|###5      | 143/405 [01:12&lt;02:03,  2.12it/s]
Processing Texts:  36%|###5      | 144/405 [01:12&lt;01:40,  2.59it/s]
Processing Texts:  36%|###5      | 145/405 [01:13&lt;02:21,  1.84it/s]
Processing Texts:  36%|###6      | 146/405 [01:14&lt;02:55,  1.48it/s]
Processing Texts:  36%|###6      | 147/405 [01:15&lt;03:28,  1.24it/s]
Processing Texts:  37%|###6      | 148/405 [01:16&lt;03:32,  1.21it/s]
Processing Texts:  37%|###6      | 149/405 [01:17&lt;03:24,  1.25it/s]
Processing Texts:  37%|###7      | 150/405 [01:17&lt;03:11,  1.33it/s]
Processing Texts:  37%|###7      | 151/405 [01:18&lt;02:41,  1.57it/s]
Processing Texts:  38%|###7      | 152/405 [01:18&lt;02:29,  1.69it/s]
Processing Texts:  38%|###7      | 153/405 [01:19&lt;02:49,  1.49it/s]
Processing Texts:  38%|###8      | 154/405 [01:20&lt;03:11,  1.31it/s]
Processing Texts:  38%|###8      | 155/405 [01:21&lt;03:32,  1.18it/s]
Processing Texts:  39%|###8      | 156/405 [01:22&lt;03:34,  1.16it/s]
Processing Texts:  39%|###8      | 157/405 [01:23&lt;03:05,  1.34it/s]
Processing Texts:  39%|###9      | 158/405 [01:23&lt;03:09,  1.30it/s]
Processing Texts:  39%|###9      | 159/405 [01:24&lt;02:38,  1.55it/s]
Processing Texts:  40%|###9      | 160/405 [01:24&lt;02:37,  1.56it/s]
Processing Texts:  40%|###9      | 161/405 [01:25&lt;02:28,  1.64it/s]
Processing Texts:  40%|####      | 162/405 [01:25&lt;02:17,  1.76it/s]
Processing Texts:  40%|####      | 163/405 [01:26&lt;01:57,  2.05it/s]
Processing Texts:  40%|####      | 164/405 [01:26&lt;02:04,  1.94it/s]
Processing Texts:  41%|####      | 165/405 [01:27&lt;01:45,  2.28it/s]
Processing Texts:  41%|####      | 166/405 [01:27&lt;02:01,  1.97it/s]
Processing Texts:  41%|####1     | 167/405 [01:28&lt;01:52,  2.11it/s]
Processing Texts:  41%|####1     | 168/405 [01:28&lt;01:55,  2.05it/s]
Processing Texts:  42%|####1     | 169/405 [01:29&lt;01:49,  2.15it/s]
Processing Texts:  42%|####1     | 170/405 [01:29&lt;01:56,  2.01it/s]
Processing Texts:  42%|####2     | 171/405 [01:29&lt;01:44,  2.24it/s]
Processing Texts:  42%|####2     | 172/405 [01:30&lt;01:46,  2.18it/s]
Processing Texts:  43%|####2     | 173/405 [01:30&lt;01:45,  2.20it/s]
Processing Texts:  43%|####2     | 174/405 [01:31&lt;01:44,  2.21it/s]
Processing Texts:  43%|####3     | 175/405 [01:31&lt;01:37,  2.35it/s]
Processing Texts:  43%|####3     | 176/405 [01:32&lt;01:42,  2.23it/s]
Processing Texts:  44%|####3     | 177/405 [01:32&lt;01:57,  1.93it/s]
Processing Texts:  44%|####3     | 178/405 [01:33&lt;01:57,  1.93it/s]
Processing Texts:  44%|####4     | 179/405 [01:33&lt;02:01,  1.86it/s]
Processing Texts:  44%|####4     | 180/405 [01:34&lt;01:48,  2.08it/s]
Processing Texts:  45%|####4     | 181/405 [01:34&lt;01:58,  1.89it/s]
Processing Texts:  45%|####4     | 182/405 [01:35&lt;01:57,  1.89it/s]
Processing Texts:  45%|####5     | 183/405 [01:35&lt;01:53,  1.96it/s]
Processing Texts:  45%|####5     | 184/405 [01:36&lt;01:44,  2.11it/s]
Processing Texts:  46%|####5     | 185/405 [01:36&lt;01:30,  2.42it/s]
Processing Texts:  46%|####5     | 186/405 [01:37&lt;01:35,  2.30it/s]
Processing Texts:  46%|####6     | 187/405 [01:37&lt;01:39,  2.19it/s]
Processing Texts:  46%|####6     | 188/405 [01:38&lt;01:41,  2.14it/s]
Processing Texts:  47%|####6     | 189/405 [01:38&lt;01:40,  2.15it/s]
Processing Texts:  47%|####6     | 190/405 [01:38&lt;01:35,  2.26it/s]
Processing Texts:  47%|####7     | 191/405 [01:39&lt;01:39,  2.15it/s]
Processing Texts:  47%|####7     | 192/405 [01:39&lt;01:34,  2.26it/s]
Processing Texts:  48%|####7     | 193/405 [01:40&lt;01:23,  2.54it/s]
Processing Texts:  48%|####7     | 194/405 [01:40&lt;01:41,  2.08it/s]
Processing Texts:  48%|####8     | 195/405 [01:41&lt;01:33,  2.24it/s]
Processing Texts:  48%|####8     | 196/405 [01:41&lt;01:30,  2.31it/s]
Processing Texts:  49%|####8     | 197/405 [01:41&lt;01:23,  2.49it/s]
Processing Texts:  49%|####8     | 198/405 [01:42&lt;01:20,  2.56it/s]
Processing Texts:  49%|####9     | 199/405 [01:42&lt;01:19,  2.59it/s]
Processing Texts:  49%|####9     | 200/405 [01:43&lt;01:26,  2.36it/s]
Processing Texts:  50%|####9     | 201/405 [01:43&lt;01:30,  2.24it/s]
Processing Texts:  50%|####9     | 202/405 [01:44&lt;01:29,  2.27it/s]
Processing Texts:  50%|#####     | 203/405 [01:44&lt;01:33,  2.17it/s]
Processing Texts:  50%|#####     | 204/405 [01:45&lt;01:49,  1.84it/s]
Processing Texts:  51%|#####     | 205/405 [01:45&lt;01:49,  1.83it/s]
Processing Texts:  51%|#####     | 206/405 [01:46&lt;01:54,  1.74it/s]
Processing Texts:  51%|#####1    | 207/405 [01:47&lt;01:53,  1.74it/s]
Processing Texts:  51%|#####1    | 208/405 [01:47&lt;01:39,  1.97it/s]
Processing Texts:  52%|#####1    | 209/405 [01:48&lt;01:41,  1.93it/s]
Processing Texts:  52%|#####1    | 210/405 [01:48&lt;01:33,  2.08it/s]
Processing Texts:  52%|#####2    | 211/405 [01:48&lt;01:27,  2.22it/s]
Processing Texts:  52%|#####2    | 212/405 [01:49&lt;01:39,  1.95it/s]
Processing Texts:  53%|#####2    | 213/405 [01:49&lt;01:30,  2.12it/s]
Processing Texts:  53%|#####2    | 214/405 [01:50&lt;01:33,  2.04it/s]
Processing Texts:  53%|#####3    | 215/405 [01:51&lt;01:44,  1.82it/s]
Processing Texts:  53%|#####3    | 216/405 [01:51&lt;01:51,  1.70it/s]
Processing Texts:  54%|#####3    | 217/405 [01:52&lt;01:33,  2.01it/s]
Processing Texts:  54%|#####3    | 218/405 [01:52&lt;01:57,  1.59it/s]
Processing Texts:  54%|#####4    | 219/405 [01:53&lt;01:42,  1.82it/s]
Processing Texts:  54%|#####4    | 220/405 [01:53&lt;01:31,  2.03it/s]
Processing Texts:  55%|#####4    | 221/405 [01:54&lt;01:26,  2.13it/s]
Processing Texts:  55%|#####4    | 222/405 [01:54&lt;01:26,  2.11it/s]
Processing Texts:  55%|#####5    | 223/405 [01:54&lt;01:21,  2.22it/s]
Processing Texts:  55%|#####5    | 224/405 [01:55&lt;01:28,  2.06it/s]
Processing Texts:  56%|#####5    | 225/405 [01:56&lt;01:26,  2.08it/s]
Processing Texts:  56%|#####5    | 226/405 [01:56&lt;01:19,  2.24it/s]
Processing Texts:  56%|#####6    | 227/405 [01:56&lt;01:12,  2.46it/s]
Processing Texts:  56%|#####6    | 228/405 [01:57&lt;01:15,  2.36it/s]
Processing Texts:  57%|#####6    | 229/405 [01:57&lt;01:14,  2.37it/s]
Processing Texts:  57%|#####6    | 230/405 [01:57&lt;01:13,  2.40it/s]
Processing Texts:  57%|#####7    | 231/405 [01:58&lt;01:16,  2.29it/s]
Processing Texts:  57%|#####7    | 232/405 [01:58&lt;01:20,  2.15it/s]
Processing Texts:  58%|#####7    | 233/405 [01:59&lt;01:19,  2.16it/s]
Processing Texts:  58%|#####7    | 234/405 [02:00&lt;01:27,  1.96it/s]
Processing Texts:  58%|#####8    | 235/405 [02:00&lt;01:28,  1.92it/s]
Processing Texts:  58%|#####8    | 236/405 [02:01&lt;01:22,  2.05it/s]
Processing Texts:  59%|#####8    | 237/405 [02:01&lt;01:24,  2.00it/s]
Processing Texts:  59%|#####8    | 238/405 [02:02&lt;01:22,  2.03it/s]
Processing Texts:  59%|#####9    | 239/405 [02:02&lt;01:24,  1.96it/s]
Processing Texts:  59%|#####9    | 240/405 [02:02&lt;01:19,  2.08it/s]
Processing Texts:  60%|#####9    | 241/405 [02:03&lt;01:19,  2.05it/s]
Processing Texts:  60%|#####9    | 242/405 [02:04&lt;01:30,  1.79it/s]
Processing Texts:  60%|######    | 243/405 [02:04&lt;01:23,  1.94it/s]
Processing Texts:  60%|######    | 244/405 [02:05&lt;01:20,  2.00it/s]
Processing Texts:  60%|######    | 245/405 [02:05&lt;01:15,  2.11it/s]
Processing Texts:  61%|######    | 246/405 [02:06&lt;01:16,  2.07it/s]
Processing Texts:  61%|######    | 247/405 [02:06&lt;01:11,  2.21it/s]
Processing Texts:  61%|######1   | 248/405 [02:06&lt;01:13,  2.13it/s]
Processing Texts:  61%|######1   | 249/405 [02:07&lt;01:35,  1.63it/s]
Processing Texts:  62%|######1   | 250/405 [02:08&lt;01:57,  1.32it/s]
Processing Texts:  62%|######1   | 251/405 [02:09&lt;01:57,  1.31it/s]
Processing Texts:  62%|######2   | 252/405 [02:10&lt;01:50,  1.38it/s]
Processing Texts:  62%|######2   | 253/405 [02:10&lt;01:43,  1.47it/s]
Processing Texts:  63%|######2   | 254/405 [02:11&lt;01:31,  1.65it/s]
Processing Texts:  63%|######2   | 255/405 [02:12&lt;01:41,  1.48it/s]
Processing Texts:  63%|######3   | 256/405 [02:12&lt;01:30,  1.65it/s]
Processing Texts:  63%|######3   | 257/405 [02:13&lt;01:20,  1.85it/s]
Processing Texts:  64%|######3   | 258/405 [02:13&lt;01:08,  2.13it/s]
Processing Texts:  64%|######3   | 259/405 [02:13&lt;01:05,  2.23it/s]
Processing Texts:  64%|######4   | 260/405 [02:14&lt;01:00,  2.39it/s]
Processing Texts:  64%|######4   | 261/405 [02:15&lt;01:23,  1.72it/s]
Processing Texts:  65%|######4   | 262/405 [02:15&lt;01:38,  1.45it/s]
Processing Texts:  65%|######4   | 263/405 [02:16&lt;01:39,  1.42it/s]
Processing Texts:  65%|######5   | 264/405 [02:17&lt;01:38,  1.43it/s]
Processing Texts:  65%|######5   | 265/405 [02:18&lt;01:46,  1.32it/s]
Processing Texts:  66%|######5   | 266/405 [02:19&lt;01:55,  1.20it/s]
Processing Texts:  66%|######5   | 267/405 [02:19&lt;01:47,  1.28it/s]
Processing Texts:  66%|######6   | 268/405 [02:20&lt;01:35,  1.44it/s]
Processing Texts:  66%|######6   | 269/405 [02:21&lt;01:43,  1.31it/s]
Processing Texts:  67%|######6   | 270/405 [02:21&lt;01:32,  1.46it/s]
Processing Texts:  67%|######6   | 271/405 [02:22&lt;01:33,  1.43it/s]
Processing Texts:  67%|######7   | 272/405 [02:23&lt;01:22,  1.61it/s]
Processing Texts:  67%|######7   | 273/405 [02:23&lt;01:15,  1.75it/s]
Processing Texts:  68%|######7   | 274/405 [02:23&lt;01:10,  1.86it/s]
Processing Texts:  68%|######7   | 275/405 [02:24&lt;01:03,  2.04it/s]
Processing Texts:  68%|######8   | 276/405 [02:24&lt;01:09,  1.87it/s]
Processing Texts:  68%|######8   | 277/405 [02:25&lt;01:10,  1.81it/s]
Processing Texts:  69%|######8   | 278/405 [02:26&lt;01:07,  1.87it/s]
Processing Texts:  69%|######8   | 279/405 [02:26&lt;01:05,  1.93it/s]
Processing Texts:  69%|######9   | 280/405 [02:27&lt;01:05,  1.92it/s]
Processing Texts:  69%|######9   | 281/405 [02:27&lt;01:06,  1.87it/s]
Processing Texts:  70%|######9   | 282/405 [02:28&lt;01:07,  1.82it/s]
Processing Texts:  70%|######9   | 283/405 [02:28&lt;01:04,  1.89it/s]
Processing Texts:  70%|#######   | 284/405 [02:29&lt;00:59,  2.04it/s]
Processing Texts:  70%|#######   | 285/405 [02:30&lt;01:19,  1.51it/s]
Processing Texts:  71%|#######   | 286/405 [02:30&lt;01:14,  1.59it/s]
Processing Texts:  71%|#######   | 287/405 [02:31&lt;01:06,  1.77it/s]
Processing Texts:  71%|#######1  | 288/405 [02:31&lt;01:09,  1.69it/s]
Processing Texts:  71%|#######1  | 289/405 [02:32&lt;01:15,  1.53it/s]
Processing Texts:  72%|#######1  | 290/405 [02:33&lt;01:15,  1.53it/s]
Processing Texts:  72%|#######1  | 291/405 [02:33&lt;01:11,  1.60it/s]
Processing Texts:  72%|#######2  | 292/405 [02:34&lt;01:12,  1.56it/s]
Processing Texts:  72%|#######2  | 293/405 [02:34&lt;01:02,  1.78it/s]
Processing Texts:  73%|#######2  | 294/405 [02:35&lt;00:58,  1.88it/s]
Processing Texts:  73%|#######2  | 295/405 [02:35&lt;00:54,  2.03it/s]
Processing Texts:  73%|#######3  | 296/405 [02:36&lt;00:52,  2.10it/s]
Processing Texts:  73%|#######3  | 297/405 [02:36&lt;00:54,  1.98it/s]
Processing Texts:  74%|#######3  | 298/405 [02:37&lt;00:47,  2.26it/s]
Processing Texts:  74%|#######3  | 299/405 [02:37&lt;00:55,  1.92it/s]
Processing Texts:  74%|#######4  | 300/405 [02:38&lt;00:51,  2.04it/s]
Processing Texts:  74%|#######4  | 301/405 [02:38&lt;00:47,  2.17it/s]
Processing Texts:  75%|#######4  | 303/405 [02:39&lt;00:40,  2.54it/s]
Processing Texts:  75%|#######5  | 304/405 [02:39&lt;00:43,  2.32it/s]
Processing Texts:  75%|#######5  | 305/405 [02:40&lt;00:44,  2.25it/s]
Processing Texts:  76%|#######5  | 306/405 [02:40&lt;00:44,  2.22it/s]
Processing Texts:  76%|#######5  | 307/405 [02:40&lt;00:43,  2.24it/s]
Processing Texts:  76%|#######6  | 308/405 [02:41&lt;00:45,  2.16it/s]
Processing Texts:  76%|#######6  | 309/405 [02:41&lt;00:43,  2.19it/s]
Processing Texts:  77%|#######6  | 310/405 [02:42&lt;00:43,  2.17it/s]
Processing Texts:  77%|#######6  | 311/405 [02:43&lt;00:55,  1.69it/s]
Processing Texts:  77%|#######7  | 312/405 [02:43&lt;00:58,  1.60it/s]
Processing Texts:  77%|#######7  | 313/405 [02:44&lt;00:46,  1.96it/s]
Processing Texts:  78%|#######7  | 314/405 [02:44&lt;00:44,  2.04it/s]
Processing Texts:  78%|#######7  | 315/405 [02:45&lt;00:42,  2.10it/s]
Processing Texts:  78%|#######8  | 316/405 [02:45&lt;00:43,  2.04it/s]
Processing Texts:  78%|#######8  | 317/405 [02:46&lt;00:45,  1.93it/s]
Processing Texts:  79%|#######8  | 318/405 [02:46&lt;00:40,  2.14it/s]
Processing Texts:  79%|#######8  | 319/405 [02:46&lt;00:37,  2.28it/s]
Processing Texts:  79%|#######9  | 320/405 [02:47&lt;00:42,  2.02it/s]
Processing Texts:  79%|#######9  | 321/405 [02:48&lt;00:41,  2.04it/s]
Processing Texts:  80%|#######9  | 322/405 [02:48&lt;00:37,  2.23it/s]
Processing Texts:  80%|#######9  | 323/405 [02:48&lt;00:36,  2.25it/s]
Processing Texts:  80%|########  | 324/405 [02:49&lt;00:32,  2.50it/s]
Processing Texts:  80%|########  | 325/405 [02:49&lt;00:30,  2.63it/s]
Processing Texts:  80%|########  | 326/405 [02:49&lt;00:27,  2.86it/s]
Processing Texts:  81%|########  | 327/405 [02:50&lt;00:36,  2.14it/s]
Processing Texts:  81%|########  | 328/405 [02:51&lt;00:46,  1.67it/s]
Processing Texts:  81%|########1 | 329/405 [02:52&lt;00:53,  1.42it/s]
Processing Texts:  81%|########1 | 330/405 [02:52&lt;00:42,  1.75it/s]
Processing Texts:  82%|########1 | 331/405 [02:53&lt;00:46,  1.59it/s]
Processing Texts:  82%|########1 | 332/405 [02:54&lt;00:51,  1.40it/s]
Processing Texts:  82%|########2 | 333/405 [02:55&lt;00:56,  1.28it/s]
Processing Texts:  82%|########2 | 334/405 [02:55&lt;00:47,  1.50it/s]
Processing Texts:  83%|########2 | 335/405 [02:56&lt;00:42,  1.65it/s]
Processing Texts:  83%|########2 | 336/405 [02:56&lt;00:36,  1.90it/s]
Processing Texts:  83%|########3 | 337/405 [02:56&lt;00:32,  2.08it/s]
Processing Texts:  83%|########3 | 338/405 [02:57&lt;00:29,  2.28it/s]
Processing Texts:  84%|########3 | 339/405 [02:57&lt;00:29,  2.24it/s]
Processing Texts:  84%|########3 | 340/405 [02:58&lt;00:29,  2.17it/s]
Processing Texts:  84%|########4 | 341/405 [02:58&lt;00:30,  2.11it/s]
Processing Texts:  84%|########4 | 342/405 [02:59&lt;00:30,  2.06it/s]
Processing Texts:  85%|########4 | 343/405 [03:00&lt;00:40,  1.53it/s]
Processing Texts:  85%|########4 | 344/405 [03:00&lt;00:33,  1.82it/s]
Processing Texts:  85%|########5 | 345/405 [03:00&lt;00:32,  1.86it/s]
Processing Texts:  85%|########5 | 346/405 [03:01&lt;00:30,  1.97it/s]
Processing Texts:  86%|########5 | 347/405 [03:01&lt;00:26,  2.18it/s]
Processing Texts:  86%|########5 | 348/405 [03:02&lt;00:23,  2.43it/s]
Processing Texts:  86%|########6 | 349/405 [03:02&lt;00:21,  2.62it/s]
Processing Texts:  86%|########6 | 350/405 [03:02&lt;00:25,  2.19it/s]
Processing Texts:  87%|########6 | 351/405 [03:03&lt;00:26,  2.02it/s]
Processing Texts:  87%|########6 | 352/405 [03:03&lt;00:25,  2.11it/s]
Processing Texts:  87%|########7 | 353/405 [03:04&lt;00:24,  2.16it/s]
Processing Texts:  87%|########7 | 354/405 [03:04&lt;00:22,  2.22it/s]
Processing Texts:  88%|########7 | 355/405 [03:06&lt;00:34,  1.47it/s]
Processing Texts:  88%|########7 | 356/405 [03:06&lt;00:28,  1.72it/s]
Processing Texts:  88%|########8 | 357/405 [03:06&lt;00:26,  1.78it/s]
Processing Texts:  88%|########8 | 358/405 [03:07&lt;00:23,  2.02it/s]
Processing Texts:  89%|########8 | 359/405 [03:07&lt;00:21,  2.11it/s]
Processing Texts:  89%|########8 | 360/405 [03:08&lt;00:23,  1.91it/s]
Processing Texts:  89%|########9 | 361/405 [03:08&lt;00:19,  2.27it/s]
Processing Texts:  89%|########9 | 362/405 [03:08&lt;00:18,  2.34it/s]
Processing Texts:  90%|########9 | 363/405 [03:10&lt;00:32,  1.30it/s]
Processing Texts:  90%|########9 | 364/405 [03:10&lt;00:25,  1.60it/s]
Processing Texts:  90%|######### | 365/405 [03:11&lt;00:23,  1.74it/s]
Processing Texts:  90%|######### | 366/405 [03:11&lt;00:19,  2.01it/s]
Processing Texts:  91%|######### | 367/405 [03:11&lt;00:17,  2.13it/s]
Processing Texts:  91%|######### | 368/405 [03:12&lt;00:17,  2.11it/s]
Processing Texts:  91%|#########1| 369/405 [03:12&lt;00:14,  2.48it/s]
Processing Texts:  91%|#########1| 370/405 [03:13&lt;00:13,  2.57it/s]
Processing Texts:  92%|#########1| 371/405 [03:13&lt;00:15,  2.23it/s]
Processing Texts:  92%|#########1| 372/405 [03:14&lt;00:16,  1.97it/s]
Processing Texts:  92%|#########2| 373/405 [03:14&lt;00:16,  1.90it/s]
Processing Texts:  92%|#########2| 374/405 [03:15&lt;00:16,  1.90it/s]
Processing Texts:  93%|#########2| 375/405 [03:15&lt;00:14,  2.08it/s]
Processing Texts:  93%|#########2| 376/405 [03:15&lt;00:11,  2.48it/s]
Processing Texts:  93%|#########3| 377/405 [03:16&lt;00:11,  2.51it/s]
Processing Texts:  93%|#########3| 378/405 [03:17&lt;00:12,  2.14it/s]
Processing Texts:  94%|#########3| 379/405 [03:17&lt;00:12,  2.03it/s]
Processing Texts:  94%|#########3| 380/405 [03:18&lt;00:12,  2.07it/s]
Processing Texts:  94%|#########4| 381/405 [03:18&lt;00:10,  2.25it/s]
Processing Texts:  94%|#########4| 382/405 [03:18&lt;00:11,  2.03it/s]
Processing Texts:  95%|#########4| 383/405 [03:19&lt;00:10,  2.12it/s]
Processing Texts:  95%|#########4| 384/405 [03:20&lt;00:11,  1.81it/s]
Processing Texts:  95%|#########5| 385/405 [03:20&lt;00:10,  1.97it/s]
Processing Texts:  95%|#########5| 386/405 [03:20&lt;00:08,  2.18it/s]
Processing Texts:  96%|#########5| 387/405 [03:21&lt;00:06,  2.60it/s]
Processing Texts:  96%|#########5| 388/405 [03:21&lt;00:06,  2.69it/s]
Processing Texts:  96%|#########6| 389/405 [03:21&lt;00:06,  2.49it/s]
Processing Texts:  96%|#########6| 390/405 [03:22&lt;00:06,  2.37it/s]
Processing Texts:  97%|#########6| 391/405 [03:22&lt;00:04,  2.88it/s]
Processing Texts:  97%|#########6| 392/405 [03:23&lt;00:04,  2.63it/s]
Processing Texts:  97%|#########7| 393/405 [03:23&lt;00:04,  2.69it/s]
Processing Texts:  97%|#########7| 394/405 [03:23&lt;00:04,  2.61it/s]
Processing Texts:  98%|#########7| 395/405 [03:24&lt;00:04,  2.17it/s]
Processing Texts:  98%|#########7| 396/405 [03:25&lt;00:04,  2.01it/s]
Processing Texts:  98%|#########8| 397/405 [03:25&lt;00:04,  1.93it/s]
Processing Texts:  98%|#########8| 398/405 [03:26&lt;00:03,  1.83it/s]
Processing Texts:  99%|#########8| 399/405 [03:26&lt;00:02,  2.03it/s]
Processing Texts:  99%|#########8| 400/405 [03:27&lt;00:02,  1.98it/s]
Processing Texts:  99%|#########9| 401/405 [03:27&lt;00:01,  2.21it/s]
Processing Texts:  99%|#########9| 402/405 [03:27&lt;00:01,  2.14it/s]
Processing Texts: 100%|#########9| 403/405 [03:28&lt;00:00,  2.02it/s]
Processing Texts: 100%|#########9| 404/405 [03:28&lt;00:00,  2.09it/s]
Processing Texts: 100%|##########| 405/405 [03:29&lt;00:00,  2.53it/s]</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment the line below to save the annotated data to a CSV file</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># annotated_df.to_csv("annotated_stanza.csv")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="top-20-nouns-with-stanza" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="top-20-nouns-with-stanza"><span class="header-section-number">11</span> Top 20 nouns with Stanza</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>annotation_stanza <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"annotated_stanza.csv"</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>lemma <span class="ot">&lt;-</span> annotation_stanza <span class="sc">%&gt;%</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(upos <span class="sc">==</span> <span class="st">"NOUN"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(lemma) <span class="sc">%&gt;%</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">top_n</span>(<span class="dv">20</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(lemma, <span class="fu">aes</span>(<span class="at">x =</span> n, <span class="at">y =</span> <span class="fu">reorder</span>(lemma, n))) <span class="sc">+</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Lemma"</span>) <span class="sc">+</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 Most Frequent Nouns"</span>) <span class="sc">+</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-0d2d68de31952b4cc85b" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-0d2d68de31952b4cc85b">{"x":{"data":[{"x":[746,295,415,772,399,470,402,226,513,379,377,421,593,747,238,317,546,791,236,250],"y":[17,5,11,19,9,13,10,1,14,8,7,12,16,18,3,6,15,20,2,4],"text":["n: 746<br />reorder(lemma, n): analysis","n: 295<br />reorder(lemma, n): approach","n: 415<br />reorder(lemma, n): brand","n: 772<br />reorder(lemma, n): consumer","n: 399<br />reorder(lemma, n): content","n: 470<br />reorder(lemma, n): customer","n: 402<br />reorder(lemma, n): datum","n: 226<br />reorder(lemma, n): information","n: 513<br />reorder(lemma, n): marketing","n: 379<br />reorder(lemma, n): media","n: 377<br />reorder(lemma, n): mining","n: 421<br />reorder(lemma, n): product","n: 593<br />reorder(lemma, n): research","n: 747<br />reorder(lemma, n): review","n: 238<br />reorder(lemma, n): sentiment","n: 317<br />reorder(lemma, n): service","n: 546<br />reorder(lemma, n): study","n: 791<br />reorder(lemma, n): text","n: 236<br />reorder(lemma, n): topic","n: 250<br />reorder(lemma, n): user"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(65,105,225,1)","opacity":1,"size":5.6692913385826778,"symbol":"circle","line":{"width":1.8897637795275593,"color":"rgba(65,105,225,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":43.762557077625573,"r":7.3059360730593621,"b":40.182648401826491,"l":89.863013698630155},"font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724},"title":{"text":"Top 20 Most Frequent Nouns","font":{"color":"rgba(0,0,0,1)","family":"","size":17.534246575342465},"x":0.5,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[197.75,819.25],"tickmode":"array","ticktext":["200","400","600","800"],"tickvals":[200,400,600,800],"categoryorder":"array","categoryarray":["200","400","600","800"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"y","title":{"text":"Frequency","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[0.40000000000000002,20.600000000000001],"tickmode":"array","ticktext":["information","topic","sentiment","user","approach","service","mining","media","content","datum","brand","product","customer","marketing","study","research","analysis","review","consumer","text"],"tickvals":[1,2,3,4.0000000000000009,5,6.0000000000000009,7,8,9,10,11,12.000000000000002,13,14.000000000000002,15,16,17,18,19,20],"categoryorder":"array","categoryarray":["information","topic","sentiment","user","approach","service","mining","media","content","datum","brand","product","customer","marketing","study","research","analysis","review","consumer","text"],"nticks":null,"ticks":"","tickcolor":null,"ticklen":3.6529680365296811,"tickwidth":0,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.68949771689498},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(235,235,235,1)","gridwidth":0.66417600664176002,"zeroline":false,"anchor":"x","title":{"text":"Lemma","font":{"color":"rgba(0,0,0,1)","family":"","size":14.611872146118724}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":null,"bordercolor":null,"borderwidth":0,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.68949771689498}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"34b42a177330":{"x":{},"y":{},"type":"scatter"}},"cur_data":"34b42a177330","visdat":{"34b42a177330":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-nguyen2021trankit" class="csl-entry" role="listitem">
Nguyen, Minh Van, Viet Lai, Amir Pouran Ben Veyseh, and Thien Huu Nguyen. 2021. <span>“Trankit: A Light-Weight Transformer-Based Toolkit for Multilingual Natural Language Processing.”</span> In <em>Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations</em>.
</div>
<div id="ref-qi2020stanza" class="csl-entry" role="listitem">
Qi, Peng, Yuhao Zhang, Yuhui Zhang, Jason Bolton, and Christopher D Manning. 2020. <span>“Stanza: A Python Natural Language Processing Toolkit for Many Human Languages.”</span> <em>arXiv Preprint arXiv:2003.07082</em>.
</div>
<div id="ref-straka-strakova-2017-tokenizing" class="csl-entry" role="listitem">
Straka, Milan, and Jana Straková. 2017. <span>“Tokenizing, <span>POS</span> Tagging, Lemmatizing and Parsing <span>UD</span> 2.0 with <span>UDP</span>ipe.”</span> In <em>Proceedings of the <span>C</span>o<span>NLL</span> 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</em>, 88–99. Vancouver, Canada: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/K17-3009">https://doi.org/10.18653/v1/K17-3009</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb32" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Systematic literature review"</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner:</span><span class="co"> true</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Annotations"</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Olivier Caron</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co">    email: olivier.caron@dauphine.psl.eu</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations: </span></span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="co">      name: "Paris Dauphine - PSL"</span></span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="co">      city: Paris</span></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co">      state: France</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Christophe Benavent</span></span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="co">    email: christophe.benavent@dauphine.psl.eu</span></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations: </span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="co">      name: "Paris Dauphine - PSL"</span></span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a><span class="co">      city: Paris</span></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a><span class="co">      state: France</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a><span class="an">date :</span><span class="co"> "last-modified"</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="an">number-depth:</span><span class="co"> 5</span></span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="co">    theme:</span></span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a><span class="co">      light: yeti</span></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a><span class="co">      dark: darkly</span></span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a><span class="co">    code-summary: "Display code"</span></span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true #enables to display/hide all blocks of code</span></span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a><span class="co">    code-copy: true #enables to copy code</span></span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a><span class="co">    grid:</span></span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a><span class="co">      body-width: 1000px</span></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a><span class="co">      margin-width: 100px</span></span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-location: left</span></span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a><span class="co">  message: false</span></span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> visual</span></span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a><span class="an">fig-align:</span><span class="co"> "center"</span></span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a><span class="an">highlight-style:</span><span class="co"> ayu</span></span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a><span class="an">css:</span><span class="co"> styles.css</span></span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a><span class="an">reference-location:</span><span class="co"> margin</span></span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a><span class="fu">## Libraries and loading data</span></span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-packages</span></span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(word2vec)</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(quanteda)</span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(text)</span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(udpipe)</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(text2vec)</span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reactable)</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>num_cores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>(<span class="at">logical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>num_cores</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">'Number of logical cores to use when training Word2vec model: '</span>, num_cores, <span class="st">'</span><span class="sc">\n</span><span class="st">'</span>)</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a><span class="fu">## Loading data</span></span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-data</span></span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-78"><a href="#cb32-78" aria-hidden="true" tabindex="-1"></a>list_articles <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">"nlp_full_data_final_18-08-2023.csv"</span>, <span class="at">encoding =</span> <span class="st">"UTF-8"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">"entry_number"</span> <span class="ot">=</span> <span class="dv">1</span>)</span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a>list_references <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">"nlp_references_final_18-08-2023.csv"</span>, <span class="at">encoding =</span> <span class="st">"UTF-8"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="st">"citing_art"</span> <span class="ot">=</span> <span class="dv">1</span>)</span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_articles) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"</span><span class="sc">\\</span><span class="st">.+"</span>, <span class="st">"_"</span>, <span class="fu">colnames</span>(list_articles)) <span class="co"># &lt;1&gt;</span></span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_articles) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"^[[:punct:]]+|[[:punct:]]+$"</span>, <span class="st">""</span>, <span class="fu">colnames</span>(list_articles)) <span class="co"># &lt;2&gt;</span></span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_references) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"</span><span class="sc">\\</span><span class="st">.+"</span>, <span class="st">"_"</span>, <span class="fu">colnames</span>(list_references))</span>
<span id="cb32-85"><a href="#cb32-85" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(list_references) <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">"^[[:punct:]]+|[[:punct:]]+$"</span>, <span class="st">""</span>, <span class="fu">colnames</span>(list_references))</span>
<span id="cb32-86"><a href="#cb32-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-87"><a href="#cb32-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-88"><a href="#cb32-88" aria-hidden="true" tabindex="-1"></a>data_embeddings <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span></span>
<span id="cb32-89"><a href="#cb32-89" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(entry_number, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb32-90"><a href="#cb32-90" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(marketing <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb32-91"><a href="#cb32-91" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">"year"</span> <span class="ot">=</span> <span class="fu">substr</span>(prism_coverDate, <span class="dv">7</span>, <span class="dv">10</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb32-92"><a href="#cb32-92" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">keywords =</span> <span class="fu">str_replace_all</span>(authkeywords, <span class="st">"</span><span class="sc">\\</span><span class="st">|"</span>, <span class="st">""</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb32-93"><a href="#cb32-93" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">keywords =</span> <span class="fu">str_squish</span>(keywords)) <span class="sc">%&gt;%</span></span>
<span id="cb32-94"><a href="#cb32-94" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="st">"combined_text"</span> <span class="ot">=</span> <span class="fu">paste0</span>(dc_title,<span class="st">". "</span>, dc_description, <span class="st">". "</span>, keywords))</span>
<span id="cb32-95"><a href="#cb32-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-96"><a href="#cb32-96" aria-hidden="true" tabindex="-1"></a><span class="co">#write.csv(data_embeddings,"data_for_embeddings.csv")</span></span>
<span id="cb32-97"><a href="#cb32-97" aria-hidden="true" tabindex="-1"></a><span class="co">#data_embeddings &lt;- read.csv("data_for_embeddings.csv")</span></span>
<span id="cb32-98"><a href="#cb32-98" aria-hidden="true" tabindex="-1"></a><span class="co">#embeddings &lt;- read.csv("embeddings_bge.csv")</span></span>
<span id="cb32-99"><a href="#cb32-99" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-100"><a href="#cb32-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-101"><a href="#cb32-101" aria-hidden="true" tabindex="-1"></a><span class="fu">## A glimpse of data</span></span>
<span id="cb32-102"><a href="#cb32-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-105"><a href="#cb32-105" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-106"><a href="#cb32-106" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: glimpse-data</span></span>
<span id="cb32-107"><a href="#cb32-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-108"><a href="#cb32-108" aria-hidden="true" tabindex="-1"></a>data_embeddings <span class="sc">%&gt;%</span></span>
<span id="cb32-109"><a href="#cb32-109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">5</span>) <span class="sc">%&gt;%</span></span>
<span id="cb32-110"><a href="#cb32-110" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(entry_number, dc_creator, combined_text, year)</span>
<span id="cb32-111"><a href="#cb32-111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-112"><a href="#cb32-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-113"><a href="#cb32-113" aria-hidden="true" tabindex="-1"></a><span class="fu">## A first Word2Vec embeddings analysis (skip-gram)</span></span>
<span id="cb32-114"><a href="#cb32-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-117"><a href="#cb32-117" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-118"><a href="#cb32-118" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: word2vec-skipgram</span></span>
<span id="cb32-119"><a href="#cb32-119" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb32-120"><a href="#cb32-120" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb32-121"><a href="#cb32-121" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">word2vec</span>(<span class="at">x =</span> <span class="fu">tolower</span>(data_embeddings<span class="sc">$</span>combined_text),</span>
<span id="cb32-122"><a href="#cb32-122" aria-hidden="true" tabindex="-1"></a>                  <span class="at">type =</span> <span class="st">"skip-gram"</span>,</span>
<span id="cb32-123"><a href="#cb32-123" aria-hidden="true" tabindex="-1"></a>                  <span class="at">dim =</span> <span class="dv">500</span>,</span>
<span id="cb32-124"><a href="#cb32-124" aria-hidden="true" tabindex="-1"></a>                  <span class="at">iter =</span> <span class="dv">250</span>,</span>
<span id="cb32-125"><a href="#cb32-125" aria-hidden="true" tabindex="-1"></a>                  <span class="at">min_count =</span> <span class="dv">3</span>,</span>
<span id="cb32-126"><a href="#cb32-126" aria-hidden="true" tabindex="-1"></a>                  <span class="at">hs =</span> <span class="dv">1</span>,</span>
<span id="cb32-127"><a href="#cb32-127" aria-hidden="true" tabindex="-1"></a>                  <span class="at">verbose=</span><span class="dv">10</span>,</span>
<span id="cb32-128"><a href="#cb32-128" aria-hidden="true" tabindex="-1"></a>                  <span class="at">stopwords =</span> <span class="fu">stopwords</span>(<span class="st">"english"</span>),</span>
<span id="cb32-129"><a href="#cb32-129" aria-hidden="true" tabindex="-1"></a>                  <span class="at">window =</span> <span class="st">"7"</span>,</span>
<span id="cb32-130"><a href="#cb32-130" aria-hidden="true" tabindex="-1"></a>                  <span class="at">threads =</span> num_cores)</span>
<span id="cb32-131"><a href="#cb32-131" aria-hidden="true" tabindex="-1"></a>embedding <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(model)</span>
<span id="cb32-132"><a href="#cb32-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-133"><a href="#cb32-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-134"><a href="#cb32-134" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-135"><a href="#cb32-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-136"><a href="#cb32-136" aria-hidden="true" tabindex="-1"></a><span class="fu">### Let's try to find softwares related to text analysis using additions of word embeddings</span></span>
<span id="cb32-137"><a href="#cb32-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-140"><a href="#cb32-140" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-141"><a href="#cb32-141" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: plotly-embedding-skipgram</span></span>
<span id="cb32-142"><a href="#cb32-142" aria-hidden="true" tabindex="-1"></a><span class="co">#| panel: center</span></span>
<span id="cb32-143"><a href="#cb32-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-144"><a href="#cb32-144" aria-hidden="true" tabindex="-1"></a><span class="co">#addition of the wordd embeddings "text", "analysis" and "software"</span></span>
<span id="cb32-145"><a href="#cb32-145" aria-hidden="true" tabindex="-1"></a>embedding_text <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="fu">c</span>(<span class="st">"text"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb32-146"><a href="#cb32-146" aria-hidden="true" tabindex="-1"></a>embedding_analysis <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="fu">c</span>(<span class="st">"analysis"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb32-147"><a href="#cb32-147" aria-hidden="true" tabindex="-1"></a>embedding_software <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, <span class="fu">c</span>(<span class="st">"software"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb32-148"><a href="#cb32-148" aria-hidden="true" tabindex="-1"></a>embedding_text_software <span class="ot">&lt;-</span> embedding_text <span class="sc">+</span> embedding_analysis <span class="sc">+</span> embedding_software</span>
<span id="cb32-149"><a href="#cb32-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-150"><a href="#cb32-150" aria-hidden="true" tabindex="-1"></a>lookslike <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, embedding_text_software, <span class="at">type =</span> <span class="st">"nearest"</span>, <span class="at">top_n =</span> <span class="dv">200</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">text.similarity =</span> <span class="fu">round</span>(text.similarity, <span class="dv">2</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(text.term, text.similarity)</span>
<span id="cb32-151"><a href="#cb32-151" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(lookslike, <span class="at">searchable =</span> <span class="cn">TRUE</span>, <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(</span>
<span id="cb32-152"><a href="#cb32-152" aria-hidden="true" tabindex="-1"></a>  <span class="at">maxWidth =</span> <span class="dv">200</span>,</span>
<span id="cb32-153"><a href="#cb32-153" aria-hidden="true" tabindex="-1"></a>  <span class="at">sortable =</span> <span class="cn">TRUE</span>,</span>
<span id="cb32-154"><a href="#cb32-154" aria-hidden="true" tabindex="-1"></a>  <span class="at">resizable =</span> <span class="cn">TRUE</span></span>
<span id="cb32-155"><a href="#cb32-155" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb32-156"><a href="#cb32-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-157"><a href="#cb32-157" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> lookslike <span class="sc">%&gt;%</span> <span class="fu">top_n</span>(<span class="dv">20</span>, text.similarity) <span class="sc">%&gt;%</span></span>
<span id="cb32-158"><a href="#cb32-158" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> text.similarity, <span class="at">y =</span> <span class="fu">reorder</span>(text.term, text.similarity))) <span class="sc">+</span></span>
<span id="cb32-159"><a href="#cb32-159" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb32-160"><a href="#cb32-160" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb32-161"><a href="#cb32-161" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"similarity score"</span>,</span>
<span id="cb32-162"><a href="#cb32-162" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb32-163"><a href="#cb32-163" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 similarity scores with 'text'+'analysis'+'software' embeddings"</span> ) <span class="sc">+</span></span>
<span id="cb32-164"><a href="#cb32-164" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb32-165"><a href="#cb32-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-166"><a href="#cb32-166" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span>
<span id="cb32-167"><a href="#cb32-167" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-168"><a href="#cb32-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-169"><a href="#cb32-169" aria-hidden="true" tabindex="-1"></a><span class="fu">## A Word2Vec embeddings analysis (cbow)</span></span>
<span id="cb32-170"><a href="#cb32-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-173"><a href="#cb32-173" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-174"><a href="#cb32-174" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: word2vec-cbow</span></span>
<span id="cb32-175"><a href="#cb32-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-176"><a href="#cb32-176" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb32-177"><a href="#cb32-177" aria-hidden="true" tabindex="-1"></a>modelcbow <span class="ot">&lt;-</span> <span class="fu">word2vec</span>(<span class="at">x =</span> <span class="fu">tolower</span>(data_embeddings<span class="sc">$</span>combined_text),</span>
<span id="cb32-178"><a href="#cb32-178" aria-hidden="true" tabindex="-1"></a>                  <span class="at">type =</span> <span class="st">"cbow"</span>,</span>
<span id="cb32-179"><a href="#cb32-179" aria-hidden="true" tabindex="-1"></a>                  <span class="at">dim =</span> <span class="dv">500</span>,</span>
<span id="cb32-180"><a href="#cb32-180" aria-hidden="true" tabindex="-1"></a>                  <span class="at">iter =</span> <span class="dv">250</span>,</span>
<span id="cb32-181"><a href="#cb32-181" aria-hidden="true" tabindex="-1"></a>                  <span class="at">min_count =</span> <span class="dv">3</span>,</span>
<span id="cb32-182"><a href="#cb32-182" aria-hidden="true" tabindex="-1"></a>                  <span class="at">hs =</span> <span class="dv">1</span>,</span>
<span id="cb32-183"><a href="#cb32-183" aria-hidden="true" tabindex="-1"></a>                  <span class="at">verbose=</span><span class="dv">10</span>,</span>
<span id="cb32-184"><a href="#cb32-184" aria-hidden="true" tabindex="-1"></a>                  <span class="at">stopwords =</span> <span class="fu">stopwords</span>(<span class="st">"english"</span>),</span>
<span id="cb32-185"><a href="#cb32-185" aria-hidden="true" tabindex="-1"></a>                  <span class="at">window =</span> <span class="st">"7"</span>,</span>
<span id="cb32-186"><a href="#cb32-186" aria-hidden="true" tabindex="-1"></a>                  <span class="at">threads =</span> num_cores)</span>
<span id="cb32-187"><a href="#cb32-187" aria-hidden="true" tabindex="-1"></a>embedding1 <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(modelcbow)</span>
<span id="cb32-188"><a href="#cb32-188" aria-hidden="true" tabindex="-1"></a><span class="co">#embedding &lt;- predict(modelcbow, c("mining"), type = "embedding")</span></span>
<span id="cb32-189"><a href="#cb32-189" aria-hidden="true" tabindex="-1"></a><span class="co">#embedding</span></span>
<span id="cb32-190"><a href="#cb32-190" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-191"><a href="#cb32-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-194"><a href="#cb32-194" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-195"><a href="#cb32-195" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: plotly-embedding-cbow</span></span>
<span id="cb32-196"><a href="#cb32-196" aria-hidden="true" tabindex="-1"></a><span class="co">#| panel: center</span></span>
<span id="cb32-197"><a href="#cb32-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-198"><a href="#cb32-198" aria-hidden="true" tabindex="-1"></a><span class="co">#addition of the wordd embeddings "text", "analysis" and "software"</span></span>
<span id="cb32-199"><a href="#cb32-199" aria-hidden="true" tabindex="-1"></a>embedding_text <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, <span class="fu">c</span>(<span class="st">"text"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb32-200"><a href="#cb32-200" aria-hidden="true" tabindex="-1"></a>embedding_analysis <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, <span class="fu">c</span>(<span class="st">"analysis"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb32-201"><a href="#cb32-201" aria-hidden="true" tabindex="-1"></a>embedding_software <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, <span class="fu">c</span>(<span class="st">"software"</span>), <span class="at">type =</span> <span class="st">"embedding"</span>)</span>
<span id="cb32-202"><a href="#cb32-202" aria-hidden="true" tabindex="-1"></a>embedding_text_software <span class="ot">&lt;-</span> embedding_text <span class="sc">+</span> embedding_analysis <span class="sc">+</span> embedding_software</span>
<span id="cb32-203"><a href="#cb32-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-204"><a href="#cb32-204" aria-hidden="true" tabindex="-1"></a>lookslike <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelcbow, embedding_text_software, <span class="at">type =</span> <span class="st">"nearest"</span>, <span class="at">top_n =</span> <span class="dv">200</span>) <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">text.similarity =</span> <span class="fu">round</span>(text.similarity, <span class="dv">2</span>)) <span class="sc">%&gt;%</span> <span class="fu">select</span>(text.term, text.similarity)</span>
<span id="cb32-205"><a href="#cb32-205" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(lookslike, <span class="at">searchable =</span> <span class="cn">TRUE</span>, <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(</span>
<span id="cb32-206"><a href="#cb32-206" aria-hidden="true" tabindex="-1"></a>  <span class="at">maxWidth =</span> <span class="dv">200</span>,</span>
<span id="cb32-207"><a href="#cb32-207" aria-hidden="true" tabindex="-1"></a>  <span class="at">sortable =</span> <span class="cn">TRUE</span>,</span>
<span id="cb32-208"><a href="#cb32-208" aria-hidden="true" tabindex="-1"></a>  <span class="at">resizable =</span> <span class="cn">TRUE</span></span>
<span id="cb32-209"><a href="#cb32-209" aria-hidden="true" tabindex="-1"></a>))</span>
<span id="cb32-210"><a href="#cb32-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-211"><a href="#cb32-211" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> lookslike <span class="sc">%&gt;%</span> <span class="fu">top_n</span>(<span class="dv">20</span>, text.similarity) <span class="sc">%&gt;%</span></span>
<span id="cb32-212"><a href="#cb32-212" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> text.similarity, <span class="at">y =</span> <span class="fu">reorder</span>(text.term, text.similarity))) <span class="sc">+</span></span>
<span id="cb32-213"><a href="#cb32-213" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb32-214"><a href="#cb32-214" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb32-215"><a href="#cb32-215" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"similarity score"</span>,</span>
<span id="cb32-216"><a href="#cb32-216" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb32-217"><a href="#cb32-217" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 similarity scores with 'text'+'analysis'+'software' embeddings"</span> ) <span class="sc">+</span></span>
<span id="cb32-218"><a href="#cb32-218" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb32-219"><a href="#cb32-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-220"><a href="#cb32-220" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span>
<span id="cb32-221"><a href="#cb32-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-222"><a href="#cb32-222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-223"><a href="#cb32-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-224"><a href="#cb32-224" aria-hidden="true" tabindex="-1"></a>It seems that skip-gram performs better here. Skip-gram is better at capturing infrequent words, while CBOW is faster and has better representations for more frequent words. Also, skip-gram trains the context word from the center word, while CBOW trains the center word from the context word.</span>
<span id="cb32-225"><a href="#cb32-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-226"><a href="#cb32-226" aria-hidden="true" tabindex="-1"></a>More simply:</span>
<span id="cb32-227"><a href="#cb32-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-228"><a href="#cb32-228" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>CBOW model tries to predict the missing word given a set of context words;</span>
<span id="cb32-229"><a href="#cb32-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-230"><a href="#cb32-230" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Skip-gram model tries to predict the other context missing words given a word.</span>
<span id="cb32-231"><a href="#cb32-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-232"><a href="#cb32-232" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part of speech tagging with UDPipe (@straka-strakova-2017-tokenizing)</span></span>
<span id="cb32-233"><a href="#cb32-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-236"><a href="#cb32-236" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-237"><a href="#cb32-237" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: udpipe</span></span>
<span id="cb32-238"><a href="#cb32-238" aria-hidden="true" tabindex="-1"></a><span class="fu">udpipe_download_model</span>(<span class="at">language =</span> <span class="st">"english"</span>)</span>
<span id="cb32-239"><a href="#cb32-239" aria-hidden="true" tabindex="-1"></a>udmodel_english <span class="ot">&lt;-</span> <span class="fu">udpipe_load_model</span>(<span class="at">file =</span> <span class="st">"english-ewt-ud-2.5-191206.udpipe"</span>)</span>
<span id="cb32-240"><a href="#cb32-240" aria-hidden="true" tabindex="-1"></a>t1<span class="ot">=</span><span class="fu">Sys.time</span>()</span>
<span id="cb32-241"><a href="#cb32-241" aria-hidden="true" tabindex="-1"></a>UD <span class="ot">&lt;-</span> <span class="fu">udpipe_annotate</span>(udmodel_english, <span class="at">x=</span>data_embeddings<span class="sc">$</span>combined_text, <span class="at">trace =</span><span class="dv">40</span>, <span class="at">parallel.cores =</span> <span class="dv">6</span>)</span>
<span id="cb32-242"><a href="#cb32-242" aria-hidden="true" tabindex="-1"></a><span class="fu">Sys.time</span>()<span class="sc">-</span>t1</span>
<span id="cb32-243"><a href="#cb32-243" aria-hidden="true" tabindex="-1"></a>annotated_text <span class="ot">&lt;-</span> UD <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb32-244"><a href="#cb32-244" aria-hidden="true" tabindex="-1"></a><span class="co">#write.csv(annotated_text,"annotated_udpipe.csv")</span></span>
<span id="cb32-245"><a href="#cb32-245" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-246"><a href="#cb32-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-247"><a href="#cb32-247" aria-hidden="true" tabindex="-1"></a><span class="fu">## Top 20 nouns with UDPipe</span></span>
<span id="cb32-248"><a href="#cb32-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-251"><a href="#cb32-251" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-252"><a href="#cb32-252" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: plotly-udpipe</span></span>
<span id="cb32-253"><a href="#cb32-253" aria-hidden="true" tabindex="-1"></a>lemma <span class="ot">&lt;-</span> annotated_text <span class="sc">%&gt;%</span></span>
<span id="cb32-254"><a href="#cb32-254" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(upos <span class="sc">==</span> <span class="st">"NOUN"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb32-255"><a href="#cb32-255" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(lemma) <span class="sc">%&gt;%</span></span>
<span id="cb32-256"><a href="#cb32-256" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb32-257"><a href="#cb32-257" aria-hidden="true" tabindex="-1"></a>  <span class="fu">top_n</span>(<span class="dv">20</span>)</span>
<span id="cb32-258"><a href="#cb32-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-259"><a href="#cb32-259" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(lemma, <span class="fu">aes</span>(<span class="at">x =</span> n, <span class="at">y =</span> <span class="fu">reorder</span>(lemma, n))) <span class="sc">+</span></span>
<span id="cb32-260"><a href="#cb32-260" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb32-261"><a href="#cb32-261" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb32-262"><a href="#cb32-262" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb32-263"><a href="#cb32-263" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Lemma"</span>) <span class="sc">+</span></span>
<span id="cb32-264"><a href="#cb32-264" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 Most Frequent Nouns"</span>) <span class="sc">+</span></span>
<span id="cb32-265"><a href="#cb32-265" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb32-266"><a href="#cb32-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-267"><a href="#cb32-267" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span>
<span id="cb32-268"><a href="#cb32-268" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-269"><a href="#cb32-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-270"><a href="#cb32-270" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part of speech tagging with Trankit (@nguyen2021trankit)</span></span>
<span id="cb32-271"><a href="#cb32-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-274"><a href="#cb32-274" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-275"><a href="#cb32-275" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: trankit</span></span>
<span id="cb32-276"><a href="#cb32-276" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> trankit <span class="im">import</span> Pipeline</span>
<span id="cb32-277"><a href="#cb32-277" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb32-278"><a href="#cb32-278" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pandas <span class="im">import</span> json_normalize</span>
<span id="cb32-279"><a href="#cb32-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-280"><a href="#cb32-280" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data_for_embeddings.csv"</span>)</span>
<span id="cb32-281"><a href="#cb32-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-282"><a href="#cb32-282" aria-hidden="true" tabindex="-1"></a><span class="co"># initialize a pipeline for English</span></span>
<span id="cb32-283"><a href="#cb32-283" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> Pipeline(<span class="st">'english'</span>)</span>
<span id="cb32-284"><a href="#cb32-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-285"><a href="#cb32-285" aria-hidden="true" tabindex="-1"></a><span class="co">#test = p.posdep(df.loc[:5]['combined_text'][1])</span></span>
<span id="cb32-286"><a href="#cb32-286" aria-hidden="true" tabindex="-1"></a><span class="co">#testdf = pd.DataFrame(pd.json_normalize(test['sentences'], 'tokens'))</span></span>
<span id="cb32-287"><a href="#cb32-287" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb32-288"><a href="#cb32-288" aria-hidden="true" tabindex="-1"></a><span class="co">#pos = p.posdep(all)</span></span>
<span id="cb32-289"><a href="#cb32-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-290"><a href="#cb32-290" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame()  </span>
<span id="cb32-291"><a href="#cb32-291" aria-hidden="true" tabindex="-1"></a><span class="co">#part of speech tagging</span></span>
<span id="cb32-292"><a href="#cb32-292" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> df[<span class="st">'combined_text'</span>]:</span>
<span id="cb32-293"><a href="#cb32-293" aria-hidden="true" tabindex="-1"></a>    pos <span class="op">=</span> p.posdep(text)</span>
<span id="cb32-294"><a href="#cb32-294" aria-hidden="true" tabindex="-1"></a>    pos_df <span class="op">=</span> pd.json_normalize(pos[<span class="st">'sentences'</span>], <span class="st">'tokens'</span>)</span>
<span id="cb32-295"><a href="#cb32-295" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> pd.concat([results,pos_df])</span>
<span id="cb32-296"><a href="#cb32-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-297"><a href="#cb32-297" aria-hidden="true" tabindex="-1"></a><span class="co">#lemmatization</span></span>
<span id="cb32-298"><a href="#cb32-298" aria-hidden="true" tabindex="-1"></a>results_lemma <span class="op">=</span> pd.DataFrame()  </span>
<span id="cb32-299"><a href="#cb32-299" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> df[<span class="st">'combined_text'</span>]:</span>
<span id="cb32-300"><a href="#cb32-300" aria-hidden="true" tabindex="-1"></a>    lemma <span class="op">=</span> p.lemmatize(text)</span>
<span id="cb32-301"><a href="#cb32-301" aria-hidden="true" tabindex="-1"></a>    lemma_df <span class="op">=</span> pd.json_normalize(lemma[<span class="st">'sentences'</span>], <span class="st">'tokens'</span>)</span>
<span id="cb32-302"><a href="#cb32-302" aria-hidden="true" tabindex="-1"></a>    results_lemma <span class="op">=</span> pd.concat([results_lemma,lemma_df])</span>
<span id="cb32-303"><a href="#cb32-303" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-304"><a href="#cb32-304" aria-hidden="true" tabindex="-1"></a><span class="co">#join both data frames</span></span>
<span id="cb32-305"><a href="#cb32-305" aria-hidden="true" tabindex="-1"></a>results_complete <span class="op">=</span> pd.concat([results, results_lemma[<span class="st">'text'</span>].rename(<span class="st">"lemma"</span>)], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb32-306"><a href="#cb32-306" aria-hidden="true" tabindex="-1"></a>results_complete[<span class="st">"lemma"</span>] <span class="op">=</span> results_complete[<span class="st">"text"</span>]</span>
<span id="cb32-307"><a href="#cb32-307" aria-hidden="true" tabindex="-1"></a><span class="co">#results_lemma.to_csv("lemmas_trankit.csv")</span></span>
<span id="cb32-308"><a href="#cb32-308" aria-hidden="true" tabindex="-1"></a><span class="co">#results_complete.to_csv("annotated_trankit.csv")</span></span>
<span id="cb32-309"><a href="#cb32-309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-310"><a href="#cb32-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-311"><a href="#cb32-311" aria-hidden="true" tabindex="-1"></a><span class="fu">## Top 20 nouns with Trankit</span></span>
<span id="cb32-312"><a href="#cb32-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-315"><a href="#cb32-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-316"><a href="#cb32-316" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: plotly-trankit</span></span>
<span id="cb32-317"><a href="#cb32-317" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb32-318"><a href="#cb32-318" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb32-319"><a href="#cb32-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-320"><a href="#cb32-320" aria-hidden="true" tabindex="-1"></a><span class="co"># Load data from the "results" DataFrame</span></span>
<span id="cb32-321"><a href="#cb32-321" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure that "results" contains the same columns as the original CSV file</span></span>
<span id="cb32-322"><a href="#cb32-322" aria-hidden="true" tabindex="-1"></a><span class="co"># (e.g., "upos" and "lemma")</span></span>
<span id="cb32-323"><a href="#cb32-323" aria-hidden="true" tabindex="-1"></a>results_complete <span class="op">=</span> pd.read_csv(<span class="st">"annotated_trankit.csv"</span>)</span>
<span id="cb32-324"><a href="#cb32-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-325"><a href="#cb32-325" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter rows where 'upos' is equal to "NOUN"</span></span>
<span id="cb32-326"><a href="#cb32-326" aria-hidden="true" tabindex="-1"></a>noun_data <span class="op">=</span> results_complete[results_complete[<span class="st">'upos'</span>] <span class="op">==</span> <span class="st">'NOUN'</span>]</span>
<span id="cb32-327"><a href="#cb32-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-328"><a href="#cb32-328" aria-hidden="true" tabindex="-1"></a><span class="co"># Group by 'lemma' and count the number of occurrences</span></span>
<span id="cb32-329"><a href="#cb32-329" aria-hidden="true" tabindex="-1"></a>top_nouns <span class="op">=</span> noun_data[<span class="st">'lemma'</span>].value_counts().reset_index()</span>
<span id="cb32-330"><a href="#cb32-330" aria-hidden="true" tabindex="-1"></a>top_nouns.columns <span class="op">=</span> [<span class="st">'lemma'</span>, <span class="st">'n'</span>]</span>
<span id="cb32-331"><a href="#cb32-331" aria-hidden="true" tabindex="-1"></a>top_nouns <span class="op">=</span> top_nouns.head(<span class="dv">20</span>)</span>
<span id="cb32-332"><a href="#cb32-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-333"><a href="#cb32-333" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a chart using Plotly Express</span></span>
<span id="cb32-334"><a href="#cb32-334" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">"fig"</span> <span class="kw">not</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb32-335"><a href="#cb32-335" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> px.scatter(top_nouns, x<span class="op">=</span><span class="st">'n'</span>, y<span class="op">=</span><span class="st">'lemma'</span>, color<span class="op">=</span><span class="st">'lemma'</span>,</span>
<span id="cb32-336"><a href="#cb32-336" aria-hidden="true" tabindex="-1"></a>                     labels<span class="op">=</span>{<span class="st">'n'</span>: <span class="st">'Frequency'</span>, <span class="st">'lemma'</span>: <span class="st">'Lemma'</span>},</span>
<span id="cb32-337"><a href="#cb32-337" aria-hidden="true" tabindex="-1"></a>                     title<span class="op">=</span><span class="st">'Top 20 Most Frequent Nouns'</span>)</span>
<span id="cb32-338"><a href="#cb32-338" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-339"><a href="#cb32-339" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Customize the chart's style</span></span>
<span id="cb32-340"><a href="#cb32-340" aria-hidden="true" tabindex="-1"></a>    fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">12</span>, opacity<span class="op">=</span><span class="fl">0.6</span>),</span>
<span id="cb32-341"><a href="#cb32-341" aria-hidden="true" tabindex="-1"></a>                      selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>))</span>
<span id="cb32-342"><a href="#cb32-342" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-343"><a href="#cb32-343" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(title_x<span class="op">=</span><span class="fl">0.5</span>, title_font<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">20</span>))</span>
<span id="cb32-344"><a href="#cb32-344" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(template<span class="op">=</span><span class="st">"plotly_white"</span>)</span>
<span id="cb32-345"><a href="#cb32-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-346"><a href="#cb32-346" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the chart</span></span>
<span id="cb32-347"><a href="#cb32-347" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.show()</span></span>
<span id="cb32-348"><a href="#cb32-348" aria-hidden="true" tabindex="-1"></a><span class="co">#fig.write_html("top_20_nouns_trankit_python.html")</span></span>
<span id="cb32-349"><a href="#cb32-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-350"><a href="#cb32-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-351"><a href="#cb32-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-352"><a href="#cb32-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-353"><a href="#cb32-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-354"><a href="#cb32-354" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part of speech tagging with Stanza (@qi2020stanza)</span></span>
<span id="cb32-355"><a href="#cb32-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-358"><a href="#cb32-358" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb32-359"><a href="#cb32-359" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: stanza</span></span>
<span id="cb32-360"><a href="#cb32-360" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> stanza</span>
<span id="cb32-361"><a href="#cb32-361" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb32-362"><a href="#cb32-362" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb32-363"><a href="#cb32-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-364"><a href="#cb32-364" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the Stanza model</span></span>
<span id="cb32-365"><a href="#cb32-365" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> stanza.Pipeline(lang<span class="op">=</span><span class="st">'en'</span>, processors<span class="op">=</span><span class="st">'tokenize, mwt, pos, lemma, ner'</span>, use_gpu<span class="op">=</span><span class="va">True</span>, tokenize_pretokenized<span class="op">=</span><span class="va">False</span>, tokenize_no_ssplit<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-366"><a href="#cb32-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-367"><a href="#cb32-367" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the DataFrame from the CSV file</span></span>
<span id="cb32-368"><a href="#cb32-368" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data_for_embeddings.csv"</span>)</span>
<span id="cb32-369"><a href="#cb32-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-370"><a href="#cb32-370" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty DataFrame to store annotated data</span></span>
<span id="cb32-371"><a href="#cb32-371" aria-hidden="true" tabindex="-1"></a>annotated_df <span class="op">=</span> pd.DataFrame()</span>
<span id="cb32-372"><a href="#cb32-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-373"><a href="#cb32-373" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> text <span class="kw">in</span> tqdm(df[<span class="st">'combined_text'</span>], desc<span class="op">=</span><span class="st">"Processing Texts"</span>):</span>
<span id="cb32-374"><a href="#cb32-374" aria-hidden="true" tabindex="-1"></a>    doc <span class="op">=</span> nlp(text)</span>
<span id="cb32-375"><a href="#cb32-375" aria-hidden="true" tabindex="-1"></a>    dicts <span class="op">=</span> doc.to_dict()</span>
<span id="cb32-376"><a href="#cb32-376" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-377"><a href="#cb32-377" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert the dictionary into a temporary DataFrame</span></span>
<span id="cb32-378"><a href="#cb32-378" aria-hidden="true" tabindex="-1"></a>    temp_df <span class="op">=</span> pd.DataFrame(dicts[<span class="dv">0</span>])</span>
<span id="cb32-379"><a href="#cb32-379" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-380"><a href="#cb32-380" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Append data from the temporary DataFrame to annotated_df while ignoring the index</span></span>
<span id="cb32-381"><a href="#cb32-381" aria-hidden="true" tabindex="-1"></a>    annotated_df <span class="op">=</span> pd.concat([annotated_df, temp_df], ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb32-382"><a href="#cb32-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-383"><a href="#cb32-383" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment the line below to save the annotated data to a CSV file</span></span>
<span id="cb32-384"><a href="#cb32-384" aria-hidden="true" tabindex="-1"></a><span class="co"># annotated_df.to_csv("annotated_stanza.csv")</span></span>
<span id="cb32-385"><a href="#cb32-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-386"><a href="#cb32-386" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb32-387"><a href="#cb32-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-388"><a href="#cb32-388" aria-hidden="true" tabindex="-1"></a><span class="fu">## Top 20 nouns with Stanza</span></span>
<span id="cb32-389"><a href="#cb32-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-392"><a href="#cb32-392" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb32-393"><a href="#cb32-393" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: plotly-stanza</span></span>
<span id="cb32-394"><a href="#cb32-394" aria-hidden="true" tabindex="-1"></a>annotation_stanza <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"annotated_stanza.csv"</span>)</span>
<span id="cb32-395"><a href="#cb32-395" aria-hidden="true" tabindex="-1"></a>lemma <span class="ot">&lt;-</span> annotation_stanza <span class="sc">%&gt;%</span></span>
<span id="cb32-396"><a href="#cb32-396" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(upos <span class="sc">==</span> <span class="st">"NOUN"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb32-397"><a href="#cb32-397" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(lemma) <span class="sc">%&gt;%</span></span>
<span id="cb32-398"><a href="#cb32-398" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb32-399"><a href="#cb32-399" aria-hidden="true" tabindex="-1"></a>  <span class="fu">top_n</span>(<span class="dv">20</span>)</span>
<span id="cb32-400"><a href="#cb32-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-401"><a href="#cb32-401" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(lemma, <span class="fu">aes</span>(<span class="at">x =</span> n, <span class="at">y =</span> <span class="fu">reorder</span>(lemma, n))) <span class="sc">+</span></span>
<span id="cb32-402"><a href="#cb32-402" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"royalblue"</span>) <span class="sc">+</span></span>
<span id="cb32-403"><a href="#cb32-403" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb32-404"><a href="#cb32-404" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb32-405"><a href="#cb32-405" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Lemma"</span>) <span class="sc">+</span></span>
<span id="cb32-406"><a href="#cb32-406" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Top 20 Most Frequent Nouns"</span>) <span class="sc">+</span></span>
<span id="cb32-407"><a href="#cb32-407" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb32-408"><a href="#cb32-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-409"><a href="#cb32-409" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplotly</span>(fig)</span>
<span id="cb32-410"><a href="#cb32-410" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>