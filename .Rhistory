chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model)
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
print(f"\nCreating BERTopic visualizations in the `images/{embeddings_model}` folder.")
# list of embeddings models
list_embeddings = ["all-mpnet-base-v2", "all-mpnet-base-v1"]
# create a list to store model information
table_data = []
topic_models = {}
# loop through the list of embeddings models and create topic_model + viz in images
for embeddings_model in list_embeddings:
print(f"\nCreating BERTopics with the {embeddings_model} Sentence-Transformers pretrained model.")
topic_model = create_bertopic(docs_marketing, embeddings_model, 5, 13)
print(f"\nCreating BERTopic visualizations in the `images/{embeddings_model}` folder.")
visualize_bertopic(topic_model, embeddings_model)
chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model)
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
# list of embeddings models
list_embeddings = ["all-mpnet-base-v2", "all-mpnet-base-v1"]
# create a list to store model information
table_data = []
topic_models = {}
# loop through the list of embeddings models and create topic_model + viz in images
for embeddings_model in list_embeddings:
print(f"\nCreating BERTopics with the {embeddings_model} Sentence-Transformers pretrained model.")
topic_model = create_bertopic(docs_marketing, embeddings_model, 5, 13)
print(f"\nCreating BERTopic visualizations in the `images/{embeddings_model}` folder.")
visualize_bertopic(topic_model, embeddings_model)
chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model)
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
model_name+"14"
def generate_topics_table(topic_model):
# get topic information from the model
topics_info = topic_model.get_topic_info()
# Check if topics_info is empty or None
if topics_info is None or topics_info.empty:
return "No topics found."
# convert the data into a list
data_as_list = topics_info.values.tolist()
# get column names as headers
headers = topics_info.columns.tolist()
# generate the table in HTML format
table = tabulate(data_as_list, headers, tablefmt='html')
return table
def visualize_bertopic(topic_model, model_name, nr_topics):
# create the "images" folder if it doesn't exist already
if not os.path.exists("images"):
os.makedirs("images")
# create a subfolder for the specific topic model
model_folder = os.path.join("images", model_name+str(nr_topics))
# create the model folder if it doesn't exist already
if not os.path.exists(model_folder):
os.makedirs(model_folder)
else:
# delete existing files in the model folder if it exists
for file in os.listdir(model_folder):
os.remove(os.path.join(model_folder, file))
# generate topics information table
topics_table = generate_topics_table(topic_model)
with open(os.path.join(model_folder, 'table_topics.html'), 'w') as f:
f.write(topics_table)
# visualize topics
fig_topics = topic_model.visualize_topics()
fig_topics.write_html(os.path.join(model_folder, "topicsinfo.html"))
# visualize hierarchy
fig_hierarchy = topic_model.visualize_hierarchy()
fig_hierarchy.write_html(os.path.join(model_folder, "hierarchy.html"))
# visualize hierarchical topics
hierarchical_topics = topic_model.hierarchical_topics(docs_marketing)
fig_hierarchical_topics = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)
fig_hierarchical_topics.write_html(os.path.join(model_folder, "hierarchical.html"))
# visualize the bar chart
fig_barchart = topic_model.visualize_barchart(width=300, height=300, n_words=10, topics=None, top_n_topics=20)
fig_barchart.write_html(os.path.join(model_folder, "barchart.html"))
# visualize the heatmap
fig_heatmap = topic_model.visualize_heatmap()
fig_heatmap.write_html(os.path.join(model_folder, "heatmap.html"))
# topics over time
years =  df['year'].to_list()
topics_over_time = topic_model.topics_over_time(docs_marketing, years)
fig_topics_over_time = topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20, normalize_frequency=True)
fig_topics_over_time.write_html(os.path.join(model_folder, "topicsovertime.html"))
def create_bertopic(docs, embeddings_model, min_topic_size, nr_topics):
# initialize a count-based tf-idf transformer
ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)
# initialize a sentence transformer model for embeddings
sentence_model = SentenceTransformer(embeddings_model, device='cuda')
# generate embeddings for the input documents
embeddings = sentence_model.encode(docs, show_progress_bar=True)
# create a bertopic model with specified parameters
topic_model = BERTopic(
ctfidf_model=ctfidf_model,
calculate_probabilities=True,
verbose=True,
min_topic_size=min_topic_size,
nr_topics=nr_topics
)
# fit the bertopic model to the input documents and embeddings
topics, probs = topic_model.fit_transform(docs, embeddings)
# update the vectorizer model used by bertopic
updated_vectorizer_model = CountVectorizer(stop_words="english", ngram_range=(1, 3), min_df=0.05)
topic_model.update_topics(docs, vectorizer_model=updated_vectorizer_model)
# return the trained bertopic model
return topic_model
#topic_model_test = create_bertopic(docs_marketing, "allenai-specter", 5, 13)
#model_name = "test"
#visualize_bertopic(topic_model_test, model_name)
# list of embeddings models
list_embeddings = ["all-mpnet-base-v2", "all-mpnet-base-v1"]
# create a list to store model information
table_data = []
topic_models = {}
# loop through the list of embeddings models and create topic_model + viz in images
for embeddings_model in list_embeddings:
print(f"\nCreating BERTopics with the {embeddings_model} Sentence-Transformers pretrained model.")
topic_model = create_bertopic(docs_marketing, embeddings_model, 5, 13)
print(f"\nCreating BERTopic visualizations in the `images\{embeddings_model}` folder.")
visualize_bertopic(topic_model, embeddings_model, 13)
chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model)
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
print(f"{nr_topics + nr_topics")
print(f"{nr_topics + nr_topics"})
print(f"{nr_topics + nr_topics"})
print(f"{nr_topics}{nr_topics}")
print(f"{embeddings_model}{embeddings_model}")
print(f"{embeddings_model+embeddings_model}")
print(f"{embeddings_model+   embeddings_model}")
print(f"{embeddings_model+ '  '  embeddings_model}")
print(f"{embeddings_model     +   embeddings_model}")
print(f"{embeddings_modelembeddings_model}")
print(f"{embeddings_model embeddings_model}")
print(f"{embeddings_model +embeddings_model}")
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}` folder.")
nb_topics = 13
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}_{nbtopics}topics` folder.")
nb_topics = 13
nbtopics = 13
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}_{nbtopics}topics` folder.")
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}-{nbtopics}topics` folder.")
def generate_topics_table(topic_model):
# get topic information from the model
topics_info = topic_model.get_topic_info()
# Check if topics_info is empty or None
if topics_info is None or topics_info.empty:
return "No topics found."
# convert the data into a list
data_as_list = topics_info.values.tolist()
# get column names as headers
headers = topics_info.columns.tolist()
# generate the table in HTML format
table = tabulate(data_as_list, headers, tablefmt='html')
return table
def visualize_bertopic(topic_model, model_name, nr_topics):
# create the "images" folder if it doesn't exist already
if not os.path.exists("images"):
os.makedirs("images")
# create a subfolder for the specific topic model
model_folder = os.path.join("images", model_name+"-"+str(nr_topics)+"topics")
# create the model folder if it doesn't exist already
if not os.path.exists(model_folder):
os.makedirs(model_folder)
else:
# delete existing files in the model folder if it exists
for file in os.listdir(model_folder):
os.remove(os.path.join(model_folder, file))
# generate topics information table
topics_table = generate_topics_table(topic_model)
with open(os.path.join(model_folder, 'table_topics.html'), 'w') as f:
f.write(topics_table)
# visualize topics
fig_topics = topic_model.visualize_topics()
fig_topics.write_html(os.path.join(model_folder, "topicsinfo.html"))
# visualize hierarchy
fig_hierarchy = topic_model.visualize_hierarchy()
fig_hierarchy.write_html(os.path.join(model_folder, "hierarchy.html"))
# visualize hierarchical topics
hierarchical_topics = topic_model.hierarchical_topics(docs_marketing)
fig_hierarchical_topics = topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)
fig_hierarchical_topics.write_html(os.path.join(model_folder, "hierarchical.html"))
# visualize the bar chart
fig_barchart = topic_model.visualize_barchart(width=300, height=300, n_words=10, topics=None, top_n_topics=20)
fig_barchart.write_html(os.path.join(model_folder, "barchart.html"))
# visualize the heatmap
fig_heatmap = topic_model.visualize_heatmap()
fig_heatmap.write_html(os.path.join(model_folder, "heatmap.html"))
# topics over time
years =  df['year'].to_list()
topics_over_time = topic_model.topics_over_time(docs_marketing, years)
fig_topics_over_time = topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20, normalize_frequency=True)
fig_topics_over_time.write_html(os.path.join(model_folder, "topicsovertime.html"))
def create_bertopic(docs, embeddings_model, min_topic_size, nr_topics):
# initialize a count-based tf-idf transformer
ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)
# initialize a sentence transformer model for embeddings
sentence_model = SentenceTransformer(embeddings_model, device='cuda')
# generate embeddings for the input documents
embeddings = sentence_model.encode(docs, show_progress_bar=True)
# create a bertopic model with specified parameters
topic_model = BERTopic(
ctfidf_model=ctfidf_model,
calculate_probabilities=True,
verbose=True,
min_topic_size=min_topic_size,
nr_topics=nr_topics
)
# fit the bertopic model to the input documents and embeddings
topics, probs = topic_model.fit_transform(docs, embeddings)
# update the vectorizer model used by bertopic
updated_vectorizer_model = CountVectorizer(stop_words="english", ngram_range=(1, 3), min_df=0.05)
topic_model.update_topics(docs, vectorizer_model=updated_vectorizer_model)
# return the trained bertopic model
return topic_model
#topic_model_test = create_bertopic(docs_marketing, "allenai-specter", 5, 13)
#model_name = "test"
#visualize_bertopic(topic_model_test, model_name)
# list of embeddings models
list_embeddings = ["all-mpnet-base-v2", "all-mpnet-base-v1"]
# create a list to store model information
table_data = []
topic_models = {}
nbtopics = 13
# loop through the list of embeddings models and create topic_model + viz in images
for embeddings_model in list_embeddings:
print(f"\nCreating BERTopics with the {embeddings_model} Sentence-Transformers pretrained model.")
topic_model = create_bertopic(docs_marketing, embeddings_model, 5, 13)
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}-{nbtopics}topics` folder.")
visualize_bertopic(topic_model, embeddings_model, 13)
chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model)
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
nbmintopicsize = 5
# list of embeddings models
list_embeddings = ["all-mpnet-base-v2", "all-mpnet-base-v1"]
# create a list to store model information
table_data = []
topic_models = {}
#nbtopics is the number of topics we want to create/reduce to
#nbmintopicsize is the minimum number of documents to form a topic
nbtopics = 13
nbmintopicsize = 5
# loop through the list of embeddings models and create topic_model + viz in images
for embeddings_model in list_embeddings:
print(f"\nCreating BERTopics with the {embeddings_model} Sentence-Transformers pretrained model.")
topic_model = create_bertopic(docs_marketing, embeddings_model, nbmintopicsize, nbtopics)
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}-{nbtopics}topics` folder.")
visualize_bertopic(topic_model, embeddings_model, nbtopics)
chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model)
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
# list of embeddings models
list_embeddings = ["all-mpnet-base-v2", "all-mpnet-base-v1"]
# create a list to store model information
table_data = []
topic_models = {}
#nbtopics is the number of topics we want to create/reduce to
#nbmintopicsize is the minimum number of documents to form a topic
nbtopics = 13
nbmintopicsize = 5
# loop through the list of embeddings models and create topic_model + viz in images
for embeddings_model in list_embeddings:
print(f"\nCreating BERTopics with the {embeddings_model} Sentence-Transformers pretrained model.")
topic_model = create_bertopic(docs_marketing, embeddings_model, nbmintopicsize, nbtopics)
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}-{nbtopics}topics` folder.")
visualize_bertopic(topic_model, embeddings_model, nbtopics)
chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model)
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
View(topic_model)
def create_bertopic(docs, embeddings_model, min_topic_size, nr_topics):
# initialize a count-based tf-idf transformer
ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)
# initialize a sentence transformer model for embeddings
sentence_model = SentenceTransformer(embeddings_model, device='cuda')
# generate embeddings for the input documents
embeddings = sentence_model.encode(docs, show_progress_bar=True)
# create a bertopic model with specified parameters
topic_model = BERTopic(
ctfidf_model=ctfidf_model,
calculate_probabilities=True,
verbose=True,
min_topic_size=min_topic_size,
nr_topics=nr_topics
)
# fit the bertopic model to the input documents and embeddings
topics, probs = topic_model.fit_transform(docs, embeddings)
# update the vectorizer model used by bertopic
# `min_df` is the minimum document frequency for terms (words or n-grams) in the CountVectorizer.
# it specifies the minimum percentage of documents a term must appear in to be included in the vectorization.
updated_vectorizer_model = CountVectorizer(stop_words="english", ngram_range=(1, 3), min_df=0.03)
topic_model.update_topics(docs, vectorizer_model=updated_vectorizer_model)
# return the trained bertopic model
return topic_model
#topic_model_test = create_bertopic(docs_marketing, "allenai-specter", 5, 13)
#model_name = "test"
#visualize_bertopic(topic_model_test, model_name)
model_folder = os.path.join("images", embeddings_model+"-"+str(nbtopics)+"topics")
#09/26/2023 -----------------------------------------
#to-do  clean code : embeddings are charged twice for viz purposes (document viz) because it is loaded a first time in the create_bertopic function and again in the loop
#---------------------------------------------------
# list of embeddings models
list_embeddings = ["all-mpnet-base-v2", "all-mpnet-base-v1"]
# create a list to store model information
table_data = []
topic_models = {}
#nbtopics is the number of topics we want to create/reduce to
#nbmintopicsize is the minimum number of documents to form a topic
nbtopics = 13
nbmintopicsize = 5
# loop through the list of embeddings models and create topic_model + viz in images
for embeddings_model in list_embeddings:
print(f"\nCreating BERTopics with the {embeddings_model} Sentence-Transformers pretrained model.")
topic_model = create_bertopic(docs_marketing, embeddings_model, nbmintopicsize, nbtopics)
print(f"\nCreating BERTopic visualizations in the `images\\{embeddings_model}-{nbtopics}topics` folder.")
visualize_bertopic(topic_model, embeddings_model, nbtopics)
chargedmodel = SentenceTransformer(embeddings_model, device='cuda')
# visualize the documents
model_folder = os.path.join("images", embeddings_model+"-"+str(nbtopics)+"topics")
embeddings = chargedmodel.encode(docs_marketing, show_progress_bar=False)
fig_documents = topic_model.visualize_documents(docs_marketing, embeddings=embeddings)
fig_documents.write_html(os.path.join(model_folder, "documents_topics.html"))
# to summarize embeddings' models
dimensions =  chargedmodel.get_sentence_embedding_dimension()
max_tokens = chargedmodel.max_seq_length
# Store the topic_model in the dictionary with the embeddings name as key
topic_models[embeddings_model] = topic_model
# add model information to the table data list
table_data.append([embeddings_model, dimensions, max_tokens])
# table headers
headers = ["Embeddings Model", "Dimensions", "Max Tokens"]
# title for the table, centered
table_title = "Summary of Embeddings Models used"
# create the table with centered title
table = tabulate(table_data, headers, tablefmt="pretty")
table_lines = table.split("\n")
table_lines.insert(0, table_title.center(len(table_lines[0])))
table_with_centered_title = "\n".join(table_lines)
# display the table with centered title
print("\n")
print(table_with_centered_title)
#sentence_model.max_seq_length
#sentence_model.get_sentence_embedding_dimension()
