year_ranges = [(None, 2013), (2013, 2017), (2018, 2021), (2022, 2023)]
# Initialize a list to store the results for each year period
result_dfs = []
# Iterate through the year ranges
for start_year, end_year in year_ranges:
if start_year is None:
# Filter articles before 2013
filtered_articles = list_articles[list_articles['year'] < end_year]
else:
# Filter articles within the specified year range
filtered_articles = list_articles[(list_articles['year'] >= start_year) & (list_articles['year'] <= end_year)]
# Create a list to store author pairs and their details for the current year period
author_pairs = []
# Group the filtered dataframe by article number and collect unique author IDs for each article
grouped = filtered_articles.groupby('entry_number')[['authid', 'authname']].agg(list).reset_index()
# Iterate through the grouped dataframe and find author pairs for each article
for _, row in grouped.iterrows():
entry_number = row['entry_number']
authors = row['authid']
authnames = row['authname']
if len(authors) == 1:
# Handle single authors by creating a self-relation
author_pairs.append((entry_number, authors[0], authors[0], authnames[0], authnames[0]))
elif len(authors) > 1:
# Create pairs of authors who have co-authored the article
author_combinations = list(combinations(range(len(authors)), 2))
for i, j in author_combinations:
author_pairs.append((entry_number, authors[i], authors[j], authnames[i], authnames[j]))
# Create the DataFrame with the additional 'entry_number' column for the current year period
result_df = pd.DataFrame(author_pairs, columns=['entry_number', 'authid1', 'authid2', 'authname1', 'authname2'])
# Append the result DataFrame to the list of results
result_dfs.append(result_df)
# Now, result_dfs contains DataFrames for each year period
# result_dfs[0] corresponds to articles before 2013
# result_dfs[1] corresponds to articles from 2013 to 2017
# result_dfs[2] corresponds to articles from 2018 to 2021
# result_dfs[3] corresponds to articles from 2022 to 2023
authors_before_2013 = result_dfs[0]
authors_2013_2017 = result_dfs[1]
authors_2018_2021 = result_dfs[2]
authors_2022_2023 = result_dfs[3]
test4 = calculate_edge_weights(result_dfs[3])
View(test4)
test4 = authors_2022_2023["authname1","authname2"]
View(authors_2022_2023)
test4 = authors_2022_2023["authname1","authname2"]
View(authors_2022_2023)
test4 = authors_2022_2023[["authname1","authname2"]]
View(test4)
collaboration_df = collaboration_df.groupby(["authname1","authname2"]), sort=False, as_index=False).sum()
collaboration_df = collaboration_df.groupby(["authname1","authname2"], sort=False, as_index=False).sum()
collaboration_df = pd.DataFrame(np.sort(test4.values, axis=1), columns=test4.columns)
collaboration_df = collaboration_df.groupby(["authname1","authname2"], sort=False, as_index=False).sum()
View(collaboration_df)
test4 = authors_2022_2023[["authname1","authname2"]]
collaboration_df = pd.DataFrame(np.sort(test4.values, axis=1), columns=test4.columns)
collaboration_df['value'] = 1
collaboration_df = collaboration_df.groupby(["authname1","authname2"], sort=False, as_index=False).sum()
View(collaboration_df)
def get_collaboration_df(df):
collaboration_df = df[["authname1","authname2"]]
collaboration_df = pd.DataFrame(np.sort(collaboration_df.values, axis=1), columns=collaboration_df.columns)
collaboration_df['value'] = 1
collaboration_df = collaboration_df.groupby(["authname1","authname2"], sort=False, as_index=False).sum()
return collaboration_df
graph_data_2022_2023 = get_collaboration_df(authors_2022_2023)
network_data_2022_2023 = get_collaboration_df(authors_2022_2023)
View(network_data_2022_2023)
import networkx as nx
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
pos = nx.spring_layout(G, k=0.5, iterations=50)
nx.draw(G, pos, node_size=10, alpha=0.5, node_color="blue", with_labels=False)
pos = nx.kaamada_kawai_layout(G)
pos = nx.kaamada_kawai_layout(G)
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue')
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)
import matplotlib.pyplot as plt
import networkx as nx
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)
write_csv2(network_data_2022_2023, "network_data_2022_2023.csv")
netwooork_data_2022_2023.write_csv2("network_data_2022_2023.csv")
network_data_2022_2023.write_csv2("network_data_2022_2023.csv")
network_data_2022_2023.to_csv("network_data_2022_2023.csv")
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos = pos)
from pyvis.network import Network
net = Network(notebook=True, width=1000, height=1000, bgcolor="#222222", font_color="white")
net.from_nx(G)
net.show()
net.show("network_2022_2023.html")
from pyvis.network import Network
net = Network(notebook=True, width=1000, height=1000, bgcolor="#222222", font_color="white")
net.from_nx(G)
net.show("network_2022_2023.html")
from pyvis.network import Network
net = Network(notebook=FALSE, width=1000, height=1000, bgcolor="#222222", font_color="white")
net.from_nx(G)
net.show("network_2022_2023.html")
from pyvis.network import Network
net = Network(notebook=TRUE, width=1000, height=1000, bgcolor="#222222", font_color="white")
net.from_nx(G)
net.show("network_2022_2023.html")
from pyvis.network import Network
net = Network(notebook=True, width=1000, height=1000, bgcolor="#222222", font_color="white")
net.from_nx(G)
net.show("network_2022_2023.html")
from pyvis.network import Network
net = Network(notebook=False, width=1000, height=1000, bgcolor="#222222", font_color="white")
net.from_nx(G)
net.show("network_2022_2023.html")
net.save_graph("network_2022_2023.html)
net.save_graph("network_2022_2023.html")
#| label: circular-layout
# Create a Network instance
net = Network(notebook=True, width=1000, height=1000, bgcolor="white", font_color="black")
# Assuming you have already created your network graph G
# Set the layout to 'circular' in Pyvis
net.barnes_hut(gravity=-8000, central_gravity=0.3, spring_length=100)
# Load your network graph into Pyvis
net.from_nx(G)
# Save the visualization to an HTML file
net.save_graph("network_2022_2023_circular.html")
#| label: circular-layout
# Create a Network instance
net = Network(notebook=True, width=1000, height=1000, bgcolor="white", font_color="black")
# Assuming you have already created your network graph G
# Set the layout to 'circular' in Pyvis
net.barnes_hut(gravity=-6000, central_gravity=0.3, spring_length=100)
# Load your network graph into Pyvis
net.from_nx(G)
# Save the visualization to an HTML file
net.save_graph("network_2022_2023_circular.html")
#| label: circular-layout
# Create a Network instance
net = Network(notebook=True, width=1000, height=1000, bgcolor="white", font_color="black")
# Assuming you have already created your network graph G
# Set the layout to 'circular' in Pyvis
net.barnes_hut(gravity=-10000, central_gravity=0.3, spring_length=100)
# Load your network graph into Pyvis
net.from_nx(G)
# Save the visualization to an HTML file
net.save_graph("network_2022_2023_circular.html")
#| label: circular-layout
# Create a Network instance
net = Network(notebook=True, width=1000, height=1000, bgcolor="white", font_color="black")
# Assuming you have already created your network graph G
# Set the layout to 'circular' in Pyvis
net.barnes_hut(gravity=-8000, central_gravity=0.8, spring_length=100)
# Load your network graph into Pyvis
net.from_nx(G)
# Save the visualization to an HTML file
net.save_graph("network_2022_2023_circular.html")
network.Network.set_options()
from pyvis.network import Network
net = Network(notebook=True, width=1400, height=1000, bgcolor="white", font_color="black")
net.show_buttons(filter_=['physics'])
net.from_nx(G)
network.Network.set_options()
net.Network.set_options()
node_degree = dict(G.degree())
node_degree
dict(G.degree())
View(node_degree)
View(node_degree)
nx.set_node_attributes(G, node_degree, 'degree')
nx.set_node_attributes(G, node_degree, 'degree')
net.from_nx(G)
pos = nx.kamada_kawai_layout(G)
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
net = Network(notebook=True, width=600, height=600, bgcolor="white", font_color="black")
net.show_buttons(filter_=['physics'])
node_degree = dict(G.degree())
nx.set_node_attributes(G, node_degree, 'size')
net.from_nx(G)
net.show("network_2022_2023.html")
nx.set_node_attributes(G, exp(node_degree), 'size')
import math
nx.set_node_attributes(G, exp(node_degree), 'size')
nx.set_node_attributes(G, math.exp(node_degree), 'size')
node_degree
node_size =  [math.exp(v) for v in node_degree.values()]
node_size
node_size =  [math.log(v) for v in node_degree.values()]
nx.set_node_attributes(G, math.exp(node_degree), 'size')
node_degree = dict(G.degree())
G.nodes[node]['size'] = math.exp(node_degree[node])
for node in G.nodes:
G.nodes[node]['size'] = math.exp(node_degree[node])
net.show("networks/network_2022_2023.html")
View(G)
G.node.size
G.nodes.size
G.node
G.nodes
G.nodes
View(G)
G.size
net.from_nx(G)
G.size
for node, degree in node_degree.items():
net.add_node(node, size=math.log(degree+1)*10, title=node)
net.from_nx(G)
net.show("networks/network_2022_2023.html")
import math
from pyvis.network import Network
net = Network(notebook=True, width=1600, height=1600, bgcolor="white", font_color="black")
net.show_buttons(filter_=['physics'])
node_degree = dict(G.degree())
for node, degree in node_degree.items():
net.add_node(node, size=math.log(degree+1)*10, title=node)
net.from_nx(G)
net.show("networks/network_2022_2023.html")
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
net = Network(notebook=True, width=1600, height=1600, bgcolor="white", font_color="black")
net.show_buttons(filter_=['physics'])
# Add nodes with calculated sizes
for node, size in node_sizes.items():
net.add_node(node, size=size)
node_sizes = {node: sum(G[node][neighbor]['value'] for neighbor in G.neighbors(node)) for node in G.nodes()}
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
node_sizes = {node: sum(G[node][neighbor]['value'] for neighbor in G.neighbors(node)) for node in G.nodes()}
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
#| label: network-visualization-pyvis
from pyvis.network import Network
net = Network(notebook=True, width=1600, height=1600, bgcolor="white", font_color="black")
net.show_buttons(filter_=['physics'])
# Add nodes with calculated sizes
for node, size in node_sizes.items():
net.add_node(node, size=size)
net.from_nx(G)
net.show("networks/network_2022_2023.html")
net.save_graph("networks/network_2022_2023.html")
#| label: network-visualization-pyvis
from pyvis.network import Network
net = Network(notebook=True,cdn_resources='remote', width=1600, height=1600, bgcolor="white", font_color="black")
net.show_buttons(filter_=['physics'])
# Add nodes with calculated sizes
for node, size in node_sizes.items():
net.add_node(node, size=size)
net.from_nx(G)
net.show("networks/network_2022_2023.html")
net.save_graph("networks/network_2022_2023.html")
View(list_articles)
node_sizes
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
View(G)
nodes.values
g.nodes
G.nodes
G.nodes.values
G.nodes.values()
G.edges.values
G.edges
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
#| label: introduction
cowsay::say("After researching the articles and references by making graphs to
better visualize the structure of the research. We want to focus
here on the authors, trying to understand how communities evolve over time.")
reticulate::repl_python()
#| label: load-libraries-python
#| echo: false
#Libraries
import pandas as pd
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt
from itertools import combinations
#Data
data = pd.read_csv("data_final.csv")
list_articles = pd.read_csv("nlp_full_data_final_18-08-2023.csv", sep=';', decimal=',')
list_articles = list_articles[list_articles['marketing'] == 1] #only marketing articles
# Merge the "topic" and "topic_name" columns from the "data" dataframe into "list_articles"
list_articles = list_articles.merge(data[['entry_number', 'topic', 'topic_name']], on='entry_number', how='left')
list_references = pd.read_csv("nlp_references_final_18-08-2023.csv", sep=';', decimal=',')
quit
#| label: load-libraries-r
library(tidyverse)
library(reactable)
list_articles <- read_csv2("nlp_full_data_final_18-08-2023.csv")
test <- list_articles %>%
group_by(authid) %>%
select(authid, authname, entry_number) %>%
mutate(n = n())
result <- test %>%
group_by(authid) %>%
filter(n_distinct(authname) > 1) %>%
distinct(authid, .keep_all = TRUE)
result %>% reactable()
number_duplicates <- nrow(result)
cat("There are ", number_duplicates, " authors registered with different names.")
#| label: change-data-authors
# Merge list_articles with result on the authid column
merged_df <- left_join(list_articles, result, by = "authid")
# Replace authname values in list_articles with those from result
list_articles$authname <- ifelse(!is.na(merged_df$authname.y), merged_df$authname.y, list_articles$authname)
# Write the updated dataframe to a CSV file
write_csv2(list_articles, "nlp_full_data_final_unique_author_names.csv")
#| label: check-unique-name-authors
test <- list_articles %>%
group_by(authid) %>%
select(authid, authname, entry_number) %>%
mutate(n = n())
result <- test %>%
group_by(authid) %>%
filter(n_distinct(authname) > 1) %>%
distinct(authid, .keep_all = TRUE) %>%
relocate(entry_number)
result %>% reactable()
reticulate::repl_python()
#| label: network-authors
# Define the year ranges
year_ranges = [(None, 2013), (2013, 2017), (2018, 2021), (2022, 2023)]
# Initialize a list to store the results for each year period
result_dfs = []
# Iterate through the year ranges
for start_year, end_year in year_ranges:
if start_year is None:
# Filter articles before 2013
filtered_articles = list_articles[list_articles['year'] < end_year]
else:
# Filter articles within the specified year range
filtered_articles = list_articles[(list_articles['year'] >= start_year) & (list_articles['year'] <= end_year)]
# Create a list to store author pairs and their details for the current year period
author_pairs = []
# Group the filtered dataframe by article number and collect unique author IDs for each article
grouped = filtered_articles.groupby('entry_number')[['authid', 'authname']].agg(list).reset_index()
# Iterate through the grouped dataframe and find author pairs for each article
for _, row in grouped.iterrows():
entry_number = row['entry_number']
authors = row['authid']
authnames = row['authname']
if len(authors) == 1:
# Handle single authors by creating a self-relation
author_pairs.append((entry_number, authors[0], authors[0], authnames[0], authnames[0]))
elif len(authors) > 1:
# Create pairs of authors who have co-authored the article
author_combinations = list(combinations(range(len(authors)), 2))
for i, j in author_combinations:
author_pairs.append((entry_number, authors[i], authors[j], authnames[i], authnames[j]))
# Create the DataFrame with the additional 'entry_number' column for the current year period
result_df = pd.DataFrame(author_pairs, columns=['entry_number', 'authid1', 'authid2', 'authname1', 'authname2'])
# Append the result DataFrame to the list of results
result_dfs.append(result_df)
# Now, result_dfs contains DataFrames for each year period
# result_dfs[0] corresponds to articles before 2013
# result_dfs[1] corresponds to articles from 2013 to 2017
# result_dfs[2] corresponds to articles from 2018 to 2021
# result_dfs[3] corresponds to articles from 2022 to 2023
authors_before_2013 = result_dfs[0]
authors_2013_2017 = result_dfs[1]
authors_2018_2021 = result_dfs[2]
authors_2022_2023 = result_dfs[3]
View(filtered_articles)
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: function-calculate-edge-weights
#Sort the cases with a->b and b->a and sum them up => it creates weighted edges
def get_collaboration_df(df):
collaboration_df = df[["authname1","authname2"]]
collaboration_df = pd.DataFrame(np.sort(collaboration_df.values, axis=1), columns=collaboration_df.columns)
collaboration_df['value'] = 1
collaboration_df = collaboration_df.groupby(["authname1","authname2"], sort=False, as_index=False).sum()
return collaboration_df
# Example usage:
# Apply the function to one of your result DataFrames (e.g., result_dfs[0])
network_data_2022_2023 = get_collaboration_df(authors_2022_2023)
network_data_2022_2023.to_csv("network_data_2022_2023.csv")
#| label: network-creation
G = nx.from_pandas_edgelist(network_data_2022_2023, 'authname1', 'authname2', edge_attr='value', create_using=nx.Graph())
#| label: network-visualization
pos = nx.kamada_kawai_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
#| label: network-visualization-pyvis
from pyvis.network import Network
net = Network(notebook=True,cdn_resources='remote', width=1000, height=1000, bgcolor="white", font_color="black")
net.show_buttons(filter_=['physics'])
#Setting up node size attribute after edge weight
degree(G)
net.from_nx(G)
net.show("networks/network_2022_2023.html")
#net.save_graph("networks/network_2022_2023.html")
degree(G)
degree(G)
node.degree(G)
help(dict)
G.degree
G.get_edge_data
View(G)
G.degree()
test = G.degree()
type(test)
test = dict(test)
type(test)
degree_dict = nx.degree_centrality(G)
degree_dict
sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True)
sorted_degree = sorted(degree_dict.items(), key=lambda x: x[1], reverse=True)
sorted_degree
sorted_degree = sorted_degree[:20]
node, degree = zip(*sorted_degree)
fig = px.bar(x=node, y=degree, labels={'x':'Node', 'y':'Degree'})
import plotly.express as px
node, degree = zip(*sorted_degree)
fig = px.bar(x=node, y=degree, labels={'x':'Node', 'y':'Degree'})
fig = px.bar(x=node, y=degree, labels={'x':'Node', 'y':'Degree'})
fig.show()
fig.update_layout(title_text='Degree Centrality', title_x=0.5)
fig.update_yaxes(range=[0, 0.5])
fig.update_xaxes(tickangle=45)
fig.show()
fig = px.bar(x=node, y=degree, labels={'x':'Node', 'y':'Degree'})
#ehnance the layout
fig.update_layout(title_text='Degree Centrality', title_x=0.5)
fig.update_yaxes(range=[0, 0.5])
fig.update_xaxes(tickangle=45)
fig.show()
sorted_degree = sorted_degree[:20]
node, degree = zip(*sorted_degree)
#make fig prettier
fig = px.bar(x=node, y=degree, labels={'x':'Node', 'y':'Degree'})
#ehnance the layout
fig.show()
degree_dict[0]
degree_dict[0,1]
degree_dict[:10]
import networkx as nx
import random
import plotly.graph_objects as go
from IPython.display import display, clear_output
# Créer un graphe aléatoire pour simuler le réseau social
G = nx.erdos_renyi_graph(100, 0.1)
# Définir les paramètres du modèle
threshold = 0.1  # Seuil de diffusion
initial_node = random.choice(list(G.nodes()))  # Noeud initial
infected_nodes = set([initial_node])  # Noeuds infectés initiaux
# Liste pour stocker les étapes de diffusion pour la visualisation
diffusion_steps = []
# Simuler la diffusion en cascade
for node in nx.nodes(G):
if node not in infected_nodes:
neighbors = list(G.neighbors(node))
infected_neighbors = [n for n in neighbors if n in infected_nodes]
influence = sum([1 for n in infected_neighbors if random.random() < threshold])
if influence >= threshold * len(neighbors):
infected_nodes.add(node)
# Ajouter une copie du graphe à cette étape pour la visualisation
diffusion_steps.append(G.copy())
# Créer un graphique interactif avec Plotly
fig = go.Figure()
for step, graph in enumerate(diffusion_steps):
pos = nx.spring_layout(graph, seed=42)
node_colors = ['green' if node in infected_nodes else 'blue' for node in graph.nodes()]
edge_colors = ['red' if (u, v) in graph.edges() or (v, u) in graph.edges() else 'gray' for u, v in graph.edges()]
# Ajouter les nœuds et les arêtes au graphique Plotly
fig.add_trace(go.Scatter(x=[pos[node][0] for node in graph.nodes()],
y=[pos[node][1] for node in graph.nodes()],
mode='markers',
marker=dict(size=10, color=node_colors),
name=f'Étape {step}'))
for edge, color in zip(graph.edges(), edge_colors):
x0, y0 = pos[edge[0]]
x1, y1 = pos[edge[1]]
fig.add_trace(go.Scatter(x=[x0, x1],
y=[y0, y1],
mode='lines',
line=dict(width=2, color=color),
showlegend=False))
# Mettre à jour le graphique à chaque étape
clear_output(wait=True)
display(fig)
pyo.write_html(fig, file='graph_interactif.html')
pyo.write_html(fig, file='graph_interactif.html')
pyo.write_html(fig, file='graph_interactif.html')
import plotly.offline as pyo
pyo.write_html(fig, file='graph_interactif.html')
import plotly.offline as pyo
import plotly.offline as pyo
pyo.write_html(fig, file='graph_interactif.html')
sigma(G, start=0, end=1, max_iter=100, tol=1e-08, weight='weight', niter_delay=0, dim=2, random_seed=None, timeout=5, **kwargs)
nx.sigma(G, start=0, end=1, max_iter=100, tol=1e-08, weight='weight', niter_delay=0, dim=2, random_seed=None, timeout=5, **kwargs)
nx.sigma(G, start=0, end=1, max_iter=100, tol=1e-08, weight='weight', niter_delay=0, dim=2, random_seed=None, timeout=5)
nx.sigma(G, niter=100, nrand=10, seed=None)
