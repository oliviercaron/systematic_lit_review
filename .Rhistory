processed_texts = []
# Itération sur les lignes du DataFrame et application du traitement NLP
for text in df['combined_text']:
doc = nlp(text)
processed_texts
print(processed_texts)
View(df)
print(processed_texts)
nlp("haha test lololo")
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency')
nlp("haha test lololo")
nlp("haha test lololo I live in New York now")
nlp("haha test lololo I live in New York now but I will move to Paris soon")
nlp("haha test lololo I live in New York now but I will move to Paris soon with Olivier CARON")
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency')
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Création d'une liste pour stocker les résultats
processed_texts = []
# Itération sur les lignes du DataFrame et application du traitement NLP
for text in tqdm(df['combined_text'], desc="Processing Texts"):
doc = nlp(text)
processed_texts.append(doc)
View(processed_texts)
processed_texts
processed_texts.head(10)
processed_texts.head()
print(processed_texts.head(4))
testest = pd.DataFrame(processed_texts)
View(testest)
processed_texts[0]
type(processed_texts)
View(processed_texts)
processed_texts[0,1]
processed_texts[1]
processed_texts[2]
processed_texts[3]
processed_texts[1]
dicts = processed_texts.to_dict()
doc = nlp("Je m'appelle olivier et je suis vraiment sympa")
dicts = processed_texts.to_dict(doc)
dicts = doc.to_dict()
dicts
df = pd.DataFrame(dicts[0])
df
View(df)
df = processed_texts.to_dict()
type(processed_texts)
df = processed_texts.to_dict()
processed_texts[1]
processed_texts[145]
processed_texts[144]
nlp("haha test lololo I live in New York now but I will move to Paris soon with Olivier CARON")
doc = nlp("Je m'appelle olivier et je suis vraiment sympa")
View(doc)
dicts = doc.to_dict()
View(dicts)
df = pd.DataFrame(dicts[0])
df = processed_text.apprend(pd.DataFrame(dicts[0]))
df = dicts.apprend(pd.DataFrame(dicts[0]))
df
df = dicts.apprend(pd.DataFrame(dicts[0]))
df = dicts.append(pd.DataFrame(dicts[0]))
df
df = pd.DataFrame(dicts[0])
df
df_subset = df.head(5)
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency', use_gpu = True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à df
df = df.append(temp_df, ignore_index=True)
View(df)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency', use_gpu = True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à df
testdf = testdf.append(temp_df, ignore_index=True)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency', use_gpu = True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = []
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à df
testdf = testdf.append(temp_df, ignore_index=True)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency', use_gpu=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = []
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df, ignore_index=True)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency', use_gpu=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = []
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner,constituency', use_gpu=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
View(df_subset)
View(df_subset)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner')
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, no_sentence_splitter=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
doc = nlp("Je m'appelle olivier et je suis vraiment sympa. Ceci est un deuxième phrase.")
#transform stanza document into dic
dicts = doc.to_dict()
dicts
#transform dict into dataframe
View(df)
df = pd.DataFrame(dicts[0])
View(df)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, tokenize_no_ssplit=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, no_sentence_splitter=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, no_sentence_splitter=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.concat(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, no_sentence_splitter=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, no_sentence_splitter=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = testdf.append(temp_df)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, no_sentence_splitter=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = pd.concat([testdf, temp_df], ignore_index=True)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, tokenize_no_ssplit=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
# Sélectionnez les 5 premières lignes de df['combined_text']
df_subset = df.head(5)
testdf = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
testdf = pd.concat([testdf, temp_df], ignore_index=True)
# À la fin de la boucle, testdf contiendra les données traitées pour les 5 lignes sélectionnées
View(testdf)
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, tokenize_no_ssplit=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
annotated_df = pd.DataFrame()
for text in tqdm(df_subset['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
annotated_df = pd.concat([annotated_df, temp_df], ignore_index=True)
annotated_df.to_csv("annotated_stanza.csv")
import stanza
import pandas as pd
from tqdm import tqdm
# Initialisation du modèle Stanza
nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,ner', use_gpu=True, tokenize_pretokenized=False, tokenize_no_ssplit=True)
# Chargement du DataFrame depuis le fichier CSV
df = pd.read_csv("data_for_embeddings.csv")
annotated_df = pd.DataFrame()
for text in tqdm(df['combined_text'], desc="Processing Texts"):
doc = nlp(text)
dicts = doc.to_dict()
# Convertissez le dictionnaire en un DataFrame temporaire
temp_df = pd.DataFrame(dicts[0])
# Ajoutez les données du DataFrame temporaire à testdf en ignorant l'index
annotated_df = pd.concat([annotated_df, temp_df], ignore_index=True)
annotated_df.to_csv("annotated_stanza.csv")
View(annotated_df)
quit
View(annotated_text)
View(data_embeddings)
udpipe_download_model(language = "english")
udmodel_english <- udpipe_load_model(file = "english-ewt-ud-2.5-191206.udpipe")
udmodel_english <- udpipe_load_model(file = "english-ewt-ud-2.5-191206.udpipe")
udpipe_download_model(language = "english")
udmodel_english <- udpipe_load_model(file = "english-ewt-ud-2.5-191206.udpipe")
t1=Sys.time()
UD <- udpipe_annotate(udmodel_english, x=data_embeddings$combined_text, trace =40, parallel.cores = 6)
UD <- udpipe_annotate(udmodel_english, x=data_embeddings$combined_text, trace =40, parallel.cores = 6)
Sys.time()-t1
annotated_text <- UD %>% as.data.frame()
write.csv(annotated_text,"annotated_udpipe.csv")
reticulate::repl_python()
View(annotated_df)
quit
annotation_stanza <- read.csv("annotated_stanza.csv")
lemma <- annotation_stanza %>%
filter(upos == "NOUN") %>%
group_by(lemma) %>%
summarize(n = n()) %>%
top_n(20)
ggplot(lemma, aes(x = n, y = reorder(lemma, n))) +
geom_point(color = "royalblue") +
theme_minimal() +
labs(x = "Frequency",
y = "Lemma") +
ggtitle("Top 20 Most Frequent Nouns") +
theme(plot.title = element_text(hjust = 0.5))
View(annotated_text)
View(list_articles)
View(embedding)
---
title: "Systematic literature review"
---
title: "Systematic literature review"
---
title: "Systematic literature review"
---
title: "Systematic literature review"
---
title: "Systematic literature review"
---
title: "Systematic literature review"
---
title: "Systematic literature review"
---
title: "Systematic literature review"
