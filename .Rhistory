print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=9, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster', text=''", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster', text=''", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=15, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster', text=''", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=4, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster', text=''", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=5, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster', text=''", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster', text=''", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster', text='blabla', axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=8))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=50))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=1))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='black'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
df = pd.read_csv("data_for_embeddings.csv")
embeddings_bge = pd.read_csv('embeddings_bge.csv')
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
View(df)
df = pd.read_csv("data_for_embeddings.csv")
df = df[df['cited_by_count'] > 10]
embeddings_bge = pd.read_csv('embeddings_bge.csv')
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
df = pd.read_csv("data_for_embeddings.csv")
df = df[df['cited_by_count'] > 10]
df = df[df['citedby_count'] > 10]
df = pd.read_csv("data_for_embeddings.csv")
df = df[df['citedby_count'] > 10]
embeddings_bge = pd.read_csv('embeddings_bge.csv')
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
View(df)
df = df[df['citedby_count'] > 20]
df = df[df['citedby_count'] > 20]
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
embeddings_2D = pca.transform(embeddings_bge)
df = df[df['citedby_count'] > 20]
pca = PCA(n_components=2)
embeddings_2D = pca.transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='Dimensionality reduction with PCA and Clustering 2D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
df = df[df['citedby_count'] > 20]
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=8, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_2D)
# Évaluation du clustering
davies_bouldin = davies_bouldin_score(embeddings_2D, df['Cluster'])
silhouette = silhouette_score(embeddings_2D, df['Cluster'])
print('Davies-Bouldin Score:', davies_bouldin)
print('Silhouette Score:', silhouette)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 2D interactif avec Plotly
fig = px.scatter(df_vis, x='X', y='Y', color='Cluster'))
fig.update_traces(marker=dict(size=7))
fig.update_layout(title='2D plot with Dimensionality reduction with PCA and Clustering with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="2D_embeddings_PCA.html")
del df, pca, embeddings_2D, fig, df_vis
df = pd.read_csv("data_for_embeddings.csv")
embeddings_bge = pd.read_csv('embeddings_bge.csv')
df = df[df['citedby_count'] > 20]
pca = PCA(n_components=2)
embeddings_2D = pca.fit_transform(embeddings_bge)
df['X'] = embeddings_2D[:, 0]
df['X'] = embeddings_2D[:, 0]
embeddings_2D = pca.fit_transform(embeddings_bge)
df['X'] = embeddings_2D[:, 0]
df['X'] = embeddings_2D[:, 0]
df['Y'] = embeddings_2D[:, 1]
df = df[df['citedby_count'] > 20]
doc_marketing_sup20citations = df['combined_text']
sentence_model_bge = SentenceTransformer('BAAI/bge-large-en')
sentence_model_bge = SentenceTransformer('BAAI/bge-large-en',device='cuda')
embeddings_bge_sup20citations = sentence_model_bge.encode(doc_marketing_sup20citations, show_progress_bar=True, normalize_embeddings=True)
print("Torch version:",torch.__version__)
import torch
print("Torch version:",torch.__version__)
print("Is CUDA enabled?",torch.cuda.is_available())
print("Is CUDA enabled?",torch.cuda.is_available())
print(f"Is CUDA supported by this system?
{torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
# Storing ID of current CUDA device
cuda_id = torch.cuda.current_device()
print(f"ID of current CUDA device:
{torch.cuda.current_device()}")
print(f"Name of current CUDA device:
{torch.cuda.get_device_name(cuda_id)}")
print(f"Is CUDA supported by this system?
{torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
# Storing ID of current CUDA device
cuda_id = torch.cuda.current_device()
print(f"ID of current CUDA device:
{torch.cuda.current_device()}")
print(f"Name of current CUDA device:
