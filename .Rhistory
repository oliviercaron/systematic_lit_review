embeddings_3D[:, 2]
df['x'] = embeddings_3D[:, 0]
df['y'] = embeddings_3D[:, 1]
df['z'] = embeddings_3D[:, 2]
df = pd.read_csv("data_for_embeddings.csv")
embeddings_bge = pd.read_csv('embeddings_bge.csv')
tsne = TSNE(n_components=3, perplexity=30, n_iter=300)
embeddings_3D = tsne.fit_transform(embeddings_bge)
df['x'] = embeddings_3D[:, 0]
df['y'] = embeddings_3D[:, 1]
df['z'] = embeddings_3D[:, 2]
View(df)
clusterer = hdbscan.HDBSCAN(min_cluster_size=60, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_3D)
df_vis = df[['X', 'Y', 'Z', 'dc_creator', 'year', 'Cluster']]
df['cluster'] = clusterer.fit_predict(embeddings_3D)
df_vis = df[['x', 'x', 'z', 'dc_creator', 'year', 'cluster']]
fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
df_vis = df[['x', 'x', 'z', 'dc_creator', 'year', 'cluster']]
fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
import pandas as pd
from sklearn.decomposition import PCA
import hdbscan
import plotly.express as px
df = pd.read_csv("data_for_embeddings.csv")
embeddings_bge = pd.read_csv('embeddings_bge.csv')
tsne = TSNE(n_components=3, perplexity=30, n_iter=300)
embeddings_3D = tsne.fit_transform(embeddings_bge)
df['x'] = embeddings_3D[:, 0]
df['y'] = embeddings_3D[:, 1]
df['z'] = embeddings_3D[:, 2]
clusterer = hdbscan.HDBSCAN(min_cluster_size=60, metric='euclidean')
df['cluster'] = clusterer.fit_predict(embeddings_3D)
df_vis = df[['x', 'x', 'z', 'dc_creator', 'year', 'cluster']]
fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
import pandas as pd
import hdbscan
import plotly.express as px
from sklearn.manifold import TSNE
import plotly.io as pio
# Étape 1 : Réduction des dimensions avec t-SNE
tsne = TSNE(n_components=3, perplexity=30, n_iter=300)
embeddings_3D = tsne.fit_transform(embeddings_bge)
#embeddings_3D = pd.DataFrame(embeddings_3D, columns = ['X','Y','Z'])
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['x'] = embeddings_3D[:, 0]
df['y'] = embeddings_3D[:, 1]
df['z'] = embeddings_3D[:, 2]
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=60, metric='euclidean')
df['cluster'] = clusterer.fit_predict(embeddings_3D)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['x', 'x', 'z', 'dc_creator', 'year', 'cluster']]
# Étape 5 : Création du graphique 3D interactif avec Plotly
fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Clustering 3D with HDBSCAN using t-SNE')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="3D_embeddings_tsne.html")
import pandas as pd
import hdbscan
import plotly.express as px
from sklearn.decomposition import PCA
import plotly.io as pio
# Étape 1 : Réduction des dimensions avec PCA
pca = PCA(n_components=3)
embeddings_3D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_3D[:, 0]
df['Y'] = embeddings_3D[:, 1]
df['Z'] = embeddings_3D[:, 2]
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_3D)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'Z', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 3D interactif avec Plotly
fig = px.scatter_3d(df_vis, x='X', y='Y', z='Z', color='Cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Clustering 3D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="3D_embeddings.html")
reticulate::repl_python()
import pandas as pd
from sklearn.decomposition import PCA
import hdbscan
import plotly.express as px
df = pd.read_csv("data_for_embeddings.csv")
embeddings_bge = pd.read_csv('embeddings_bge.csv')
import pandas as pd
import hdbscan
import plotly.express as px
from sklearn.decomposition import PCA
import plotly.io as pio
df = pd.read_csv("data_for_embeddings.csv")
embeddings_bge = pd.read_csv('embeddings_bge.csv')
pca = PCA(n_components=3)
embeddings_3D = pca.fit_transform(embeddings_bge)
df['X'] = embeddings_3D[:, 0]
df['Y'] = embeddings_3D[:, 1]
df['Z'] = embeddings_3D[:, 2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
plt.figure(figsize=(16,10))
import plotlib
import matplotlibb
import matplotlib
import matplotlib as plt
plt.figure(figsize=(16,10))
import seaborn as sns
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(16,10))
sns.scatterplot(
x="X", y="Y",
hue="y",
palette=sns.color_palette("hls", 10),
data=df.loc[rndperm,:],
legend="full",
alpha=0.3
)
plt.figure(figsize=(16,10))
sns.scatterplot(
x="X", y="Y",
hue="y",
palette=sns.color_palette("hls", 10),
data=df.loc[rndperm,:],
legend=df_vis,
alpha=0.3
)
plt.figure(figsize=(16,10))
sns.scatterplot(
x="X", y="Y",
hue="y",
palette=sns.color_palette("hls", 10),
data=df_vis,
legend="full",
alpha=0.3
)
# Étape 1 : Réduction des dimensions avec PCA
pca = PCA(n_components=3)
embeddings_3D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_3D[:, 0]
df['Y'] = embeddings_3D[:, 1]
df['Z'] = embeddings_3D[:, 2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_3D)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'Z', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 3D interactif avec Plotly
fig = px.scatter_3d(df_vis, x='X', y='Y', z='Z', color='Cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Clustering 3D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="3D_embeddings_PCA.html")
plt.figure(figsize=(16,10))
sns.scatterplot(
x="X", y="Y",
hue="y",
palette=sns.color_palette("hls", 10),
data=df_vis,
legend="full",
alpha=0.3
)
plt.figure(figsize=(16,10))
fig = sns.scatterplot(
x="X", y="Y",
hue="y",
palette=sns.color_palette("hls", 10),
data=df_vis,
legend="full",
alpha=0.3
)
plt.figure(figsize=(16,10))
fig = sns.scatterplot(
x="X", y="Y",
hue="Y",
palette=sns.color_palette("hls", 10),
data=df_vis,
legend="full",
alpha=0.3
)
fig = fig.get_figure()
fig.savefig("out.html")
fig.savefig("out.svg")
plt.figure(figsize=(16,10))
fig = sns.scatterplot(
x="X", y="Y",
hue="cluster",
palette=sns.color_palette("hls", 10),
data=df_vis,
legend="full",
alpha=0.3
)
View(df_vis)
plt.figure(figsize=(16,10))
fig = sns.scatterplot(
x="X", y="Y",
hue="Cluster",
palette=sns.color_palette("hls", 10),
data=df_vis,
legend="full",
alpha=0.3
)
fig = fig.get_figure()
fig.savefig("out.svg")
topic_model.get_topic_info()
import pandas as pd
import hdbscan
import plotly.express as px
from sklearn.manifold import TSNE
import plotly.io as pio
# Étape 1 : Réduction des dimensions avec t-SNE
tsne = TSNE(n_components=3, perplexity=30, n_iter=300)
embeddings_3D = tsne.fit_transform(embeddings_bge)
#embeddings_3D = pd.DataFrame(embeddings_3D, columns = ['X','Y','Z'])
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['x'] = embeddings_3D[:, 0]
df['y'] = embeddings_3D[:, 1]
df['z'] = embeddings_3D[:, 2]
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=60, metric='euclidean')
df['cluster'] = clusterer.fit_predict(embeddings_3D)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['x', 'x', 'z', 'dc_creator', 'year', 'cluster']]
# Étape 5 : Création du graphique 3D interactif avec Plotly
fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Clustering 3D with HDBSCAN using t-SNE')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="3D_embeddings_TSNE.html")
import pandas as pd
import hdbscan
import plotly.express as px
from sklearn.manifold import TSNE
import plotly.io as pio
# Étape 1 : Réduction des dimensions avec t-SNE
tsne = TSNE(n_components=3, perplexity=30, n_iter=300)
embeddings_3D = tsne.fit_transform(embeddings_bge)
#embeddings_3D = pd.DataFrame(embeddings_3D, columns = ['X','Y','Z'])
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['x'] = embeddings_3D[:, 0]
df['y'] = embeddings_3D[:, 1]
df['z'] = embeddings_3D[:, 2]
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=60, metric='euclidean')
df['cluster'] = clusterer.fit_predict(embeddings_3D)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['x', 'x', 'z', 'dc_creator', 'year', 'cluster']]
# Étape 5 : Création du graphique 3D interactif avec Plotly
fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Clustering 3D with HDBSCAN using t-SNE')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="3D_embeddings_TSNE.html")
# Étape 1 : Réduction des dimensions avec PCA
pca = PCA(n_components=3)
embeddings_3D = pca.fit_transform(embeddings_bge)
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['X'] = embeddings_3D[:, 0]
df['Y'] = embeddings_3D[:, 1]
df['Z'] = embeddings_3D[:, 2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_3D)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['X', 'Y', 'Z', 'dc_creator', 'year', 'Cluster']]
# Étape 5 : Création du graphique 3D interactif avec Plotly
fig = px.scatter_3d(df_vis, x='X', y='Y', z='Z', color='Cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Clustering 3D with HDBSCAN')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="3D_embeddings_PCA.html")
plt.figure(figsize=(16,10))
fig = sns.scatterplot(
x="X", y="Y",
hue="Cluster",
palette=sns.color_palette("hls", 10),
data=df_vis,
legend="full",
alpha=0.3
)
fig = fig.get_figure()
fig.savefig("out.svg")
import pandas as pd
import hdbscan
import plotly.express as px
from sklearn.manifold import TSNE
import plotly.io as pio
# Étape 1 : Réduction des dimensions avec t-SNE
tsne = TSNE(n_components=3, perplexity=30, n_iter=300)
embeddings_3D = tsne.fit_transform(embeddings_bge)
#embeddings_3D = pd.DataFrame(embeddings_3D, columns = ['X','Y','Z'])
# Étape 2 : Coller les embeddings réduits au DataFrame df
df['x'] = embeddings_3D[:, 0]
df['y'] = embeddings_3D[:, 1]
df['z'] = embeddings_3D[:, 2]
# Étape 3 : Clustering avec HDBSCAN
clusterer = hdbscan.HDBSCAN(min_cluster_size=60, metric='euclidean')
df['cluster'] = clusterer.fit_predict(embeddings_3D)
# Étape 4 : Création d'un DataFrame pour la visualisation
df_vis = df[['x', 'x', 'z', 'dc_creator', 'year', 'cluster']]
# Étape 5 : Création du graphique 3D interactif avec Plotly
fig = px.scatter_3d(df_vis, x='x', y='y', z='z', color='cluster', text=df_vis.apply(lambda row: f"{row['dc_creator']}, {row['year']}", axis=1))
fig.update_traces(marker=dict(size=5))
fig.update_layout(title='Clustering 3D with HDBSCAN using t-SNE')
fig.update_layout(template="plotly_white")
fig.show()
pio.write_html(fig, file="3D_embeddings_TSNE.html")
time_start = time.time()
import pandas as pd
import hdbscan
import plotly.express as px
from sklearn.decomposition import PCA
import plotly.io as pio
import seaborn as sns
import matplotlib.pyplot as plt
time_start = time.time()
import time
time_start = time.time()
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))
df['tsne-2d-one'] = tsne_results[:,0]
df['tsne-2d-two'] = tsne_results[:,1]
lt.figure(figsize=(16,10))
sns.scatterplot(
x="tsne-2d-one", y="tsne-2d-two",
hue="y",
palette=sns.color_palette("hls", 10),
data=df,
legend="full",
alpha=0.3
)
plt.figure(figsize=(16,10))
sns.scatterplot(
x="tsne-2d-one", y="tsne-2d-two",
hue="y",
palette=sns.color_palette("hls", 10),
data=df,
legend="full",
alpha=0.3
)
View(tsne_results)
tsne_results['y']
plt.figure(figsize=(16,10))
sns.scatterplot(
x="tsne-2d-one", y="tsne-2d-two",
palette=sns.color_palette("hls", 10),
data=df,
legend="full",
alpha=0.3
)
View(df)
plt.savefig("tsne_2D.svg", format="svg")
from umap import UMAP
from umap import UMAP
import umap
df = pd.read_csv("data_for_embeddings.csv")
embeddings_bge = pd.read_csv('embeddings_bge.csv')
umap_model = umap.UMAP(n_neighbors=15, n_components=3, min_dist=0.1, random_state=42)
umap_embeddings = umap_model.fit_transform(embeddings_bge)
umap_model = umap(n_neighbors=15, n_components=3, min_dist=0.1, random_state=42)
umap_model = umap.UMAP(n_neighbors=15, n_components=3, min_dist=0.1, random_state=42)
umap_model = umap.UMAP(n_neighbors=15, n_components=3, min_dist=0.1, random_state=42)
umap_embeddings = umap_model.fit_transform(embeddings_bge)
umap_model = umap.UMAP(n_neighbors=15, n_components=3, min_dist=0.1, random_state=42)
import umap
umap_model = umap.UMAP()
import umap
umap_model = umap.UMAP(n_neighbors=15, n_components=3, min_dist=0.1, random_state=42)
import umap.umap_ as umap
import umap.umap_ as umap
umap_model = umap.UMAP(n_neighbors=15, n_components=3, min_dist=0.1, random_state=42)
umap_embeddings = umap_model.fit_transform(embeddings_bge)
umap_embeddings[:,0]
plt.scatter(u[:,0], u[:,1], c=data)
plt.title('UMAP embedding of random colours');
plt.savefig("umap.svg", format="svg")
from sklearn.metrics import davies_bouldin_score
davies_bouldin = davies_bouldin_score(embeddings_3D, df['Cluster'])
labels = df['Cluster']
labels = df['cluster']
clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_3D)
labels = df['Cluster']
davies_bouldin = davies_bouldin_score(embeddings_3D, labels)
davies_bouuldin
print(davies_bouldin)
davies_bouldin
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=60, n_iter=1000)
tsne_results = tsne.fit_transform(embeddings_bge)
df['tsne-2d-one'] = tsne_results[:,0]
df['tsne-2d-two'] = tsne_results[:,1]
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=60, n_iter=100)
tsne_results = tsne.fit_transform(embeddings_bge)
tsne = TSNE(n_components=2, verbose=1, perplexity=60, n_iter=250)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=60, n_iter=600)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=20, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=10, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=15, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=25, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
df['tsne-2d-one'] = tsne_results[:,0]
df['tsne-2d-two'] = tsne_results[:,1]
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)
tsne_results = tsne.fit_transform(embeddings_bge)
print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))
df['tsne-2d-one'] = tsne_results[:,0]
df['tsne-2d-two'] = tsne_results[:,1]
davies_bouldin = davies_bouldin_score(tsne_results, labels)
davies_bouldin
from sklearn.metrics import silhouette_score, silhouette_samples
silhouette_score(embeddings_3D, labels)
silhouette_score(embeddings_3D, labels)
davies_bouldin_score(embeddings_3D, labels)
silhouette_score(embeddings_3D, labels)
from yellowbrick.cluuster import SilhouetteVisualizer
from yellowbrick.cluster import SilhouetteVisualizer
davies_bouldin_score(embeddings_3D, labels)
silhouette_score(embeddings_3D, labels)
pca = PCA(n_components=3)
embeddings_3D = pca.fit_transform(embeddings_bge)
labels = df['Cluster']
davies_bouldin_score(embeddings_3D, labels)
silhouette_score(embeddings_3D, labels)
View(labels)
silhouette_score(embeddings_3D, labels)
davies_bouldin_score(embeddings_3D, labels)
pca = PCA(n_components=3)
embeddings_3D = pca.fit_transform(embeddings_bge)
labels = df['Cluster']
df['X'] = embeddings_3D[:, 0]
df['Y'] = embeddings_3D[:, 1]
df['Z'] = embeddings_3D[:, 2]
print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))
clusterer = hdbscan.HDBSCAN(min_cluster_size=10, metric='euclidean')
df['Cluster'] = clusterer.fit_predict(embeddings_3D)
davies_bouldin_score(embeddings_3D, df['Cluster'])
silhouette_score(embeddings_3D, df['Cluster'])
from sentence_transformers import SentenceTransformer
from sentence_transformers import SentenceTransformer
from bertopic import BERTopic
import numpy as np
import pandas as pd  # Ajout de l'importation de pandas
from sentence_transformers import SentenceTransformer
from bertopic import BERTopic
from bertopic import BERTopic
from sentence_transformers import SentenceTransformer
from bertopic import BERTopic
from bertopic import BERTopic
pip uninstall uumap
import numpy as np
from bertopic import BERTopic
op
from bertopic import BERTopic
from bertopic import BERTopic
from bertopic import BERTopic
from bertopic import BERTopic
pip install bertopic
from bertopic import BERTopic
