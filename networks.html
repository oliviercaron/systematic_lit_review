<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Olivier Caron">
<meta name="author" content="Christophe Benavent">
<meta name="dcterms.date" content="2023-10-17">

<title>Systematic literature review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="networks_files/libs/clipboard/clipboard.min.js"></script>
<script src="networks_files/libs/quarto-html/quarto.js"></script>
<script src="networks_files/libs/quarto-html/popper.min.js"></script>
<script src="networks_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="networks_files/libs/quarto-html/anchor.min.js"></script>
<link href="networks_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="networks_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="networks_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="networks_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="networks_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

<script src="networks_files/libs/core-js-2.5.3/shim.min.js"></script>
<script src="networks_files/libs/react-17.0.0/react.min.js"></script>
<script src="networks_files/libs/react-17.0.0/react-dom.min.js"></script>
<script src="networks_files/libs/reactwidget-1.0.0/react-tools.js"></script>
<script src="networks_files/libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<link href="networks_files/libs/reactable-0.4.4/reactable.css" rel="stylesheet">
<script src="networks_files/libs/reactable-binding-0.4.4/reactable.js"></script>
<script src="networks_files/libs/plotly-binding-4.10.2/plotly.js"></script>
<script src="networks_files/libs/typedarray-0.1/typedarray.min.js"></script>
<script src="networks_files/libs/jquery-3.5.1/jquery.min.js"></script>
<link href="networks_files/libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="networks_files/libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="networks_files/libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="networks_files/libs/plotly-main-2.11.1/plotly-latest.min.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
</head>

<body>

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Systematic literature review</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
            <p class="subtitle lead">A focus on authors, articles, references with networks</p>
                      </div>
  </div>
    
  <div class="quarto-title-meta-author">
    <div class="quarto-title-meta-heading">Authors</div>
    <div class="quarto-title-meta-heading">Affiliation</div>
    
      <div class="quarto-title-meta-contents">
      <p class="author">Olivier Caron </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              Paris Dauphine - PSL
            </p>
        </div>
        <div class="quarto-title-meta-contents">
      <p class="author">Christophe Benavent </p>
    </div>
      <div class="quarto-title-meta-contents">
          <p class="affiliation">
              Paris Dauphine - PSL
            </p>
        </div>
      </div>

  <div class="quarto-title-meta">

        
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 17, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#purpose" id="toc-purpose" class="nav-link active" data-scroll-target="#purpose"><span class="header-section-number">1</span> Purpose</a></li>
  <li><a href="#libraries-and-preparing-data" id="toc-libraries-and-preparing-data" class="nav-link" data-scroll-target="#libraries-and-preparing-data"><span class="header-section-number">2</span> Libraries and preparing data</a>
  <ul class="collapse">
  <li><a href="#summary-of-the-authors-data" id="toc-summary-of-the-authors-data" class="nav-link" data-scroll-target="#summary-of-the-authors-data"><span class="header-section-number">2.1</span> Summary of the authors data</a></li>
  <li><a href="#check-name-of-authors" id="toc-check-name-of-authors" class="nav-link" data-scroll-target="#check-name-of-authors"><span class="header-section-number">2.2</span> Check name of authors</a></li>
  <li><a href="#correct-the-duplicate-names" id="toc-correct-the-duplicate-names" class="nav-link" data-scroll-target="#correct-the-duplicate-names"><span class="header-section-number">2.3</span> Correct the duplicate names</a></li>
  <li><a href="#verification-of-duplicate-names" id="toc-verification-of-duplicate-names" class="nav-link" data-scroll-target="#verification-of-duplicate-names"><span class="header-section-number">2.4</span> Verification of duplicate names</a></li>
  </ul></li>
  <li><a href="#construct-the-dataframes-for-the-networks" id="toc-construct-the-dataframes-for-the-networks" class="nav-link" data-scroll-target="#construct-the-dataframes-for-the-networks"><span class="header-section-number">3</span> Construct the dataframes for the networks</a>
  <ul class="collapse">
  <li><a href="#create-the-dataframes-of-collaboration-between-authors-one-per-period" id="toc-create-the-dataframes-of-collaboration-between-authors-one-per-period" class="nav-link" data-scroll-target="#create-the-dataframes-of-collaboration-between-authors-one-per-period"><span class="header-section-number">3.1</span> Create the dataframes of collaboration between authors (one per period)</a></li>
  <li><a href="#sort-cases-with-a-b-and-b-a-and-create-weighted-edges" id="toc-sort-cases-with-a-b-and-b-a-and-create-weighted-edges" class="nav-link" data-scroll-target="#sort-cases-with-a-b-and-b-a-and-create-weighted-edges"><span class="header-section-number">3.2</span> Sort cases with a-&gt;b and b-&gt;a and create weighted edges</a></li>
  <li><a href="#get-information-about-authors" id="toc-get-information-about-authors" class="nav-link" data-scroll-target="#get-information-about-authors"><span class="header-section-number">3.3</span> Get information about authors</a></li>
  </ul></li>
  <li><a href="#co-authorship-networks" id="toc-co-authorship-networks" class="nav-link" data-scroll-target="#co-authorship-networks"><span class="header-section-number">4</span> Co-authorship networks</a>
  <ul class="collapse">
  <li><a href="#network-basic-visualization" id="toc-network-basic-visualization" class="nav-link" data-scroll-target="#network-basic-visualization"><span class="header-section-number">4.1</span> Network basic visualization</a></li>
  <li><a href="#network-visualization-with-pyvis" id="toc-network-visualization-with-pyvis" class="nav-link" data-scroll-target="#network-visualization-with-pyvis"><span class="header-section-number">4.2</span> Network visualization with Pyvis</a></li>
  <li><a href="#detect-communities-with-louvains-algorithm" id="toc-detect-communities-with-louvains-algorithm" class="nav-link" data-scroll-target="#detect-communities-with-louvains-algorithm"><span class="header-section-number">4.3</span> Detect communities with Louvain’s algorithm</a></li>
  <li><a href="#network-visualization-with-ipysigma-pliquehal-03903518v1" id="toc-network-visualization-with-ipysigma-pliquehal-03903518v1" class="nav-link" data-scroll-target="#network-visualization-with-ipysigma-pliquehal-03903518v1"><span class="header-section-number">4.4</span> Network visualization with ipysigma <span class="citation" data-cites="plique:hal-03903518v1">(Plique 2022)</span></a></li>
  <li><a href="#an-interesting-metric-the-graph-density" id="toc-an-interesting-metric-the-graph-density" class="nav-link" data-scroll-target="#an-interesting-metric-the-graph-density"><span class="header-section-number">4.5</span> An interesting metric: the graph density</a></li>
  </ul></li>
  <li><a href="#citations-networks" id="toc-citations-networks" class="nav-link" data-scroll-target="#citations-networks"><span class="header-section-number">5</span> Citations networks</a>
  <ul class="collapse">
  <li><a href="#data-preparation-and-summary" id="toc-data-preparation-and-summary" class="nav-link" data-scroll-target="#data-preparation-and-summary"><span class="header-section-number">5.1</span> Data preparation and summary</a></li>
  </ul></li>
  <li><a href="#construct-the-dataframes" id="toc-construct-the-dataframes" class="nav-link" data-scroll-target="#construct-the-dataframes"><span class="header-section-number">6</span> Construct the dataframes</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">




<section id="purpose" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="purpose"><span class="header-section-number">1</span> Purpose</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>cowsay<span class="sc">::</span><span class="fu">say</span>(<span class="st">"After researching the articles and references by making graphs to</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="st">better visualize the structure of the research. We want to focus</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="st">here on the authors, trying to understand how communities evolve over time."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
 -------------- 
After researching the articles and references by making graphs to
better visualize the structure of the research. We want to focus
here on the authors, trying to understand how communities evolve over time. 
 --------------
    \
      \
        \
            |\___/|
          ==) ^Y^ (==
            \  ^  /
             )=*=(
            /     \
            |     |
           /| | | |\
           \| | |_|/\
      jgs  //_// ___/
               \_)
  </code></pre>
</div>
</div>
</section>
<section id="libraries-and-preparing-data" class="level2 page-columns page-full" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="libraries-and-preparing-data"><span class="header-section-number">2</span> Libraries and preparing data</h2>
<section id="summary-of-the-authors-data" class="level3 page-columns page-full" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="summary-of-the-authors-data"><span class="header-section-number">2.1</span> Summary of the authors data</h3>
<div class="cell page-columns page-full">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: summary-authors-data</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| column: screen-inset-right</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reactable)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(skimr)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>list_articles <span class="ot">&lt;-</span> <span class="fu">read_csv2</span>(<span class="st">"nlp_full_data_final_18-08-2023.csv"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">marketing =</span> <span class="fu">as.logical</span>(marketing)) <span class="sc">%&gt;%</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">authid =</span> <span class="fu">as.character</span>(authid)) <span class="sc">%&gt;%</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">afid =</span> <span class="fu">as.character</span>(afid)) <span class="sc">%&gt;%</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">entry_number =</span> <span class="fu">as.character</span>(entry_number)) <span class="sc">%&gt;%</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">source_id =</span> <span class="fu">as.character</span>(source_id)) <span class="sc">%&gt;%</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">article_number =</span> <span class="fu">as.character</span>(article_number)) <span class="sc">%&gt;%</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">openaccess =</span> <span class="fu">as.logical</span>(openaccess))</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(list_articles) <span class="co">#%&gt;%</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="co">#filter(!skim_type %in% c("logical"))</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display column-screen-inset-right">
<table class="table table-sm table-striped small">
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">Name</td>
<td style="text-align: left;">list_articles</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of rows</td>
<td style="text-align: left;">1498</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of columns</td>
<td style="text-align: left;">54</td>
</tr>
<tr class="even">
<td style="text-align: left;">_______________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Column type frequency:</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">character</td>
<td style="text-align: left;">42</td>
</tr>
<tr class="odd">
<td style="text-align: left;">logical</td>
<td style="text-align: left;">5</td>
</tr>
<tr class="even">
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">7</td>
</tr>
<tr class="odd">
<td style="text-align: left;">________________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Group variables</td>
<td style="text-align: left;">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 28%">
<col style="width: 12%">
<col style="width: 16%">
<col style="width: 4%">
<col style="width: 6%">
<col style="width: 7%">
<col style="width: 10%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">min</th>
<th style="text-align: right;">max</th>
<th style="text-align: right;">empty</th>
<th style="text-align: right;">n_unique</th>
<th style="text-align: right;">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">entry_number</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">485</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">author_url</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">61</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1255</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">authid</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1255</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">orcid</td>
<td style="text-align: right;">1237</td>
<td style="text-align: right;">0.17</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">240</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">authname</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1241</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">surname</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1002</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">given_name</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1148</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">initials</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">275</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">afid</td>
<td style="text-align: right;">116</td>
<td style="text-align: right;">0.92</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">601</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">affiliation_url</td>
<td style="text-align: right;">116</td>
<td style="text-align: right;">0.92</td>
<td style="text-align: right;">68</td>
<td style="text-align: right;">69</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">601</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">affilname</td>
<td style="text-align: right;">116</td>
<td style="text-align: right;">0.92</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">103</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">600</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">affiliation_city</td>
<td style="text-align: right;">122</td>
<td style="text-align: right;">0.92</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">26</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">416</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">affiliation_country</td>
<td style="text-align: right;">117</td>
<td style="text-align: right;">0.92</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">64</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">continent</td>
<td style="text-align: right;">117</td>
<td style="text-align: right;">0.92</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">prism:url</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">485</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">dc:identifier</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">485</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">eid</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">485</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">dc:title</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">24</td>
<td style="text-align: right;">222</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">485</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">dc:creator</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">427</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">prism:publicationName</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">167</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">128</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">prism:issn</td>
<td style="text-align: right;">219</td>
<td style="text-align: right;">0.85</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">78</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">prism:eIssn</td>
<td style="text-align: right;">681</td>
<td style="text-align: right;">0.55</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">prism:volume</td>
<td style="text-align: right;">501</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">90</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">prism:issueIdentifier</td>
<td style="text-align: right;">673</td>
<td style="text-align: right;">0.55</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">19</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">prism:pageRange</td>
<td style="text-align: right;">325</td>
<td style="text-align: right;">0.78</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">390</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">prism:coverDate</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">190</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">prism:coverDisplayDate</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">22</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">230</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">prism:doi</td>
<td style="text-align: right;">52</td>
<td style="text-align: right;">0.97</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">37</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">462</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">dc:description</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">203</td>
<td style="text-align: right;">5086</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">483</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">prism:aggregationType</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">subtype</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">subtypeDescription</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">authkeywords</td>
<td style="text-align: right;">185</td>
<td style="text-align: right;">0.88</td>
<td style="text-align: right;">27</td>
<td style="text-align: right;">318</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">430</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">source_id</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">127</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">fund_no</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">24</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">79</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">freetoread.value.$</td>
<td style="text-align: right;">1132</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">freetoreadLabel.value.$</td>
<td style="text-align: right;">1132</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">fund_acr</td>
<td style="text-align: right;">1154</td>
<td style="text-align: right;">0.23</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">54</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">fund_sponsor</td>
<td style="text-align: right;">1141</td>
<td style="text-align: right;">0.24</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">94</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">64</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">pii</td>
<td style="text-align: right;">1316</td>
<td style="text-align: right;">0.12</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">57</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">article_number</td>
<td style="text-align: right;">1285</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">subjects_area</td>
<td style="text-align: right;">153</td>
<td style="text-align: right;">0.90</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">251</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">81</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: logical</strong></p>
<table class="table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">mean</th>
<th style="text-align: left;">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="citation" data-cites="_fa">(<a href="#ref-_fa" role="doc-biblioref"><strong>_fa?</strong></a>)</span></td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: left;">TRU: 1498</td>
</tr>
<tr class="even">
<td style="text-align: left;">afid.@_fa</td>
<td style="text-align: right;">116</td>
<td style="text-align: right;">0.92</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: left;">TRU: 1382</td>
</tr>
<tr class="odd">
<td style="text-align: left;">openaccess</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: left;">FAL: 1301, TRU: 197</td>
</tr>
<tr class="even">
<td style="text-align: left;">openaccessFlag</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: left;">FAL: 1301, TRU: 197</td>
</tr>
<tr class="odd">
<td style="text-align: left;">marketing</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">0.82</td>
<td style="text-align: left;">TRU: 1226, FAL: 272</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 22%">
<col style="width: 11%">
<col style="width: 15%">
<col style="width: 8%">
<col style="width: 6%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 5%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">sd</th>
<th style="text-align: right;">p0</th>
<th style="text-align: right;">p25</th>
<th style="text-align: right;">p50</th>
<th style="text-align: right;">p75</th>
<th style="text-align: right;">p100</th>
<th style="text-align: left;">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="citation" data-cites="seq">(<a href="#ref-seq" role="doc-biblioref"><strong>seq?</strong></a>)</span></td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.0</td>
<td style="text-align: right;">2.37</td>
<td style="text-align: right;">1.47</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">12</td>
<td style="text-align: left;">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">citedby_count</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.0</td>
<td style="text-align: right;">22.28</td>
<td style="text-align: right;">59.27</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">495</td>
<td style="text-align: left;">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author_count.@limit</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.0</td>
<td style="text-align: right;">100.00</td>
<td style="text-align: right;">0.00</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: left;">▁▁▇▁▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">author_count.@total</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.0</td>
<td style="text-align: right;">3.75</td>
<td style="text-align: right;">1.80</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">12</td>
<td style="text-align: left;">▇▅▁▁▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author_count</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.0</td>
<td style="text-align: right;">3.75</td>
<td style="text-align: right;">1.80</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">12</td>
<td style="text-align: left;">▇▅▁▁▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">year</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.0</td>
<td style="text-align: right;">2019.47</td>
<td style="text-align: right;">4.61</td>
<td style="text-align: right;">1992</td>
<td style="text-align: right;">2019</td>
<td style="text-align: right;">2021</td>
<td style="text-align: right;">2022</td>
<td style="text-align: right;">2023</td>
<td style="text-align: left;">▁▁▁▁▇</td>
</tr>
<tr class="odd">
<td style="text-align: left;">nref</td>
<td style="text-align: right;">153</td>
<td style="text-align: right;">0.9</td>
<td style="text-align: right;">63.94</td>
<td style="text-align: right;">44.92</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">32</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">85</td>
<td style="text-align: right;">311</td>
<td style="text-align: left;">▇▆▁▁▁</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="check-name-of-authors" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="check-name-of-authors"><span class="header-section-number">2.2</span> Check name of authors</h3>
<p>We need to check if there are more than one unique <code>authorname</code> per <code>authid</code>. If so, we need to change the different names of author to the same name in order to have the exact same node per author later in the network.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(authid, authname, entry_number) <span class="sc">%&gt;%</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n =</span> <span class="fu">n</span>())</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> test <span class="sc">%&gt;%</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">n_distinct</span>(authname) <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(authid, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>result <span class="sc">%&gt;%</span> <span class="fu">reactable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div class="reactable html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-168e0750a6c589bb7488" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-168e0750a6c589bb7488">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"authid":["57210597224","57189367543","56233503500","58193152000","7003743717","13805392100","55520009700","57192699976","57207932854","7004399351","55294413800","7101962114","26435082100","57113646300","7004664517","56699638600","55814461100","7005227018","57192993903","8327167000","7003609866","25637923200","57211430198","7004159593","57194864072"],"authname":["Lee J.k.","Luangrath A.W.","Villarroel Ordenes F.","Stupavsky I.","Moe W.W.","Schweidel D.A.","de Regt A.","Pitt C.","Cooper H.B.","Ewing M.T.","Rocklage M.D.","Tsao H.Y.","Campbell C.","Ozansoy Çadırcı T.","de Ruyter K.","Mulcahy R.","Álvarez G.P.J.","Pitt L.","Chavan G.","Fresneda J.E.","Allenby G.M.","van Laer T.","Bin Ahmadon M.A.","Kamakura W.A.","Lee C.C."],"entry_number":["3","19","23","39","56","56","62","67","94","94","101","104","104","106","116","129","136","214","244","249","273","322","347","397","439"],"n":[3,3,4,2,3,5,3,5,2,4,4,2,2,2,5,2,2,5,2,2,2,2,2,2,2]},"columns":[{"id":"authid","name":"authid","type":"character"},{"id":"authname","name":"authname","type":"character"},{"id":"entry_number","name":"entry_number","type":"character"},{"id":"n","name":"n","type":"numeric"}],"dataKey":"ddcb9a217f9be837f71c05576131a3bc"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>number_duplicates <span class="ot">&lt;-</span> <span class="fu">nrow</span>(result)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"There are "</span>, number_duplicates, <span class="st">" authors registered with different names."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are  25  authors registered with different names.</code></pre>
</div>
</div>
</section>
<section id="correct-the-duplicate-names" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="correct-the-duplicate-names"><span class="header-section-number">2.3</span> Correct the duplicate names</h3>
<p>Let’s correct that by using one property of the distinct function: the <code>.keep_all = TRUE</code> parameter. It keeps the first occurrence of each group, which is the first row encountered for each unique combination of <code>authid</code> and <code>authname</code>. It will be faster than manually changing the name of each author.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge list_articles with result on the authid column</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>merged_df <span class="ot">&lt;-</span> <span class="fu">left_join</span>(list_articles, result, <span class="at">by =</span> <span class="st">"authid"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace authname values in list_articles with those from result</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>list_articles<span class="sc">$</span>authname <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(<span class="sc">!</span><span class="fu">is.na</span>(merged_df<span class="sc">$</span>authname.y), merged_df<span class="sc">$</span>authname.y, list_articles<span class="sc">$</span>authname)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only marketing articles and filter "Erratum" type of publications (=correction)</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>list_articles <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span> </span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(marketing <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(subtypeDescription <span class="sc">!=</span> <span class="st">"Erratum"</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"There are"</span>, <span class="fu">n_distinct</span>(list_articles<span class="sc">$</span>entry_number), <span class="st">"articles and"</span>, <span class="fu">n_distinct</span>(list_articles<span class="sc">$</span>authname), <span class="st">"authors overall in the data."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 404 articles and 976 authors overall in the data.</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Write the updated dataframe to a CSV file </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">write_csv2</span>(list_articles, <span class="st">"nlp_full_data_final_unique_author_names.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>It is now done. We can check again if there are more than one unique <code>authorname</code> per <code>authid</code>.</p>
</section>
<section id="verification-of-duplicate-names" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="verification-of-duplicate-names"><span class="header-section-number">2.4</span> Verification of duplicate names</h3>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(authid, authname, entry_number) <span class="sc">%&gt;%</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n =</span> <span class="fu">n</span>())</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> test <span class="sc">%&gt;%</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">n_distinct</span>(authname) <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(authid, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">relocate</span>(entry_number)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>result <span class="sc">%&gt;%</span> <span class="fu">reactable</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div class="reactable html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-dae3126c4ff406ed99f8" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-dae3126c4ff406ed99f8">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"entry_number":[],"authid":[],"authname":[],"n":[]},"columns":[{"id":"entry_number","name":"entry_number","type":"character"},{"id":"authid","name":"authid","type":"character"},{"id":"authname","name":"authname","type":"character"},{"id":"n","name":"n","type":"numeric"}],"dataKey":"653c35af9b801b666f70290551abf231"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>It’s alright, we can now continue on constructing the data frames for the networks.</p>
</section>
</section>
<section id="construct-the-dataframes-for-the-networks" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="construct-the-dataframes-for-the-networks"><span class="header-section-number">3</span> Construct the dataframes for the networks</h2>
<section id="create-the-dataframes-of-collaboration-between-authors-one-per-period" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="create-the-dataframes-of-collaboration-between-authors-one-per-period"><span class="header-section-number">3.1</span> Create the dataframes of collaboration between authors (one per period)</h3>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>list_articles <span class="op">=</span>  pd.read_csv(<span class="st">"nlp_full_data_final_unique_author_names.csv"</span>, sep<span class="op">=</span><span class="st">';'</span>, decimal<span class="op">=</span><span class="st">','</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the year ranges</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>year_ranges <span class="op">=</span> [(<span class="va">None</span>, <span class="dv">2013</span>), (<span class="dv">2013</span>, <span class="dv">2017</span>), (<span class="dv">2018</span>, <span class="dv">2021</span>), (<span class="dv">2022</span>, <span class="dv">2023</span>)]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a list to store the results for each year period</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>result_dfs <span class="op">=</span> []</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through the year ranges</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> start_year, end_year <span class="kw">in</span> year_ranges:</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> start_year <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filter articles before 2013</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        filtered_articles <span class="op">=</span> list_articles[list_articles[<span class="st">'year'</span>] <span class="op">&lt;</span> end_year]</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filter articles within the specified year range</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        filtered_articles <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> start_year) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> end_year)]</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a list to store author pairs and their details for the current year period</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    author_pairs <span class="op">=</span> []</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Group the filtered dataframe by article number and collect unique author IDs for each article</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    grouped <span class="op">=</span> filtered_articles.groupby(<span class="st">'entry_number'</span>)[[<span class="st">'authid'</span>, <span class="st">'authname'</span>]].agg(<span class="bu">list</span>).reset_index()</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through the grouped dataframe and find author pairs for each article</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> grouped.iterrows():</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        entry_number <span class="op">=</span> row[<span class="st">'entry_number'</span>]</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>        authors <span class="op">=</span> row[<span class="st">'authid'</span>]</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        authnames <span class="op">=</span> row[<span class="st">'authname'</span>]</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(authors) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Handle single authors by creating a self-relation</span></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>            author_pairs.append((entry_number, authors[<span class="dv">0</span>], authors[<span class="dv">0</span>], authnames[<span class="dv">0</span>], authnames[<span class="dv">0</span>]))</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">len</span>(authors) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create pairs of authors who have co-authored the article</span></span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>            author_combinations <span class="op">=</span> <span class="bu">list</span>(combinations(<span class="bu">range</span>(<span class="bu">len</span>(authors)), <span class="dv">2</span>))</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, j <span class="kw">in</span> author_combinations:</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>                author_pairs.append((entry_number, authors[i], authors[j], authnames[i], authnames[j]))</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the DataFrame with the additional 'entry_number' column for the current year period</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(author_pairs, columns<span class="op">=</span>[<span class="st">'entry_number'</span>, <span class="st">'authid1'</span>, <span class="st">'authid2'</span>, <span class="st">'authname1'</span>, <span class="st">'authname2'</span>])</span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Append the result DataFrame to the list of results</span></span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>    result_dfs.append(result_df)</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, result_dfs contains DataFrames for each year period</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[0] corresponds to articles before 2013</span></span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[1] corresponds to articles from 2013 to 2017</span></span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[2] corresponds to articles from 2018 to 2021</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[3] corresponds to articles from 2022 to 2023</span></span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>authors_before_2013 <span class="op">=</span> result_dfs[<span class="dv">0</span>]</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>authors_2013_2017 <span class="op">=</span> result_dfs[<span class="dv">1</span>]</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>authors_2018_2021 <span class="op">=</span> result_dfs[<span class="dv">2</span>]</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>authors_2022_2023 <span class="op">=</span> result_dfs[<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="sort-cases-with-a-b-and-b-a-and-create-weighted-edges" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="sort-cases-with-a-b-and-b-a-and-create-weighted-edges"><span class="header-section-number">3.2</span> Sort cases with a-&gt;b and b-&gt;a and create weighted edges</h3>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the cases with a-&gt;b and b-&gt;a and sum them up =&gt; it creates weighted edges</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_collaboration_df(df):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    collaboration_df <span class="op">=</span> df[[<span class="st">"authname1"</span>,<span class="st">"authname2"</span>]]</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    collaboration_df <span class="op">=</span> pd.DataFrame(np.sort(collaboration_df.values, axis<span class="op">=</span><span class="dv">1</span>), columns<span class="op">=</span>collaboration_df.columns)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    collaboration_df[<span class="st">'value'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    collaboration_df <span class="op">=</span> collaboration_df.groupby([<span class="st">"authname1"</span>,<span class="st">"authname2"</span>], sort<span class="op">=</span><span class="va">False</span>, as_index<span class="op">=</span><span class="va">False</span>).<span class="bu">sum</span>()</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> collaboration_df</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to DataFrames</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>network_data_2022_2023 <span class="op">=</span> get_collaboration_df(authors_2022_2023)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>network_data_2022_2023.to_csv(<span class="st">"networks/csv/network_data_2022_2023.csv"</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>network_data_2018_2021 <span class="op">=</span> get_collaboration_df(authors_2018_2021)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>network_data_2018_2021.to_csv(<span class="st">"networks/csv/network_data_2018_2021.csv"</span>)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>network_data_2013_2017 <span class="op">=</span> get_collaboration_df(authors_2013_2017)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>network_data_2013_2017.to_csv(<span class="st">"networks/csv/network_data_2013_2017.csv"</span>)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>network_data_before_2013 <span class="op">=</span> get_collaboration_df(authors_before_2013)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>network_data_before_2013.to_csv(<span class="st">"networks/csv/network_data_before_2013.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="get-information-about-authors" class="level3" data-number="3.3">
<h3 data-number="3.3" class="anchored" data-anchor-id="get-information-about-authors"><span class="header-section-number">3.3</span> Get information about authors</h3>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sort_dict(<span class="bu">dict</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    sorted_dict <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> <span class="bu">sorted</span>(<span class="bu">dict</span>.items(), key<span class="op">=</span><span class="kw">lambda</span> item: item[<span class="dv">0</span>])}</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sorted_dict</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_author_info_by_period(list_articles, period):</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter the DataFrame based on the specified period</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> period <span class="op">==</span> <span class="st">"before-2013"</span>:</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[list_articles[<span class="st">'year'</span>] <span class="op">&lt;</span> <span class="dv">2013</span>]</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> period <span class="op">==</span> <span class="st">"2013-2017"</span>:</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> <span class="dv">2013</span>) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> <span class="dv">2017</span>)]</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> period <span class="op">==</span> <span class="st">"2018-2021"</span>:</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> <span class="dv">2018</span>) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> <span class="dv">2021</span>)]</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> period <span class="op">==</span> <span class="st">"2022-2023"</span>:</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> <span class="dv">2022</span>) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> <span class="dv">2023</span>)]</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Invalid period parameter. Please choose one of: 'before-2013', '2013-2017', '2018-2021', '2022-2023"</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dictionary to store affiliations and countries for each author</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    info_author <span class="op">=</span> {<span class="st">'affiliation'</span>: {}, <span class="st">'country'</span>: {}, <span class="st">'article'</span>: {}, <span class="st">'journal'</span>: {}}</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through the filtered DataFrame to collect affiliations and countries for each author</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> index, row <span class="kw">in</span> filtered_df.iterrows():</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        author_name <span class="op">=</span> row[<span class="st">'authname'</span>]</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        affiliation <span class="op">=</span> row[<span class="st">'affilname'</span>]</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>        country <span class="op">=</span> row[<span class="st">'affiliation_country'</span>]</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        article <span class="op">=</span> row[<span class="st">'dc:title'</span>]</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        journal <span class="op">=</span> row[<span class="st">'prism:publicationName'</span>]</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the affiliation is not NaN (i.e., a valid affiliation)</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(affiliation, <span class="bu">str</span>) <span class="kw">and</span> affiliation.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if the author already has an affiliation, and if the new one is not already included, then add it with "&amp;"</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'affiliation'</span>]:</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> affiliation <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'affiliation'</span>][author_name]:</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'affiliation'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> affiliation</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'affiliation'</span>][author_name] <span class="op">=</span> affiliation</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the country is not NaN (i.e., a valid country)</span></span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(country, <span class="bu">str</span>) <span class="kw">and</span> country.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if the author already has a country, and if the new one is not already included, then add it with "&amp;"</span></span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'country'</span>]:</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> country <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'country'</span>][author_name]:</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'country'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> country</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'country'</span>][author_name] <span class="op">=</span> country</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the article title is not NaN (i.e., a valid article title)</span></span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(article, <span class="bu">str</span>) <span class="kw">and</span> article.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if an author has multiple articles, if so add the new article with "&amp;"</span></span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'article'</span>]:</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> article <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'article'</span>][author_name]:</span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'article'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> article</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'article'</span>][author_name] <span class="op">=</span> article</span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the journal name (or conference name) is not NaN (i.e., a valid journal)</span></span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(journal, <span class="bu">str</span>) <span class="kw">and</span> journal.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if the author has published in multiple journals, if so add the new journal with "&amp;"</span></span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'journal'</span>]:</span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> journal <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'journal'</span>][author_name]:</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'journal'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> journal</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'journal'</span>][author_name] <span class="op">=</span> journal</span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dictionary that associates each author with their ln(total number of citations+1)+1</span></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We do +1 twice because if the result is 0, then the log is undefined.</span></span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We add another +1 to avoid having 0 values in the network.</span></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a>    citedby_dict <span class="op">=</span> filtered_df.groupby(<span class="st">'authname'</span>)[<span class="st">'citedby_count'</span>].<span class="bu">sum</span>() .to_dict()</span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>    <span class="co">#citedby_dict = filtered_df.groupby('authname')['citedby_count'].sum().apply(lambda x: np.log(x + 1) + 1).to_dict()</span></span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add the 'citedby_count' dictionary to the 'info_author' dictionary under the key 'citations'</span></span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>    info_author[<span class="st">'citations'</span>] <span class="op">=</span> citedby_dict</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the info_author dictionary containing both affiliation, country, and citations information</span></span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> info_author</span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a><span class="co"># How to use:</span></span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the period of interest: ("before-2013", "2013-2017", "2018-2021", or "2022-2023")</span></span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a><span class="co"># The function returns a dictionary with four keys: 'affiliation', 'country', 'article', 'journal', and 'citations'</span></span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a><span class="co"># The dictionaries are then used as attributes for the nodes in the network (see below)</span></span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>affilauthor_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a>affilauthor_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>affilauthor_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a>affilauthor_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a>countryauthor_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'country'</span>])</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>countryauthor_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'country'</span>])</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>countryauthor_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'country'</span>])</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>countryauthor_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'country'</span>])</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>citations_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>citations_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>citations_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb13-96"><a href="#cb13-96" aria-hidden="true" tabindex="-1"></a>citations_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb13-97"><a href="#cb13-97" aria-hidden="true" tabindex="-1"></a>article_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'article'</span>])</span>
<span id="cb13-98"><a href="#cb13-98" aria-hidden="true" tabindex="-1"></a>article_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'article'</span>])</span>
<span id="cb13-99"><a href="#cb13-99" aria-hidden="true" tabindex="-1"></a>article_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'article'</span>])</span>
<span id="cb13-100"><a href="#cb13-100" aria-hidden="true" tabindex="-1"></a>article_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'article'</span>])</span>
<span id="cb13-101"><a href="#cb13-101" aria-hidden="true" tabindex="-1"></a>journal_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'journal'</span>])</span>
<span id="cb13-102"><a href="#cb13-102" aria-hidden="true" tabindex="-1"></a>journal_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'journal'</span>])</span>
<span id="cb13-103"><a href="#cb13-103" aria-hidden="true" tabindex="-1"></a>journal_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'journal'</span>])</span>
<span id="cb13-104"><a href="#cb13-104" aria-hidden="true" tabindex="-1"></a>journal_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'journal'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="co-authorship-networks" class="level2 page-columns page-full" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="co-authorship-networks"><span class="header-section-number">4</span> Co-authorship networks</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.from_pandas_edgelist(network_data_2022_2023, <span class="st">'authname1'</span>, <span class="st">'authname2'</span>, edge_attr<span class="op">=</span><span class="st">'value'</span>, create_using<span class="op">=</span>nx.Graph())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="network-basic-visualization" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="network-basic-visualization"><span class="header-section-number">4.1</span> Network basic visualization</h3>
<p>This is a basic visualization done with the NetworkX library and matplotlib.</p>
<div class="cell" data-layout-align="center">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Visualization of the co-authorship network for the 2022-2023 period, created using NetworkX and matplotlib.</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">20</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.kamada_kawai_layout(G)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>nx.draw(G, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">'skyblue'</span>, edge_cmap<span class="op">=</span>plt.cm.Blues, pos<span class="op">=</span>pos)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;Figure size 2000x2000 with 0 Axes&gt;</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="networks_files/figure-html/network-visualization-1.png" class="img-fluid figure-img" width="1920"></p>
<figcaption class="figure-caption">Visualization of the co-authorship network for the 2022-2023 period, created using NetworkX and matplotlib.</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is not interactive and the result is not enlightening at all. We then decide to use <code>Pyvis</code> to create an interactive visualization.</p>
</div>
</div>
</section>
<section id="network-visualization-with-pyvis" class="level3 page-columns page-full" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="network-visualization-with-pyvis"><span class="header-section-number">4.2</span> Network visualization with Pyvis</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pyvis enables us to create interactive visualizations and modify the network layout in real time with the <code>net.show_buttons(filter_=['physics'])</code> command. This button then generates options to include in our code by using the <code>net.set_options()</code> function. <a href="https://pyvis.readthedocs.io/en/latest/tutorial.html#using-the-configuration-ui-to-dynamically-tweak-network-settings" title="button physics Pyvis">More information here</a>.</p>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-pyvis</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyvis.network <span class="im">import</span> Network</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> Network(notebook<span class="op">=</span><span class="va">True</span>, cdn_resources<span class="op">=</span><span class="st">'remote'</span>, width<span class="op">=</span><span class="dv">1500</span>, height<span class="op">=</span><span class="dv">900</span>, bgcolor<span class="op">=</span><span class="st">"white"</span>, font_color<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">#net.show_buttons(filter_=['physics'])</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>net.set_options(<span class="st">"""</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="st">const options = {</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="st">  "physics": {</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="st">    "forceAtlas2Based": {</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="st">      "gravitationalConstant": -13,</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="st">      "centralGravity": 0.015,</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="st">      "springLength": 70</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="st">    },</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="st">    "minVelocity": 0.75,</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="st">    "solver": "forceAtlas2Based"</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>node_degree <span class="op">=</span> <span class="bu">dict</span>(G.degree)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co">## Some values for nodes</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiply node sizes by two</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>node_degree_doubled <span class="op">=</span> {node: <span class="dv">2</span> <span class="op">*</span> degree <span class="cf">for</span> node, degree <span class="kw">in</span> node_degree.items()}</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>node_degree_centrality <span class="op">=</span> nx.degree_centrality(G)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>node_degree_betweenness <span class="op">=</span> nx.betweenness_centrality(G)</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>node_degree_closeness <span class="op">=</span> nx.closeness_centrality(G)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>node_degree_constraint <span class="op">=</span> nx.constraint(G)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the node attributes with the doubled sizes</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_doubled, <span class="st">'size'</span>)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_centrality, <span class="st">'centrality'</span>)</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_betweenness, <span class="st">'betweenness'</span>)</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_closeness, <span class="st">'closeness'</span>)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_constraint, <span class="st">'constraint'</span>)</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, affilauthor_2022_2023, <span class="st">'affiliation'</span>)</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, countryauthor_2022_2023, <span class="st">'country'</span>)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, citations_2022_2023, <span class="st">'citations'</span>)</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, article_2022_2023, <span class="st">'title'</span>)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, journal_2022_2023, <span class="st">'journal'</span>)</span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="co">#listnodes = net.nodes</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="co">#net.nodes.__getitem__(1)</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="co">#listnodes = net.nodes</span></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>net.from_nx(G)</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>net.show(<span class="st">"networks/authors/network_2022_2023_pyvis.html"</span>)</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<iframe width="1500" height="900" src="networks/authors/network_2022_2023_pyvis.html" title="Quarto Documentation" frameborder="0" class="column-page"></iframe>
</section>
<section id="detect-communities-with-louvains-algorithm" class="level3 page-columns page-full" data-number="4.3">
<h3 data-number="4.3" class="anchored" data-anchor-id="detect-communities-with-louvains-algorithm"><span class="header-section-number">4.3</span> Detect communities with Louvain’s algorithm</h3>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: community-detection-louvain</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> community <span class="im">as</span> community_louvain</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the best partition</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#dftest = pd.DataFrame(list(communities.items()), columns=['authname', 'community'])</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, communities, <span class="st">'group'</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-pyvis-louvain</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>com_net <span class="op">=</span> Network(notebook<span class="op">=</span><span class="va">True</span>, cdn_resources<span class="op">=</span><span class="st">'remote'</span>, width<span class="op">=</span><span class="dv">1500</span>, height<span class="op">=</span><span class="dv">900</span>, bgcolor<span class="op">=</span><span class="st">"white"</span>, font_color<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>com_net.set_options(<span class="st">"""</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="st">const options = {</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="st">  "physics": {</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="st">    "forceAtlas2Based": {</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="st">      "gravitationalConstant": -13,</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="st">      "centralGravity": 0.015,</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="st">      "springLength": 50</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="st">    },</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="st">    "minVelocity": 0.75,</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="st">    "solver": "forceAtlas2Based"</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>com_net.from_nx(G)</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>com_net.show(<span class="st">"networks/authors/network_2022_2023_louvain_pyvis.html"</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<iframe width="1500" height="900" src="networks/authors/network_2022_2023_louvain_pyvis.html" title="network_2022_2023_louvain" frameborder="0" class="column-page"></iframe>
</section>
<section id="network-visualization-with-ipysigma-pliquehal-03903518v1" class="level3 page-columns page-full" data-number="4.4">
<h3 data-number="4.4" class="anchored" data-anchor-id="network-visualization-with-ipysigma-pliquehal-03903518v1"><span class="header-section-number">4.4</span> Network visualization with ipysigma <span class="citation" data-cites="plique:hal-03903518v1">(<a href="#ref-plique:hal-03903518v1" role="doc-biblioref">Plique 2022</a>)</span></h3>
<section id="a-function-to-graph-them-all" class="level4 page-columns page-full" data-number="4.4.1">
<h4 data-number="4.4.1" class="anchored" data-anchor-id="a-function-to-graph-them-all"><span class="header-section-number">4.4.1</span> A function to graph them all</h4>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/graph_ring.png" class="img-fluid figure-img" width="289"></p>
</figure>
</div>
</div></div><div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigma_graph(dataframe, year_period):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a graph from the given dataframe</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> nx.from_pandas_edgelist(dataframe, <span class="st">'authname1'</span>, <span class="st">'authname2'</span>, edge_attr<span class="op">=</span><span class="st">'value'</span>, create_using<span class="op">=</span>nx.Graph())</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set edge colors for visualization</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> u, v <span class="kw">in</span> G.edges:</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        G[u][v][<span class="st">"color"</span>] <span class="op">=</span> <span class="st">"#7D7C7C"</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the degree of each node</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    node_degree <span class="op">=</span> <span class="bu">dict</span>(G.degree)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute multiple centrality metrics for nodes</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    node_degree_centrality <span class="op">=</span> nx.degree_centrality(G)</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>    node_degree_betweenness <span class="op">=</span> nx.betweenness_centrality(G)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    node_degree_closeness <span class="op">=</span> nx.closeness_centrality(G)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    node_degree_eigenvector <span class="op">=</span> nx.closeness_centrality(G)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    node_degree_constraint_weighted <span class="op">=</span> nx.constraint(G, weight<span class="op">=</span><span class="st">"value"</span>)</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    node_degree_constraint_unweighted <span class="op">=</span> nx.constraint(G)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set node attributes for various metrics</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_centrality, <span class="st">'centrality'</span>)</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_betweenness, <span class="st">'betweenness'</span>)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_closeness, <span class="st">'closeness'</span>)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_eigenvector, <span class="st">'eigenvector centrality'</span>)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_weighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint weighted'</span>)</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_unweighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint unweighted'</span>)</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mapping of variables based on the provided 'year_period'</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>    affilauthor_mapping <span class="op">=</span> {</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: affilauthor_before_2013,</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: affilauthor_2013_2017,</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: affilauthor_2018_2021,</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: affilauthor_2022_2023</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>    countryauthor_mapping <span class="op">=</span> {</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: countryauthor_before_2013,</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: countryauthor_2013_2017,</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: countryauthor_2018_2021,</span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: countryauthor_2022_2023</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>    citations_mapping <span class="op">=</span> {</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: citations_before_2013,</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: citations_2013_2017,</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: citations_2018_2021,</span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: citations_2022_2023</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>    article_mapping <span class="op">=</span> {</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: article_before_2013,</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: article_2013_2017,</span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: article_2018_2021,</span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: article_2022_2023</span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>    journal_mapping <span class="op">=</span> {</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: journal_before_2013,</span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: journal_2013_2017,</span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: journal_2018_2021,</span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: journal_2022_2023</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set node attributes based on the selected 'year_period'</span></span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a>    <span class="co"># They appear in the graph in the same order they are added</span></span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, affilauthor_mapping[year_period], <span class="st">'affiliation'</span>)</span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, countryauthor_mapping[year_period], <span class="st">'country'</span>)</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, article_mapping[year_period], <span class="st">'articles'</span>)</span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, journal_mapping[year_period], <span class="st">'journals'</span>)</span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, citations_mapping[year_period], <span class="st">'citations'</span>)</span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_weighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint weighted'</span>)</span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_unweighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint unweighted'</span>)</span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Construct the sigma graph and customize visualization</span></span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a>    Sigma.write_html(G,</span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>        node_metrics<span class="op">=</span>{<span class="st">"community"</span>: {<span class="st">"name"</span>: <span class="st">"louvain"</span>, <span class="st">"resolution"</span>: <span class="dv">1</span>}},  <span class="co"># Specify node metrics. increase resolution to have more communities</span></span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>        edge_size<span class="op">=</span><span class="st">"value"</span>,  <span class="co"># Set edge size</span></span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a>        node_color<span class="op">=</span><span class="st">"community"</span>,  <span class="co"># Set node colors</span></span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>        path<span class="op">=</span><span class="ss">f"networks/authors/</span><span class="sc">{</span>year_period<span class="sc">}</span><span class="ss">_sigma.html"</span>,  <span class="co"># Specify the output file path</span></span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>        fullscreen<span class="op">=</span><span class="va">True</span>,  <span class="co"># Display in fullscreen mode</span></span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>        start_layout<span class="op">=</span><span class="dv">3</span>,  <span class="co"># Start the layout algorithm automatically and lasts 3 seconds</span></span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a>        max_categorical_colors<span class="op">=</span><span class="dv">10</span>,  <span class="co"># Max categorical colors for communities</span></span>
<span id="cb20-84"><a href="#cb20-84" aria-hidden="true" tabindex="-1"></a>        label_density<span class="op">=</span><span class="dv">2</span>,  <span class="co"># Increase this to have more labels appear, it is also possible to display all labels</span></span>
<span id="cb20-85"><a href="#cb20-85" aria-hidden="true" tabindex="-1"></a>        node_size_range<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">20</span>),  <span class="co"># Set node size range</span></span>
<span id="cb20-86"><a href="#cb20-86" aria-hidden="true" tabindex="-1"></a>        default_edge_type<span class="op">=</span><span class="st">"curve"</span>,  <span class="co"># Set default edge type</span></span>
<span id="cb20-87"><a href="#cb20-87" aria-hidden="true" tabindex="-1"></a>        label_font<span class="op">=</span><span class="st">"Helvetica Neue"</span>,  <span class="co"># Set label font</span></span>
<span id="cb20-88"><a href="#cb20-88" aria-hidden="true" tabindex="-1"></a>        node_label_size<span class="op">=</span><span class="st">"citations"</span>,  <span class="co"># Set node label size</span></span>
<span id="cb20-89"><a href="#cb20-89" aria-hidden="true" tabindex="-1"></a>        <span class="co">#node_border_color="black",  # Set node border color</span></span>
<span id="cb20-90"><a href="#cb20-90" aria-hidden="true" tabindex="-1"></a>        <span class="co">#edge_color="source",  # Set edge color from 'source' attribute</span></span>
<span id="cb20-91"><a href="#cb20-91" aria-hidden="true" tabindex="-1"></a>        node_border_color_from<span class="op">=</span><span class="st">'node'</span>,  <span class="co"># Set node border color from 'node' attribute</span></span>
<span id="cb20-92"><a href="#cb20-92" aria-hidden="true" tabindex="-1"></a>        node_size<span class="op">=</span><span class="st">"citations"</span>,  <span class="co"># Set node size based on 'citations' attribute</span></span>
<span id="cb20-93"><a href="#cb20-93" aria-hidden="true" tabindex="-1"></a>        node_label_size_range<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">25</span>)</span>
<span id="cb20-94"><a href="#cb20-94" aria-hidden="true" tabindex="-1"></a>        <span class="co"># node_label_color="community"  # Set node label color based on 'community' attribute</span></span>
<span id="cb20-95"><a href="#cb20-95" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-96"><a href="#cb20-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-97"><a href="#cb20-97" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> G</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="co-authorship-network-for-the-2022-2023-period" class="level4 page-columns page-full" data-number="4.4.2">
<h4 data-number="4.4.2" class="anchored" data-anchor-id="co-authorship-network-for-the-2022-2023-period"><span class="header-section-number">4.4.2</span> Co-authorship network for the 2022-2023 period</h4>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> community <span class="im">as</span> community_louvain</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fix the seed for reproducibility</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">42</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>G_2022_2023 <span class="op">=</span> sigma_graph(network_data_2022_2023, <span class="st">'2022-2023'</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">#detect how many commmunities there are in the graph</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_2022_2023)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the 2022-2023 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 132 communities in the 2022-2023 network</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The density of the graph is {}".format(round(nx.density(G_2022_2023), 6)))</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>test_value <span class="op">=</span> nx.constraint(G_2022_2023, nodes<span class="op">=</span><span class="va">None</span>, weight<span class="op">=</span><span class="st">"value"</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>test_novalue <span class="op">=</span> nx.constraint(G_2022_2023, nodes<span class="op">=</span><span class="va">None</span>, weight<span class="op">=</span><span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<iframe width="1500" height="900" src="networks/authors/2022-2023_sigma.html" title="Sigma graph" frameborder="0" class="column-page"></iframe>
</section>
<section id="co-authorship-network-for-the-2018-2021-period" class="level4 page-columns page-full" data-number="4.4.3">
<h4 data-number="4.4.3" class="anchored" data-anchor-id="co-authorship-network-for-the-2018-2021-period"><span class="header-section-number">4.4.3</span> Co-authorship network for the 2018-2021 period</h4>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>G_2018_2021 <span class="op">=</span> sigma_graph(network_data_2018_2021, <span class="st">'2018-2021'</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The density of the graph is {}".format(nx.density(G_2018_2021))</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_2018_2021)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the 2018-2021 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 117 communities in the 2018-2021 network</code></pre>
</div>
</div>
<iframe width="1500" height="900" src="networks/authors/2018-2021_sigma.html" title="Sigma graph" frameborder="0" class="column-page"></iframe>
</section>
<section id="co-authorship-network-for-the-2013-2017-period" class="level4 page-columns page-full" data-number="4.4.4">
<h4 data-number="4.4.4" class="anchored" data-anchor-id="co-authorship-network-for-the-2013-2017-period"><span class="header-section-number">4.4.4</span> Co-authorship network for the 2013-2017 period</h4>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>G_2013_2017 <span class="op">=</span> sigma_graph(network_data_2013_2017, <span class="st">'2013-2017'</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The density of the graph is {}".format(nx.density(G_2013_2017))</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_2013_2017)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the 2013-2017 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 41 communities in the 2013-2017 network</code></pre>
</div>
</div>
<iframe width="1500" height="900" src="networks/authors/2013-2017_sigma.html" title="Sigma graph" frameborder="0" class="column-page"></iframe>
</section>
<section id="co-authorship-network-before-2013" class="level4 page-columns page-full" data-number="4.4.5">
<h4 data-number="4.4.5" class="anchored" data-anchor-id="co-authorship-network-before-2013"><span class="header-section-number">4.4.5</span> Co-authorship network before 2013</h4>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>G_before_2013 <span class="op">=</span> sigma_graph(network_data_before_2013, <span class="st">'before-2013'</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_before_2013)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the before-2013 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>There are 24 communities in the before-2013 network</code></pre>
</div>
</div>
<iframe width="1500" height="900" src="networks/authors/before-2013_sigma.html" title="Sigma graph" frameborder="0" class="column-page"></iframe>
</section>
</section>
<section id="an-interesting-metric-the-graph-density" class="level3" data-number="4.5">
<h3 data-number="4.5" class="anchored" data-anchor-id="an-interesting-metric-the-graph-density"><span class="header-section-number">4.5</span> An interesting metric: the graph density</h3>
<p>The graph density is the ratio of the number of edges to the maximum number of possible edges. It is a measure of the proportion of edges present in a graph. A graph with a high density has a large number of edges compared to the number of nodes. A graph with a low density has a small number of edges compared to the number of nodes.</p>
<p>A more formal definition is given <a href="https://networkx.org/documentation/stable/reference/generated/networkx.classes.function.density.html">here</a> by the following formulas:</p>
<ul>
<li>For undirected graphs:</li>
</ul>
<p><span class="math display">\[
\begin{equation}d=\frac{2 m}{n(n-1)}\end{equation}
\]</span></p>
<ul>
<li>For directed graphs:</li>
</ul>
<p><span class="math display">\[
\begin{equation}d=\frac{2 m}{n(n-1)}\end{equation}
\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the number of nodes and <span class="math inline">\(m\)</span> is the number of edges in the graph.</p>
<p>From an interpretation standpoint, we can appreciate the density in the graphs bellow as follows:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 87%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;"><span class="math inline">\(d\)</span></th>
<th style="text-align: left;"><strong>Interpretation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Close to <span class="math inline">\(0\)</span></td>
<td style="text-align: left;"><ul>
<li><p>The collaborative relationships among authors are sparse:</p></li>
<li><p>Authors have limited connections with each other outside of their community.</p></li>
<li><p>Scientific papers are primarily the work of individual authors or small isolated groups.</p></li>
</ul></td>
</tr>
<tr class="even">
<td style="text-align: center;">Close to <span class="math inline">\(1\)</span></td>
<td style="text-align: left;"><ul>
<li><p>Authors frequently collaborate with one another, leading to a web of interconnected scientific collaborations.</p></li>
<li><p>Scientific papers often involve contributions from multiple authors, reflecting a high level of teamwork and interdisciplinary research.</p></li>
<li><p>Collaborations are a significant aspect of the research process in this marketing field, and authors actively seek out opportunities to work together.</p></li>
<li><p>The network of collaborations is well-established and robust, facilitating the exchange of ideas and the advancement of scientific knowledge.</p></li>
</ul></td>
</tr>
</tbody>
</table>
<section id="evolution-of-the-graphs-density" class="level4" data-number="4.5.1">
<h4 data-number="4.5.1" class="anchored" data-anchor-id="evolution-of-the-graphs-density"><span class="header-section-number">4.5.1</span> Evolution of the graphs’ density</h4>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataframe with the density of each graph</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>density_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'period'</span>: [<span class="st">'before-2013'</span>, <span class="st">'2013-2017'</span>, <span class="st">'2018-2021'</span>, <span class="st">'2022-2023'</span>],</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'density'</span>: [nx.density(G_before_2013), nx.density(G_2013_2017), nx.density(G_2018_2021), nx.density(G_2022_2023)]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the 'density_df' dataframe from Python using reticulate</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>testtransfer <span class="ot">&lt;-</span> py<span class="sc">$</span>density_df</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the order of categories for the 'period' column</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>testtransfer<span class="sc">$</span>period <span class="ot">&lt;-</span> <span class="fu">factor</span>(testtransfer<span class="sc">$</span>period, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">'before-2013'</span>, <span class="st">'2013-2017'</span>, <span class="st">'2018-2021'</span>, <span class="st">'2022-2023'</span>))</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the 'gt()' function to display the dataframe</span></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>testtransfer <span class="sc">%&gt;%</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename_all</span>(Hmisc<span class="sc">::</span>capitalize) <span class="sc">%&gt;%</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">%&gt;%</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_style</span>(</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">style =</span> <span class="fu">cell_text</span>(<span class="at">weight =</span> <span class="st">"bold"</span>, <span class="at">align =</span> <span class="st">"center"</span>),</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">locations =</span> <span class="fu">cells_column_labels</span>()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div id="wohqgfjuid" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#wohqgfjuid table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#wohqgfjuid thead, #wohqgfjuid tbody, #wohqgfjuid tfoot, #wohqgfjuid tr, #wohqgfjuid td, #wohqgfjuid th {
  border-style: none;
}

#wohqgfjuid p {
  margin: 0;
  padding: 0;
}

#wohqgfjuid .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#wohqgfjuid .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#wohqgfjuid .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#wohqgfjuid .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#wohqgfjuid .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#wohqgfjuid .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wohqgfjuid .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#wohqgfjuid .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#wohqgfjuid .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#wohqgfjuid .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#wohqgfjuid .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#wohqgfjuid .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#wohqgfjuid .gt_spanner_row {
  border-bottom-style: hidden;
}

#wohqgfjuid .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#wohqgfjuid .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#wohqgfjuid .gt_from_md > :first-child {
  margin-top: 0;
}

#wohqgfjuid .gt_from_md > :last-child {
  margin-bottom: 0;
}

#wohqgfjuid .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#wohqgfjuid .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#wohqgfjuid .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#wohqgfjuid .gt_row_group_first td {
  border-top-width: 2px;
}

#wohqgfjuid .gt_row_group_first th {
  border-top-width: 2px;
}

#wohqgfjuid .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#wohqgfjuid .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#wohqgfjuid .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#wohqgfjuid .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wohqgfjuid .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#wohqgfjuid .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#wohqgfjuid .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#wohqgfjuid .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#wohqgfjuid .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#wohqgfjuid .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#wohqgfjuid .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#wohqgfjuid .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#wohqgfjuid .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#wohqgfjuid .gt_left {
  text-align: left;
}

#wohqgfjuid .gt_center {
  text-align: center;
}

#wohqgfjuid .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#wohqgfjuid .gt_font_normal {
  font-weight: normal;
}

#wohqgfjuid .gt_font_bold {
  font-weight: bold;
}

#wohqgfjuid .gt_font_italic {
  font-style: italic;
}

#wohqgfjuid .gt_super {
  font-size: 65%;
}

#wohqgfjuid .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#wohqgfjuid .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#wohqgfjuid .gt_indent_1 {
  text-indent: 5px;
}

#wohqgfjuid .gt_indent_2 {
  text-indent: 10px;
}

#wohqgfjuid .gt_indent_3 {
  text-indent: 15px;
}

#wohqgfjuid .gt_indent_4 {
  text-indent: 20px;
}

#wohqgfjuid .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" style="text-align: center; font-weight: bold;" scope="col" id="Period">Period</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1" style="text-align: center; font-weight: bold;" scope="col" id="Density">Density</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="Period" class="gt_row gt_center">before-2013</td>
<td headers="Density" class="gt_row gt_right">0.032145353</td></tr>
    <tr><td headers="Period" class="gt_row gt_center">2013-2017</td>
<td headers="Density" class="gt_row gt_right">0.019327731</td></tr>
    <tr><td headers="Period" class="gt_row gt_center">2018-2021</td>
<td headers="Density" class="gt_row gt_right">0.007211802</td></tr>
    <tr><td headers="Period" class="gt_row gt_center">2022-2023</td>
<td headers="Density" class="gt_row gt_right">0.006184432</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the Plotly graph</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> <span class="fu">plot_ly</span>(testtransfer, <span class="at">x =</span> <span class="sc">~</span>period, <span class="at">y =</span> <span class="sc">~</span>density, <span class="at">type =</span> <span class="st">'scatter'</span>, <span class="at">mode =</span> <span class="st">'lines+markers'</span>, </span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>               <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste</span>(<span class="st">"Period="</span>, period, <span class="st">"&lt;br&gt;Density="</span>, density), <span class="at">hoverinfo =</span> <span class="st">"text"</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the graph</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> fig <span class="sc">%&gt;%</span> <span class="fu">layout</span>(<span class="at">template =</span> <span class="st">"plotly_white"</span>)</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>fig</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-c8625829d42dff675cbf" style="width:100%;height:464px;"></div>
<script type="application/json" data-for="htmlwidget-c8625829d42dff675cbf">{"x":{"visdat":{"58c41f67e5a":["function () ","plotlyVisDat"]},"cur_data":"58c41f67e5a","attrs":{"58c41f67e5a":{"x":{},"y":{},"mode":"lines+markers","text":{},"hoverinfo":"text","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter"}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"template":"plotly_white","xaxis":{"domain":[0,1],"automargin":true,"title":"period","type":"category","categoryorder":"array","categoryarray":["before-2013","2013-2017","2018-2021","2022-2023"]},"yaxis":{"domain":[0,1],"automargin":true,"title":"density"},"hovermode":"closest","showlegend":false},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":["before-2013","2013-2017","2018-2021","2022-2023"],"y":[0.032145352900069882,0.019327731092436976,0.0072118015277200199,0.0061844323512198528],"mode":"lines+markers","text":["Period= before-2013 <br>Density= 0.0321453529000699","Period= 2013-2017 <br>Density= 0.019327731092437","Period= 2018-2021 <br>Density= 0.00721180152772002","Period= 2022-2023 <br>Density= 0.00618443235121985"],"hoverinfo":["text","text","text","text"],"type":"scatter","marker":{"color":"rgba(31,119,180,1)","line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"xaxis":"x","yaxis":"y","frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</section>
</section>
</section>
<section id="citations-networks" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="citations-networks"><span class="header-section-number">5</span> Citations networks</h2>
<p>Let’s now dive into the exploration of citation networks. We’ll be employing the same approach that we used for analyzing co-authorship networks across different time periods.</p>
<p>In this new investigation, our primary aim remains the acquisition of valuable insights into the ever-evolving landscape of research in marketing using NLP methods.</p>
<p>This research is motivated by the convergence of two critical factors:</p>
<ol type="1">
<li><p>The advent of novel tools and techniques that facilitate the analysis of large data volumes ;</p></li>
<li><p>The proliferation and the availability of open and private data from various sectors.</p></li>
</ol>
<p>While our prior work focused on uncovering emerging research topics, our current emphasis shifts towards comprehending which papers have garnered the most attention. We seek to determine whether it is predominantly computer science papers that have inspired marketing scholars with new perspectives into data analysis or if marketing papers have also played a role in advocating the development of new theories.</p>
<section id="data-preparation-and-summary" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="data-preparation-and-summary"><span class="header-section-number">5.1</span> Data preparation and summary</h3>
<p>We’ll start by loading the data of references and preparing it for the analysis.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data of references</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>list_references <span class="ot">&lt;-</span> <span class="fu">read_csv2</span>(<span class="st">'nlp_references_final_18-08-2023.csv'</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>list_references <span class="ot">&lt;-</span> list_references <span class="sc">%&gt;%</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">32</span>) <span class="sc">%&gt;%</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">citing_art =</span> <span class="fu">str_sub</span>(citing_art, <span class="dv">11</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">scopus_id =</span> <span class="st">`</span><span class="at">scopus-id</span><span class="st">`</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">relocate</span>(scopus_id, <span class="at">.after =</span> citing_art) <span class="sc">%&gt;%</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">year =</span> <span class="fu">as.character</span>(<span class="fu">str_sub</span>(<span class="st">`</span><span class="at">prism:coverDate</span><span class="st">`</span>, <span class="dv">1</span>, <span class="dv">4</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="st">`</span><span class="at">prism:coverDate</span><span class="st">`</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(list_references)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<table class="table table-sm table-striped small">
<caption>Data summary</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">Name</td>
<td style="text-align: left;">list_references</td>
</tr>
<tr class="even">
<td style="text-align: left;">Number of rows</td>
<td style="text-align: left;">27710</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Number of columns</td>
<td style="text-align: left;">32</td>
</tr>
<tr class="even">
<td style="text-align: left;">_______________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Column type frequency:</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">character</td>
<td style="text-align: left;">23</td>
</tr>
<tr class="odd">
<td style="text-align: left;">logical</td>
<td style="text-align: left;">3</td>
</tr>
<tr class="even">
<td style="text-align: left;">numeric</td>
<td style="text-align: left;">6</td>
</tr>
<tr class="odd">
<td style="text-align: left;">________________________</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Group variables</td>
<td style="text-align: left;">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 46%">
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 3%">
<col style="width: 3%">
<col style="width: 5%">
<col style="width: 8%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">min</th>
<th style="text-align: right;">max</th>
<th style="text-align: right;">empty</th>
<th style="text-align: right;">n_unique</th>
<th style="text-align: right;">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">citing_art</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">437</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">scopus_id</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">21176</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">scopus-eid</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">18</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">21176</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">volisspag.voliss.@volume</td>
<td style="text-align: right;">6464</td>
<td style="text-align: right;">0.77</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">59</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">577</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">volisspag.voliss.@issue</td>
<td style="text-align: right;">9919</td>
<td style="text-align: right;">0.64</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">294</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">volisspag.pagerange.@first</td>
<td style="text-align: right;">9069</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2005</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">volisspag.pagerange.@last</td>
<td style="text-align: right;">9098</td>
<td style="text-align: right;">0.67</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2030</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">sourcetitle</td>
<td style="text-align: right;">935</td>
<td style="text-align: right;">0.97</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">313</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7759</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">type</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">title</td>
<td style="text-align: right;">3820</td>
<td style="text-align: right;">0.86</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">313</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">18075</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">url</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">21176</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">ce:doi</td>
<td style="text-align: right;">8599</td>
<td style="text-align: right;">0.69</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">66</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">13905</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.ce:given-name</td>
<td style="text-align: right;">7178</td>
<td style="text-align: right;">0.74</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7732</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">author-list.author.preferred-name.ce:given-name</td>
<td style="text-align: right;">7650</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7549</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.preferred-name.ce:initials</td>
<td style="text-align: right;">7650</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">825</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">author-list.author.preferred-name.ce:surname</td>
<td style="text-align: right;">7648</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7697</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.preferred-name.ce:indexed-name</td>
<td style="text-align: right;">7648</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">10775</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">author-list.author.ce:initials</td>
<td style="text-align: right;">1127</td>
<td style="text-align: right;">0.96</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1374</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.affiliation.@href</td>
<td style="text-align: right;">8372</td>
<td style="text-align: right;">0.70</td>
<td style="text-align: right;">68</td>
<td style="text-align: right;">69</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">3540</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">author-list.author.ce:surname</td>
<td style="text-align: right;">1028</td>
<td style="text-align: right;">0.96</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">83</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">10290</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.author-url</td>
<td style="text-align: right;">7648</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">61</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">11213</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">author-list.author.ce:indexed-name</td>
<td style="text-align: right;">1028</td>
<td style="text-align: right;">0.96</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">83</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">14690</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">year</td>
<td style="text-align: right;">7645</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">79</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: logical</strong></p>
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 44%">
<col style="width: 13%">
<col style="width: 19%">
<col style="width: 6%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">mean</th>
<th style="text-align: left;">count</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="citation" data-cites="_fa">(<a href="#ref-_fa" role="doc-biblioref"><strong>_fa?</strong></a>)</span></td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">TRU: 27710</td>
</tr>
<tr class="even">
<td style="text-align: left;">author-list.author.@_fa</td>
<td style="text-align: right;">1028</td>
<td style="text-align: right;">0.96</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">TRU: 26682</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.@force-array</td>
<td style="text-align: right;">1028</td>
<td style="text-align: right;">0.96</td>
<td style="text-align: right;">1</td>
<td style="text-align: left;">TRU: 26682</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table class="table table-sm table-striped small">
<colgroup>
<col style="width: 23%">
<col style="width: 6%">
<col style="width: 9%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 7%">
<col style="width: 7%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 8%">
<col style="width: 4%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">skim_variable</th>
<th style="text-align: right;">n_missing</th>
<th style="text-align: right;">complete_rate</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">sd</th>
<th style="text-align: right;">p0</th>
<th style="text-align: right;">p25</th>
<th style="text-align: right;">p50</th>
<th style="text-align: right;">p75</th>
<th style="text-align: right;">p100</th>
<th style="text-align: left;">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">citedby-count</td>
<td style="text-align: right;">7705</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">8.617000e+02</td>
<td style="text-align: right;">4.167250e+03</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">37</td>
<td style="text-align: right;">110</td>
<td style="text-align: right;">371</td>
<td style="text-align: right;">110613</td>
<td style="text-align: left;">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="citation" data-cites="id">(<a href="#ref-id" role="doc-biblioref"><strong>id?</strong></a>)</span></td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">1.995063e+05</td>
<td style="text-align: right;">5.303331e+06</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">38</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">148402876</td>
<td style="text-align: left;">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.@seq</td>
<td style="text-align: right;">1028</td>
<td style="text-align: right;">0.96</td>
<td style="text-align: right;">1.010000e+00</td>
<td style="text-align: right;">1.200000e-01</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">7</td>
<td style="text-align: left;">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td style="text-align: left;">author-list.author.affiliation.@id</td>
<td style="text-align: right;">8372</td>
<td style="text-align: right;">0.70</td>
<td style="text-align: right;">6.173094e+07</td>
<td style="text-align: right;">9.348258e+06</td>
<td style="text-align: right;">60000009</td>
<td style="text-align: right;">60012464</td>
<td style="text-align: right;">60024324</td>
<td style="text-align: right;">60098091</td>
<td style="text-align: right;">129210871</td>
<td style="text-align: left;">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td style="text-align: left;">author-list.author.@auid</td>
<td style="text-align: right;">7648</td>
<td style="text-align: right;">0.72</td>
<td style="text-align: right;">3.249277e+10</td>
<td style="text-align: right;">2.170754e+10</td>
<td style="text-align: right;">6503961461</td>
<td style="text-align: right;">7402008640</td>
<td style="text-align: right;">35201040100</td>
<td style="text-align: right;">56174119775</td>
<td style="text-align: right;">58531000200</td>
<td style="text-align: left;">▇▂▂▁▇</td>
</tr>
<tr class="even">
<td style="text-align: left;">entry_number</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">1.831000e+01</td>
<td style="text-align: right;">1.143000e+01</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">40</td>
<td style="text-align: left;">▇▇▆▆▅</td>
</tr>
</tbody>
</table>
</div>
</div>
<section id="detect-inconsistencies" class="level4" data-number="5.1.1">
<h4 data-number="5.1.1" class="anchored" data-anchor-id="detect-inconsistencies"><span class="header-section-number">5.1.1</span> Detect inconsistencies</h4>
<p>There are some problems with the data that we need to address before proceeding with the analysis. Some <code>scopus_id</code> identifiers (the id of the reference that appears in our marketing NLP corpus articles) have multiple different values of title (even only minor differences), sourcetitle, etc. although they should be equal. We want to plot the networks with information about the nodes. One unique node should have one unique value for each variable.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>list_references <span class="op">=</span> r.list_references</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Group by 'scopus_id' and count the unique number of 'title' for each 'scopus_id'</span></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>title_counts <span class="op">=</span> list_references.groupby(<span class="st">'scopus_id'</span>)[<span class="st">'title'</span>].nunique()</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the 'scopus_id' that have more than one associated title</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>inconsistent_scopus_id <span class="op">=</span> title_counts[title_counts <span class="op">&gt;</span> <span class="dv">1</span>].index.tolist()</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>year_counts <span class="op">=</span> list_references.groupby(<span class="st">'scopus_id'</span>)[<span class="st">'year'</span>].nunique()</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>inconsistent_scopus_id_year <span class="op">=</span> year_counts[title_counts <span class="op">&gt;</span> <span class="dv">1</span>].index.tolist()</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>inconsistent_scopus_id_year</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>['0000009769', '0000102571', '0000125532', '0000125534', '0000133998', '0000200753', '0000257156', '0000268040', '0000292017', '0000392294', '0000424077', '0000428577', '0000470917', '0000534475', '0000604269', '0000607236', '0000640211', '0000659566', '0000679216', '0000696527', '0000771343', '0000881830', '0000917415', '0000922949', '0001181569', '0001227919', '0001261094', '0001287271', '0001312089', '0001449665', '0001469895', '0001494664', '0001559313', '0001561946', '0001677717', '0001721941', '0001728801', '0001736594', '0001772263', '0001819160', '0001836974', '0001878819', '0001884325', '0001925995', '0001927247', '0001951371', '0001965293', '0001995742', '0002020889', '0002059221', '0002074493', '0002098156', '0002125623', '0002126713', '0002183204', '0002273385', '0002338132', '0002373795', '0002381637', '0002408510', '0002450279', '0002466427', '0002469577', '0002487848', '0002534963', '0002535326', '0002538481', '0002546379', '0002604811', '0002607378', '0002667763', '0002671212', '0002680840', '0002816448', '0002866667', '0002934032', '0002954788', '0003018358', '0003048219', '0003054392', '0003056894', '0003248898', '0003443980', '0003487601', '0003488717', '0003517644', '0003531998', '0003550676', '0003551671', '0003583974', '0003584083', '0003586486', '0003608927', '0003634344', '0003653039', '0003654618', '0003667583', '0003670522', '0003678180', '0003710039', '0003767234', '0003768768', '0003797465', '0003798635', '0003807877', '0003868827', '0003882234', '0003954922', '0004029218', '0004040339', '0004042547', '0004048902', '0004079982', '0004104263', '0004230731', '0004266342', '0004289791', '0004296209', '0004311812', '0004816858', '0007744069', '0010335445', '0010737688', '0011939750', '0012903874', '0012960262', '0013168260', '0038052185', '0038167128', '0039013204', '0040984002', '0042429461', '0141988044', '0142192295', '0242300515', '0242704919', '0344670826', '0344885597', '0345570094', '10644254015', '1442352079', '19944373443', '21144463066', '21144478550', '21144479982', '21344475283', '21344475322', '21344476404', '21344477997', '21344485409', '21344490393', '21744438808', '21844492054', '21844510415', '21844511586', '23944509647', '33645675879', '33646714870', '33646864881', '33744918656', '33745100403', '33746036191', '33750343272', '33846300647', '34249879981', '34548080780', '34548820027', '34548831762', '37149021640', '38149091464', '44949090262', '4744338583', '51849155463', '52449116403', '55549105509', '56549123473', '61449210975', '63349083646', '64949089948', '66249144220', '67649153594', '68049107819', '70349284484', '70349460990', '77649141031', '77949504413', '77955641068', '77957885953', '77958044443', '78649311561', '78649933846', '78650393330', '79251522945', '79953762206', '79954453991', '79958249386', '80053431219', '80055049753', '83055176929', '84856343452', '84857211130', '84862732380', '84870388697', '84870854437', '84870885352', '84872195089', '84875062524', '84893112707', '84903761492', '84904895360', '84905120851', '84906270125', '84919728106', '84919895840', '84923339908', '84923351534', '84934877092', '84935533832', '84936628342', '84936823859', '84936823933', '84937293064', '84937306801', '84937332636', '84938966245', '84940046213', '84942299268', '84944735469', '84956473495', '84964770022', '84973537408', '84989220223', '84994563407', '85013120533', '85013304526', '85013457817', '85015236485', '85017111309', '85020481177', '85021643438', '85023700532', '85029459334', '85031013784', '85033687876', '85041661023', '85042201824', '85042481189', '85044163613', '85051108531', '85055278050', '85055363420', '85057019815', '85059176675', '85062069097', '85076459055', '85076489289', '85082024558', '85083322291', '85083439798', '85085117614', '85087429358', '85090707944', '85098710831', '85099424156', '85108665491', '85116889672', '85150697324', '85153747795', '85158837449']</code></pre>
</div>
</div>
</section>
<section id="list-of-all-inconsistencies" class="level4" data-number="5.1.2">
<h4 data-number="5.1.2" class="anchored" data-anchor-id="list-of-all-inconsistencies"><span class="header-section-number">5.1.2</span> List of all inconsistencies</h4>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>list_inconsistencies <span class="ot">&lt;-</span> list_references <span class="sc">%&gt;%</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(scopus_id <span class="sc">%in%</span> py<span class="sc">$</span>inconsistent_scopus_id) <span class="sc">%&gt;%</span> <span class="co">#we take the inconsistent scopus_id from python by using reticulate</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(scopus_id, citing_art, title, sourcetitle, year, <span class="st">`</span><span class="at">author-list.author.ce:indexed-name</span><span class="st">`</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>  list_inconsistencies,</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">striped =</span> <span class="cn">TRUE</span>,</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">groupBy =</span> <span class="st">"scopus_id"</span>,</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">100</span>, <span class="at">maxWidth =</span> <span class="dv">200</span>),  <span class="co"># Adjust these values as needed</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">columns =</span> <span class="fu">list</span>(</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">250</span>)  <span class="co"># Adjust this value based on the length of your titles</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div class="reactable html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-3917e4f3e48d217ed7d0" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-3917e4f3e48d217ed7d0">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"scopus_id":["21144479982","0003710039","84870885352","85098710831","0004289791","84870854437","64949089948","0001312089","85033687876","0003667583","0003868827","0002381637","0003248898","34249879981","84870388697","0141988044","0003584083","0001449665","0002816448","0004048902","84936628342","67649153594","0001927247","84870854437","0003517644","0000917415","33646714870","38149091464","0001559313","0002667763","0012960262","84936628342","0002469577","0001312089","85013304526","0003608927","85153747795","0001287271","0003710039","0001878819","0003710039","84936823933","0002469577","0004040339","85044163613","85083322291","85013120533","85057019815","0003678180","0000424077","0001181569","0003653039","85055278050","0002183204","84862732380","34548080780","33646864881","0003882234","84872195089","0004048902","21144478550","0004266342","0004266342","0001721941","0002546379","38149091464","0000392294","0000917415","0000102571","21144463066","0040984002","0002607378","0000009769","84870388697","0012903874","84923351534","0002954788","0004230731","33645675879","0001287271","34548080780","85153747795","64949089948","85031013784","85057019815","84964770022","78649311561","0002667763","77649141031","0002680840","0000659566","0000771343","0002126713","84870854437","85158837449","85150697324","85015236485","85085117614","0003710039","64949089948","85116889672","85059176675","84870854437","0002074493","0000922949","85059176675","85057019815","85076489289","0002680840","0000009769","84870854437","0004029218","0141988044","85059176675","0007744069","0001925995","0001312089","84936628342","85158837449","70349460990","0003710039","85158837449","85150697324","0003710039","64949089948","78650393330","85082024558","52449116403","63349083646","85055278050","80053431219","0002671212","21344475322","85020481177","85090707944","0003056894","0002667763","52449116403","0002538481","21144478550","85150697324","64949089948","0003584083","0001287271","0003798635","66249144220","0000125532","0003667583","0000428577","21744438808","21344485409","84940046213","0001559313","0002126713","84856343452","85099424156","85057019815","84923351534","79953762206","85021643438","0141988044","21344490393","0002535326","0000424077","0001181569","0001181569","0003488717","0003586486","85055363420","84875062524","0002408510","0001312089","0000200753","64949089948","0002408510","80055049753","85057019815","0000125534","0003710039","0002667763","21144478550","0001469895","0001561946","0000009769","84973537408","64949089948","0013168260","0003667583","0001884325","34548820027","21344477997","84903761492","84944735469","0003550676","0003653039","33646714870","0004816858","0001772263","34548820027","85082024558","64949089948","84870854437","0001559313","0001736594","64949089948","0003488717","0001927247","64949089948","0003710039","0002373795","0010737688","85098710831","0012903874","0003551671","0002020889","84956473495","0002667763","84936628342","52449116403","83055176929","0003551671","0002126713","0010737688","0003710039","64949089948","0003670522","0003767234","0002607378","0002934032","0004040339","0003531998","64949089948","0000534475","0004040339","84989220223","84893112707","84956473495","0001677717","10644254015","33846300647","77649141031","84870854437","0003054392","0001721941","0003654618","0004079982","85083439798","79958249386","0000424077","0002059221","64949089948","64949089948","0004048902","84905120851","0000392294","0004040339","0003056894","0000534475","0000292017","0004048902","64949089948","0001561946","0001494664","85042481189","84870854437","21144478550","0001836974","0001469895","61449210975","84936628342","84875062524","85051108531","0000679216","0038167128","0003443980","0003634344","0003710039","38149091464","0000392294","0003654618","0003054392","44949090262","84973537408","0011939750","38149091464","85013120533","84862732380","0000696527","0003487601","0002534963","79954453991","85013304526","0038052185","84862732380","0003517644","64949089948","84862732380","38149091464","84944735469","33646714870","85087429358","85087429358","85087429358","0003551671","0000009769","0000771343","84956473495","64949089948","85044163613","84919895840","33846300647","0003710039","21844492054","0002125623","38149091464","34548080780","0004289791","34249879981","0345570094","85076489289","85057019815","0142192295","85057019815","84923339908","85021643438","85116889672","85013457817","85085117614","85057019815","0000696527","0003653039","0004040339","21344475322","0003443980","79954453991","0001227919","85057019815","85076489289","84919728106","0004029218","0003710039","78649933846","84903761492","84875062524","64949089948","64949089948","0003710039","64949089948","0002273385","85041661023","0000679216","68049107819","0003443980","0003667583","52449116403","0003586486","34548080780","85057019815","68049107819","85090707944","0002020889","85017111309","85098710831","84934877092","0003653039","85042201824","85042201824","0003667583","21144478550","0004230731","38149091464","0002020889","84942299268","34548080780","79958249386","85013304526","64949089948","85076489289","56549123473","64949089948","84937332636","21344485409","0003583974","84870854437","84870854437","0003018358","0004029218","64949089948","84938966245","85083322291","85031013784","0003768768","0001312089","1442352079","84870854437","0001559313","21144478550","0004048902","4744338583","84944735469","0000257156","64949089948","21344485409","84906270125","79958249386","84956473495","85021643438","0002535326","0001312089","0000470917","0003667583","0002020889","0007744069","84936823933","0001951371","64949089948","0001312089","80055049753","0002408510","0002866667","0002450279","0000424077","84906270125","84994563407","64949089948","85083439798","85051108531","0002381637","85076489289","0001312089","0001261094","0002338132","21144478550","21344476404","21844510415","21144479982","0000607236","0004296209","0003670522","21344477997","0003710039","0003710039","0002466427","0003768768","85029459334","0003710039","64949089948","0003584083","0001449665","84937306801","66249144220","0000200753","33646864881","33744918656","85013457817","84872195089","85013457817","21144478550","0004266342","64949089948","85108665491","85108665491","84935533832","0039013204","84870854437","0004079982","64949089948","0003531998","21844511586","0003584083","0000009769","0001995742","0001995742","84936628342","0003583974","0000917415","0002604811","84904895360","0003517644","0001287271","0003550676","33646714870","38149091464","0004296209","0001736594","64949089948","0002816448","78649933846","85033687876","85057019815","0004289791","0003048219","44949090262","0002667763","64949089948","84904895360","0003807877","0042429461","0003018358","38149091464","21344490393","0002667763","0002408510","0001312089","0003882234","0002381637","0007744069","0004040339","84956473495","0002373795","0001925995","0001312089","0001261094","0002408510","64949089948","0002098156","0002381637","21344490393","0000534475","84870854437","0000607236","0002074493","78649311561","0004266342","0001728801","23944509647","0001227919","56549123473","84857211130","64949089948","64949089948","84870854437","0003443980","85057019815","85076489289","0003248898","0000696527","0002680840","0004040339","0003868827","84934877092","84923351534","0013168260","0002126713","0001227919","0001995742","85017111309","0003550676","52449116403","84919895840","0000257156","0002534963","64949089948","0000009769","84936823933","0000009769","0013168260","0002954788","0003048219","21844492054","84857211130","64949089948","85076459055","85076459055","85076459055","0000470917","84872195089","84942299268","0004266342","33646864881","0004230731","0003797465","33745100403","0003954922","0003798635","0002487848","84938966245","85057019815","0001312089","0002098156","84923351534","84940046213","84935533832","0000125534","21144478550","0004079982","84956473495","52449116403","0003048219","21344475322","0002954788","0040984002","0002607378","21144463066","78650393330","77958044443","0040984002","0000125532","0002466427","21344475322","64949089948","0003882234","0004048902","0344885597","37149021640","38149091464","0004816858","21144478550","0004266342","0004040339","21344476404","21844510415","0004042547","38149091464","61449210975","0002273385","0002934032","0000881830","84936823859","0003797465","0000133998","0242300515","0000659566","0000009769","0002126713","64949089948","0001677717","0004040339","0004230731","0003488717","0004040339","70349460990","0003710039","0000009769","0004296209","84870854437","0003678180","64949089948","33645675879","84857211130","64949089948","0000640211","0002538481","0141988044","34249879981","0003608927","85013304526","64949089948","0001951371","38149091464","0002126713","84905120851","84856343452","0000881830","0004040339","0003797465","84856343452","0001559313","85099424156","84994563407","0003584083","0000679216","77949504413","0003584083","79953762206","84944735469","70349284484","84903761492","84919728106","0003768768","0000424077","0001181569","0002020889","0003584083","70349460990","0002059221","0003710039","84919895840","85055278050","0001449665","84937306801","0039013204","0000607236","21344490393","0001736594","0002183204","0001736594","84956473495","0345570094","0000102571","0003797465","0003678180","21144463066","0003048219","0002954788","0040984002","84994563407","55549105509","0001559313","0004040339","0001469895","64949089948","0003710039","64949089948","0003488717","0003586486","0003583974","0002538481","0004104263","0040984002","0000125532","0003048219","70349284484","85062069097","85062069097","85042481189","52449116403","38149091464","0004816858","34548080780","64949089948","0004048902","38149091464","21144478550","0004266342","0004040339","33646864881","0003882234","84872195089","21144478550","33744918656","84872195089","0242704919","0004296209","84870854437","0004040339","64949089948","77649141031","0004104263","52449116403","77949504413","0003667583","0013168260","67649153594","0002126713","64949089948","84989220223","0002866667","0001965293","84935533832","0002667763","0003054392","19944373443","0002126713","64949089948","85041661023","0000679216","80053431219","0010335445","0038052185","0003487601","38149091464","0000696527","0003048219","0002125623","0002671212","21344475322","85020481177","85055278050","79958249386","85029459334","84875062524","84964770022","64949089948","79953762206","84893112707","21344485409","55549105509","79251522945","63349083646","34548080780","0242300515","0000659566","85013304526","64949089948","0003488717","85015236485","0003586486","85055363420","0000268040","10644254015","34548080780","85021643438","84856343452","79953762206","0004816858","0000679216","0001772263","0038052185","52449116403","0004042547","0003710039","84862732380","84875062524","0002408510","0001312089","0011939750","0002098156","0002381637","0007744069","0001181569","21344475322","21744438808","19944373443","84937293064","0002059221","0003710039","0003710039","64949089948","0000428577","21844511586","85041661023","0001836974","34548831762","70349460990","0004040339","0242704919","0000534475","0002934032","0001878819","21344475283","0001677717","0000133998","0004311812","84923339908","84862732380","0004079982","0003807877","1442352079","0002667763","0004048902","0004048902","21144478550","0004266342","0004289791","83055176929","34548080780","84956473495","51849155463","0000922949","0002866667","10644254015","0012960262","77949504413","64949089948","21744438808","0003488717","0001819160","0003586486","38149091464","0000607236","33646714870","38149091464","0001449665","85013120533","38149091464","34548080780","0003653039","4744338583","0003634344","0002487848","0001728801","0004311812","0038167128","0000604269","0003488717","0001819160","84937332636","0003586486","0004040339","51849155463","0002408510","0010335445","0002098156","0002381637","55549105509","0001559313","0001836974","0002450279","38149091464","0004296209","0003443980","84905120851","33745100403","0001884325","0000640211","0001559313","34548831762","79251522945","21144478550","0000268040","84870854437","0000125532","84870885352","0001728801","0004289791","84872195089","0344885597","0002546379","37149021640","21144478550","0004266342","0000659566","38149091464","84905120851","0002126713","0000917415","0003584083","0001728801","0001965293","84936823933","0010335445","0001728801","0001449665","84936628342","23944509647","0003018358","0002934032","0002866667","85023700532","0002604811","0001494664","0002954788","0003678180","21144463066","0003048219","0002607378","0000604269","64949089948","0001927247","0000292017","0002604811","0003584083","0142192295","33746036191","0003653039","0001721941","0002546379","0012960262","77955641068","38149091464","0004289791","33750343272","77958044443","0001965293","77955641068","0004040339","0003653039","0001721941","0002338132","33750343272","0004816858","0001772263","0000917415","33746036191","33746036191","0001951371","0002126713","0002183204","84937293064","0003488717","21344475283","0003767234","0001965293","85023700532","0002604811","0003797465","0003954922","0001878819","0042429461","0003882234","77957885953","0344670826","77957885953","0344670826","0002934032","0000881830","0000470917","84936823859","0003797465"],"citing_art":["85144463165","85166572932","85166572932","85166572932","85166572932","85148341584","85148341584","85153514480","85153514480","85153514480","85153514480","85153514480","85153514480","85153514480","85151004351","85151004351","85150347354","85150347354","85150347354","85149572870","85149572870","85132327378","85132327378","85132327378","85126047177","85126047177","85126047177","85126047177","85126047177","85146949978","85139387322","85138717027","85138717027","85146998548","85158110075","85158110075","85158110075","85150498750","85150498750","85150498750","85126071763","85143761358","85143761358","85143761358","85141511083","85141511083","85141511083","85141511083","85136274594","85131811168","85131811168","85131811168","85131811168","85131811168","85131811168","85131811168","85124730460","85124730460","85124730460","85124730460","85124730460","85124730460","85124730460","85124726420","85124726420","85124726420","85124726420","85124726420","85143324979","85143324979","85143324979","85143324979","85143324979","85143324979","85139679546","85139679546","85137669788","85137669788","85137669788","85167334948","85167334948","85167334948","85167334948","85167334948","85167334948","85166630306","85166630306","85166630306","85166630306","85166630306","85166630306","85166630306","85166630306","85166624123","85165569386","85165569386","85165413235","85165413235","85165413235","85165413235","85165413235","85165413235","85165413235","85165413235","85165395672","85165395672","85163206315","85163206315","85162774955","85162774955","85162774955","85162774955","85161509158","85160700281","85160700281","85160700281","85160700281","85159567297","85159567297","85159489905","85159489905","85158148454","85158148454","85158148454","85158148454","85158148454","85152800674","85152800674","85151960432","85151960432","85151960432","85151620034","85151620034","85151620034","85151620034","85151620034","85150855178","85150855178","85150855178","85150855178","85150739173","85150739173","85150739173","85150739173","85150739173","85150739173","85150606964","85150606964","85150606964","85150606964","85150606964","85150606964","85150606964","85150606964","85149420983","85149420983","85149113734","85147809278","85147513245","85147513245","85147100431","85143898085","85141229738","85141229738","85141229738","85139737257","85139737257","85139737257","85139737257","85139736022","85139736022","85139736022","85135121811","85135121811","85100900429","85100900429","85120649487","85153078307","85153078307","85140003141","85140003141","85140003141","85140003141","85140003141","85112524940","85120610290","85146299830","85146299830","85139848262","85136100401","85136100401","85126047472","85126047472","85124378925","85119271011","85119271011","85119271011","85119271011","85149071663","85149071663","85149071663","85149071663","85149071663","85138073856","85138073856","85138073856","85138073856","85137626292","85137626292","85137626292","85137626292","85136468469","85127426396","85127426396","85127426396","85127280924","85127280924","85127280924","85127280924","85127280924","85127280924","85127280924","85134811050","85134811050","85134811050","85134811050","85134811050","85134811050","85134811050","85134811050","85134523493","85134523493","85134523493","85134523493","85134523493","85146302485","85146302485","85146232194","85146232194","85146232194","85116722502","85116722502","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85117146222","85117146222","85117146222","85113192675","85113192675","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85122333187","85122333187","85122333187","85122333187","85118651091","85118651091","85114853462","85131319256","85131319256","85131319256","85131319256","85109761157","85122354292","85122354292","85122354292","85121749320","85121749320","85120872880","85120872880","85128482011","85127638085","85127638085","85127638085","85127638085","85126476246","85126476246","85126476246","85126476246","85126476246","85126476246","85123013062","85123013062","85123013062","85122507035","85111638251","85102511342","85117124447","85117124447","85117124447","85117124447","85117124447","85107472686","85107472686","85107472686","85104078942","85150089813","85150089813","85150089813","85150089813","85147259597","85147249097","85147249097","85146879074","85145840941","85145840941","85145840941","85145840941","85145840941","85142372695","85139115612","85139115612","85139115612","85139115612","85139115612","85139115612","85139115612","85138704935","85138704935","85138684672","85138684672","85138684672","85138684672","85136591503","85136591503","85136591503","85136515369","85136458993","85136458993","85136458993","85131678809","85131678809","85127939086","85127939086","85127334186","85127334186","85127018562","85126975314","85126946402","85126333013","85126333013","85126333013","85125102701","85125102701","85121317003","85121317003","85116556264","85116556264","85116556264","85100059556","85100059556","85100059556","85094879481","85130623788","85130623788","85130623788","85130623788","85117069469","85117069469","85116899884","85116899884","85116899884","85116899884","85116899884","85116899884","85114512213","85114464568","85114464568","85114464568","85103952432","85101453495","85101453495","85101077323","85108345184","85108345184","85108345184","85108345184","85108345184","85108345184","85108345184","85121141262","85121141262","85111740562","85111740562","85109633827","85109633827","85109633827","85109633827","85109633827","85116481460","85116481460","85116481460","85116481460","85116481460","85116481460","85116481460","85116438673","85104041731","85104041731","85104041731","85104041731","85104041731","85128903955","85128903955","85128903955","85128903955","85128903955","85118220280","85118220280","85118220280","85118220280","85118220280","85113266808","85113266808","85113266808","85105755765","85105755765","85105755765","85105755765","85104394128","85104394128","85114046286","85114046286","85114046286","85114046286","85108701962","85108701962","85108701962","85108701962","85108701962","85108701962","85108701962","85108701962","85158949640","85158949640","85158949640","85158949640","85158949640","85158949640","85158949640","85105653818","85105653818","85105653818","85103167358","85103167358","85103167358","85103167358","85103167358","85102463024","85102463024","85102463024","85102463024","85102463024","85102463024","85102463024","85102463024","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85107287236","85105488569","85105488569","85101739989","85101739989","85101739989","85101739989","85101739989","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85088692184","85087053077","85087053077","85087053077","85087053077","85087053077","85087053077","85099389536","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100845405","85100845405","85091634199","85091634199","85091634199","85091634199","85091634199","85090731774","85090731774","85090731774","85090731774","85090731774","85090731774","85101263846","85101263846","85138633642","85111091672","85111091672","85108978849","85108978849","85107991873","85107991873","85106315113","85106315113","85106315113","85106315113","85101480021","85101480021","85101480021","85101480021","85094632972","85092346299","85092346299","85091434156","85083557523","85083557523","85077154834","85077154834","85077154834","85077154834","85076455134","85076455134","85076455134","85076455134","85076455134","85097615908","85153031128","85153031128","85153031128","85153031128","85090359625","85090359625","85090359625","85090359625","85101930421","85098887052","85075881467","85098461241","85087421838","85087421838","85087421838","85085967799","85085967799","85064900712","85064900712","85073826575","85088942130","85088928551","85085975972","85085975972","85085975972","85085975972","85085975972","85085975972","85084418343","85059850575","85059850575","85059850575","85082966401","85082966401","85082131009","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85078887027","85078887027","85078887027","85078887027","85081279279","85081279279","85081279279","85081279279","85081279279","85079822358","85079822358","85079822358","85079822358","85079822358","85079822358","85079822358","85079130868","85079130868","85079130868","85079130868","85076535289","85076535289","85078424831","85078424831","85078424831","85078424831","85069448021","85069448021","85069448021","85106373785","85106373785","85106373785","85106373785","85106373785","85106373785","85072713622","85072713622","85078470711","85078470711","85078470711","85078470711","85147599237","85125179733","85125179733","85125179733","85125179733","85099410916","85099410916","85099410916","85096041672","85096041672","85082868407","85082747260","85077710168","85077710168","85077710168","85077710168","85077710168","85077710168","85077710168","85076367036","85076367036","85076367036","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85059464256","85059464256","85083648310","85083648310","85071915138","85071915138","85071915138","85060661202","85060661202","85060661202","85060661202","85060661202","85060661202","85060661202","85068532597","85068532597","85068532597","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85067848547","85067848547","85067848547","85081956713","85062084132","85068046590","85068046590","85070983662","85063587453","85063587453","85063587453","85063587453","85149382137","85149382137","85149382137","85149382137","85149382137","85149382137","85149382137","85149382137","85130629588","85130629588","85130629588","85083803034","85083803034","85083803034","85083803034","85083803034","85083803034","85083803034","85065886742","85065886742","85064056437","85064056437","85064056437","85064056437","85067034290","85067034290","85067034290","85067034290","85067034290","85061812010","85061812010","85061812010","85061812010","85065283005","85065283005","85065283005","85065283005","85069470449","85058647683","85058647683","85058647683","85055525406","85055525406","85055525406","85055525406","85055525406","85055525406","85055277517","85055277517","85055277517","85055277517","85055277517","85055277517","85055277517","85063434374","85063434374","85052138805","85052138805","85052138805","85071937753","85071937753","85071937753","85059696197","85059696197","85059696197","85059696197","85059696197","85059696197","85059696197","85148555309","85070922144","85070922144","85070922144","85070922144","85063814803","85063814803","85063814803","85042353149","85042353149","85042353149","85048377287","85047658500","85047658500","85047658500","85047658500","85047658500","85047658500","85047658500","85047658500","85047653646","85062666532","85062666532","85062666532","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85048740946","85048740946","85059376135","85059376135","85045397801","85045397801","85045397801","85045397801","85045397801","85045397801","85040710229","85030455391","85030455391","85030455391","85018173060","84981276334","84981276334","84981276334","84981276334","84981276334","85017215318","85017215318","85017215318","85017215318","85017215318","85017215318","85008145276","85008145276","85008145276","84994761908","85027195392","85010894617","85010894617","85010894617","84995546450","84979529977","84979529977","84979529977","84979529977","84979529977","84969884848","84961590428","84961590428","84961590428","84961590428","84961590428","84954393300","84954393300","84954393300","84954393300","84954393300","84954393300","84954393300","85040798247","85040798247","85040798247","85040798247","85040798247","84939550750","84939550750","84930898445","85009157659","84887334076","84887334076","84945465077","84945465077","84913539983","84913539983","84913539983","85031497817","85017727085","85017727085","84929661398","84929661398","84929661398","84929661398","84929661398","84929661398","84928152140","84928152140","84928152140","84928152140","84928152140","84905976163","84905976163","84905976163","84905976163","84902263102","84902263102","84902263102","84902263102","84902263102","84902263102","84902263102","85099664609","85099664609","85099664609","84879522483","84873301123","84873301123","84873301123","84873301123","84873301123","84873287978","84873287978","84873287978","84864568988","84864568988","84864568988","84861707692","84861707692","84861707692","84861707692","84861707692","84861707692","84861707692","84861707692","84861665218","84861665218","80155123627","79960572874","79957661901","79957661901","80855129394","80855129394","80855129394","80855129394","80855129394","80855129394","80855129394","80855129394","78649710947","84886874793","84886874793","84886874793","84886874793","33750123489","27844554380","27844554380","60849095262","60849095262","60849095262","84986046302","84986046302","84986046302","84986046302","0032003546","84986047357","84986047357","84986116844","84986116844","2342460439","2342460439","2342460439","2342460439","2342460439"],"title":["Discovery-oriented consumer research",null,"Linguistic Cues to Deception Assessed by Computer Programs: A Meta-Analysis","A Framework for Big Data Analytics in Commercial Social Networks: A Case Study on Sentiment Analysis and Fake Review Detection for Marketing Decision-Making","WordNet: An Electronic Lexical Database",null,null,null,"Text Analytics with python","An Approach to Environmental Psychology","Satisfaction: A Behavioral Perspective on Customer","Measuring service quality: a reexamination and extension","Belief, attitude, intention, and behavior: an introduction to theory and research","Correspondence Analysis in Practice","A Primer on Partial Least Squares Structural Equation Modeling","Research Design: Qualitative, Quantitative, and Mixed Methods Approaches",null,"A new product growth for model consumer durables","Estimating vector autoregressions with panel data",null,"Possessions and the extended self","Transcendent customer experience and brand community","Grounding in Communication",null,null,"A Probabilistic Choice Model for Market Segmentation and Elasticity Structure",null,null,"Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","Text mining: Finding nuggets in mountains of textual data","Possessions and the extended self","A national customer satisfaction barometer: The Swedish experience","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality",null,null,"Automation assemblages in the internet of things: discovering qualitative practices at the boundaries of quantitative change","Regression Shrinkage and Selection via the Lasso",null,"A Paradigm for Developing Better Measures of Marketing Constructs",null,"User acceptance of computer technology: a comparison of two theoretical models","A national customer satisfaction barometer: the Swedish experience","Content analysis","Strengths and limitations of qualitative and quantitative research methods","DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","Approaches, tools and applications for sentiment analysis implementation","BERT: pre-training of deep bidirectional Transformers for language understanding","Introductory econometrics: A modern approach","Information and Consumer Behavior","Advertising as Information","Introduction to Modern Information Retrieval","Social media's impact on consumer mindset: When to use which sentiment extraction tool","Measuring consumer involvement profiles","Sentiment Analysis and Opinion Mining","Introduction to Information Retrieval","An exploration of the brand identity–brand image linkage: A communications perspective","Automatic text processing","Text mining",null,"Conceptualizing, measuring, and managing customer-based brand equity",null,null,"Testing competitive market structures","Customer-oriented approaches to identifying product-markets",null,"Alternative perceptual mapping techniques: relative accuracy and usefulness","A probabilistic choice model for market segmentation and elasticity structure","Strategic orientation o business enterprises: the construct, dimensionality and measurement","Market orientation: antecedents and consequences","The capabilities of market–driven organizations","Assessing advantage: a framework for diagnosing competitive superiority","Evaluating structural equation models with unobservable variables and measurement error",null,"Analyzing the past to prepare for the future: writing a literature review",null,"The effect of a market orientation on business profitability",null,"Marketing in new ventures: theory and empirical evidence","Regression shrinkage and selection via the Lasso",null,"Automation assemblages in the internet of things: Discovering qualitative practices at the boundaries of quantitative change",null,null,"BERT: Pre-training of deep bidirectional transformers for language understanding",null,"Word of mouse: The role of cognitive personalization in online consumer reviews","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence",null,"The information processing of pictures in print advertisements","Modeling goes to Hollywood: Predicting individual differences in movie enjoyment","Consumer skepticism of advertising claims: Testing hypotheses from economics of information","The experiential aspects of consumption: Consumer fantasies, feelings, and fun",null,"The emergence and evolution of consumer language research","How verb tense shapes persuasion","The effects of content characteristics on consumer engagement with branded social media content on Facebook","rtweet: Collecting and analyzing Twitter data",null,null,"academictwitteR: An R package to access the twitter academic research product track v2 API endpoint","quanteda: An R package for the quantitative analysis of textual data",null,"Tests of certain linear hypotheses and their application to some educational problems","Product consumption-based affective responses and post-purchase processes","Quanteda: An R package for the quantitative analysis of textual data",null,null,"The Information Processing of Pictures in Print Advertisements","Evaluating Structural Equation Models with Unobservable Variables and Measurement Error",null,"Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel",null,"Quanteda: An R package for the quantitative analysis of textual data","SERVPERF versus SERVQUAL: Reconciling performance-based and perceptions-minus-expectations measurement of service quality","The marketing aspects of service quality","SERVQUAL: A multiple item scale for measuring consumer perceptions of service quality","Possessions and the extended self","The emergence and evolution of consumer language research","Communicating brand personality: Are the websites doing the talking for the top South African business schools?",null,null,"How Verb Tense Shapes Persuasion",null,null,"Emotion","How online word-of-mouth impacts receivers","A correlated topic model of science","Web2.0: Conceptual foundations and marketinngissues",null,"Introduction to latent semantic analysis","Novelty, Complexity, and Importance as Causal Determinants of Industrial Buyer Behavior","The commitment-trust theory of relationship marketing","Business-to-Business Buying: Challenges and Opportunities","R (Software)","Relationship quality in services selling: an interpersonal influence perspective","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","A correlated topic model of science","The forms of capital","Conceptualizing, measuring, and managing customer-based brand equity","How verb tense shapes persuasion",null,null,"Regression shrinkage and selection via the lasso",null,"A social psychology of cultural dynamics: Examining how cultures are formed, maintained, and transformed","Prospect theory: An analysis of decision under risk",null,"Central and peripheral routes to advertising effectiveness: The moderating role of involvement","Measuring emotions in the consumption experience","Work and/or fun: Measuring hedonic and utilitarian shopping value","Investigating Romanian healthcare consumer behaviour in online communities: Qualitative research on negative eWOM","Effects of word-of-mouth and product-attribute information on persuasion: An accessibility-diagnosticity perspective","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","Sentiment analysis of twitter data","They predicted president trump and brexit",null,null,"Twitter sentiment classification using distant supervision","tidytext: text mining and analysis using tidy data principles in R",null,"The Persuasion Knowledge Model: How People Cope with Persuasion Attempts","Utilization of Mass Communication by the Individual, the Uses of Mass Communications: Current Perspectives on Gratifications Research","Information and consumer behavior","Advertising as information","Advertising as information","Speech Acts: an Essay in the Philosophy of Language","How to Do Things with Words","A performative view of language—methodological considerations and consequences for the study of culture","A new ANEW: evaluation of a word list for sentiment analysis in microblogs","A conceptual model of service quality and its implications for future research","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Variety-seeking behavior: An interdisciplinary review",null,"A conceptual model of service quality and its implications for future research","Note from special issue editors",null,"Sample Selection Bias as a Specification Error",null,"Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","Conceptualizing, measuring, and managing customer-based brand equity","Who is the celebrity endorser? Cultural foundations of the endorsement process","Self-concept in consumer behavior: A critical review","Evaluating structural equation models with unobservable variables and measurement error","Preprocessing techniques for text mining – an overview",null,"Experiential marketing",null,"Relationship marketing theory: Its roots and direction","Sympathy and callousness: The impact of deliberative thought on donations to identifiable and statistical victims","Public service advertisements: Emotions and empathy guide prosocial behavior",null,null,null,null,"Ontology Learning from Text: An Overview,” in","The Voice of the Customer","The House of Quality","Sympathy and Callousness: The Impact of Deliberative Thought on Donations to Identifiable and Statistical Victims","How Online Word-of-Mouth Impacts Receivers",null,null,"Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","SMOG grading - a new readability formula","The development and psychometric properties of LIWC2015","Speech acts: An essay in the philosophy of language","Grounding in communication","The development and psychometric properties of LIWC2015","Linguistic inquiry and word count: LIWC 2001","Adaptive selling: Conceptualization, measurement, and nomological validity","What makes a good salesman?","A framework for big data analytics in commercial social networks: A case study on sentiment analysis and fake review detection for marketing decision-making","Analyzing the past to prepare for the future: Writing a literature review",null,"Hedonic consumption: Emerging concepts, methods and propositions",null,"Consumer Perceptions of Price, Quality, and Value: A Means-End Model and Synthesis of Evidence","Possessions and the Extended Self","A Correlated Topic Model of Science",null,null,"The Experiential Aspects of Consumption: Consumer Fantasies, Feelings, and Fun","What makes a good salesman","Linguistic inquiry and word count: LIWC2015","The development and psychometric properties of LIWC2015","Tell me a story: A new look at real and artificial memory","Sensemaking in organizations","Assessing advantage: A framework for diagnosing competitive superiority","Content analysis in consumer research","Content analysis: An introduction to its methodology","The economic institutions of capitalism","The development and psychometric properties of LIWC2015","Logic and conversation","Content Analysis: An introduction to its methodology","Quantitative analysis of textual data","Gensim–Python framework for vector space modelling","LDAvis: a method for visualizing and interpreting topics","Controlling the false discovery rate: a practical and powerful approach to multiple testing",null,"Hotel guest satisfaction among business travelers: what are the important factors?","All reviews are not created equal: the disaggregate impact of reviews and reviewers at Amazon.Com",null,"Laddering theory, method, analysis, and interpretation","Testing competitive market structures","The Psychology of Personal Constructs","Principles of Marketing","AI adoption in the enterprise 2020","Emotions evoked by common words and phrases",null,"WordStat: Content Analysis Module for SIM- STAT","The Development and Psychometric Properties of LIWC2015. Austin, TX Univ. Texas Austin 1–22","The Development and Psychometric Properties of LIWC2007. Austin, Tx LIWC.Net 1","Managing Brand Equity","Multivariate Analysis","Alternative perceptual mapping techniques : relative accuracy and usefulness",null,"Relationship Quality in Services Selling: An Interpersonal Influence Perspective",null,"Are product attribute beliefs the only mediator of advertising effects on brand attitude?",null,null,"Self-Concept in Consumer Behavior: A Critical Review","Mapping Product Constellations: A Social Categorization Approach to Consumption Symbolism","Pipelines, Platforms, and the New Rules of Strategy",null,"Conceptualizing, Measuring, and Managing Customer-Based Brand Equity","Culture and Consumption: A Theoretical account of the Structure and Movement of the Cultural Meaning of Consumer Goods","Who Is the Celebrity Endorser? Cultural Foundations of the Endorsement Process","Marketing as Exchange","Possessions and the Extended Self",null,"Matrix Completion Methods for Causal Panel Data Models. Technical Report","Distributional Structure",null,null,null,null,null,"Alternative Perceptual Mapping Techniques: Relative Accuracy and Usefulness",null,"Laddering Theory, Method, Analysis, and Interpretation",null,"Preprocessing techniques for text mining-an overview","Customer satisfaction, market share, and profitability: findings from Sweden",null,"Approaches, Tools and Applications for Sentiment Analysis Implementation",null,"Statistical bibliography or bibliometrics",null,"A model of predictive measurements of advertising effectiveness","Attitudes towards the environment and green products: consumers’ perspective",null,"Text mining: the state of the art and the challenges",null,null,null,null,null,null,null,"Smart tourists and intelligent behavior","Management and leadership for digital transformation in tourism","Strategic use of information technologies in tourism - a review and critique","Belief, attitude, intention, and behavior: An introduction to theory and research","Evaluating structural equation models with unobservable variables and measurement error","Consumer skepticism of advertising claims: testing hypotheses from economics of information","LDAvis: A Method for Visualizing and Interpreting Topics",null,"Strengths and Limitations of Qualitative and Quantitative Research Methods",null,"Hotel Guest Satisfaction among Business Travelers: What Are the Important Factors?",null,"Critical Service Encounters: The Employee’s Viewpoint","A Script-Theoretic Analysis of Industrial Purchasing Behavior",null,null,null,null,"Scaling to very very large corpora for natural language disambiguation",null,null,null,null,"Nrc emotion lexicon","Tidytext: Text mining and analysis using tidy data principles in R","academictwitteR: An rpackage to access the twitter academic research","Can sustainability be luxurious? A mixed-method investigation of implicit and explicit attitudes towards sustainable luxury consumption","Rtweet: Collecting and analyzing Twitter data",null,"Statistical bibliography or bibliometrics",null,null,"The commitment-trust theory of relationship marketing",null,"Attitude towards the environment and green products: Consumers' perspective","The intellectual development of management information systems, 1972–1982: A co-citation analysis",null,null,null,null,null,"Software Framework for Topic Modelling with Large Corpora",". Efficient estimation of word representations in vector space",null,null,null,null,null,"Time-Oriented Advertising: A content analysis of United States magazine advertising, 1890-1988","On consumer beliefs about quality and taste","Distributional structure. In: Papers in Structural and Transformational","Measuring consumers’ luxury value perception: A cross-cultural framework",null,null,"A correlated topic model of science",null,null,null,"Measuring consumers’ luxury value perception: a cross-cultural framework","R (software)","Hedonic consumption: emerging concepts, methods and propositions","The biggest data challenges that you might not even know you have","A framework for big data analytics in commercial social networks: a case study on sentiment analysis and fake review detection for marketing decision-making","Social media use in the restaurant industry: A work in progress",null,"A two-step approach to quantitative content analysis: KH coder tutorial using Anne of Green gables (Part I)","A two-step approach to quantitative content analysis: KH coder tutorial using anne of Green gables (Part II)",null,"Conceptualizing, measuring, and managing customer-based brand equity",null,null,"Hedonic Consumption: Emerging Concepts, Methods, and Propositions","Social media e sentiment analysis",null,"Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon",null,null,"RoBERTa: A Robustly Optimized BERT Pretraining Approach","Social Hierarchy: The Self-Reinforcing Nature of Power and Status",null,"Indirect Speech Acts","Work and/or Fun: Measuring Hedonic and Utilitarian Shopping Value",null,null,null,"The Market Maven: A Diffuser of Marketplace Information",null,null,null,null,"Enriching word vectors with subword information",null,"Servqual: a multiple-item scale for measuring consumer perc","Consumer-based brand equity: development and validation of a measurement instrument",null,"Effects of word-of-mouth and product-attribute information on persuasion: an accessibility-diagnosticity perspective","Conceptualizing, measuring, and managing customer-based brand equity",null,"Online reviews: do consumers use them",null,"A logit model of brand choice cali-brated on scanner data","The Development and Psychometric Properties of LIWC 2015","Work and/or fun: measuring hedonic and utilitarian shopping value","Dplyr: A Grammar of Data Manipulation","Emotions evoked by common words and phrases: using Mechanical Turk to create an emotion lexicon","{LDA}vis: a method for visualizing and interpreting topics","tidytext: Text Mining and Analysis Using Tidy Data Principles in R","Utilization of mass communication by the individual","Servqual: a multiple-item scale for measuring consumer PERC","Cluster analysis in marketing research: review and suggestions for application",null,"Hedonic consumption: emerging concepts, methods and propositions","SERVPERF versus SERVQUAL: reconciling performance-based and perceptions-minus-expectations measurement of service quality","User acceptance of computer technology: a comparison of two theoretical models","Store atmosphere – an environmental psychology approach",null,"SERVQUAL: A multiple-item scale for measuring consumer perceptions of service quality","Note from special issue editors: advertising with user-generated content: a framework and research agenda","A conceptual model of service quality and its implications for future research","Evaluating service encounters: the effects of physical surroundings and employee responses","Consumer perception of product quality and the country-of-origin effect","Information and consumer behavior",null,null,null,null,null,"Measuring service quality: A reexamination and extension",null,"A multiple item scale for measuring consumer perceptions of service quality","Refinement and reassessment of the SERVQUAL instrument","Commercial Use of Conjoint Analysis: An Update","Conceptualizing, Measuring, and Managing Customer-Based Brand Equity","Reliability Measures for Qualitative Data: Theory and Implications","Analysis and Interpretation of Qualitative Data in Consumer Research","Discovery-Oriented Consumer Research","Dimensions of Consumer Expertise",null,null,"Public service advertisements: emotions and empath guide prosocial behavior",null,null,"Disruptive technologies: Catching the next wave",null,null,null,null,null,"A New Product Growth for Model Consumer Durables","All Hits Are Flukes: Institutionalized Decision Making and the Rhetoric of Network Prime-Time Program Development","A Social Psychology of Cultural Dynamics: Examining How Cultures Are Formed, Maintained, and Transformed","Variety Seeking Behavior: An Interdisciplinary Review","An exploration of the brand identity-brand image linkage: A communications perspective","\"It's really fascinating work\": Differences in evaluative adjectives across academic registers","Can sustainability be luxurious?","Text mining","Can sustainability be luxurious? A mixed-method investigation of implicit and explicit attitudes towards sustainable luxury consumption","Conceptualizing, measuring, and managing customer-based brand equity",null,null,"Does Consumer Promiscuity Influence Purchase Intent? The Role of AI, Change Seeking, and Pride","Your Screen-Time App Is Keeping Track’: Consumers Are Happy to Monitor but Unlikely to Reduce Smartphone Usage","Social Ties and Word-of-Mouth Referral Behavior","How word-of-mouth advertising works",null,null,null,null,"Subcultures of consumption: An ethnography of the new bikers",null,"Evaluating structural equation models with unobservable variables and measurement error","Keywords plus-ISI's breakthrough retrieval method. Part 1. Expanding your searching power on Current Contents on Diskette","Keywords plus takes you beyond title words. Part 2. Expanded journal coverage for Current Contents on Diskette, includes social and behavioral sciences","Possessions and the extended self",null,"A probabilistic choice model for market segmentation and elasticity structure","Negative word-of-mouth by dissatisfied consumers: a pilot study",null,"Neural and Intelligent Systems Integration","Regression shrinkage and selection via the lasso","Market Segmentation: Conceptual and Methodological Foundations","Ontology Learning from Text: Methods, Evaluation and Applications","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Econometric Analysis","SMOG grading: A new readability formula",null,"Estimating Vector Autoregressions with Panel Data","Software framework for topic modelling with large corpora",null,null,null,"Market orientation: The construct, research propositions, and managerial implications","Nudge: Improving decisions about health, wealth, and happiness","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","The development and psychometric properties of LIWC2015","Getting started with SAS® Text Miner 12.1","Marketing services: Competing through quality","The relationship between status consumption and materialism: A cross-cultural comparison of Chinese, Mexican, and American student","The market maven: A diffuser of marketplace information","The text mining handbook: Advanced approaches in analyzing unstructured data","The persuasion knowledge model: How people cope with persuasion attempts","Consumer perception of price, quality and value: a means‐end model and synthesis of evidence","A conceptual model of service quality and its implications for future research","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality",null,"Measuring service quality: a reexamination and extension","SERVPERF versus SERVQUAL: reconciling performance-based and perceptions-minus-expectations measurement of service quality",null,"LDAvis: A Method for Visualizing and Interpreting Topics. In Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, Baltimore, Maryland, USA, June 27","Adaptive Selling: Conceptualization, Measurement, and Nomological Validity","The Marketing Aspects of Service Quality","SERVQUAL: A Multiple-Item Scale for Measuring Consumer Perceptions of Service Quality","Refinement and Reassessment of the SERVQUAL Scale","A Conceptual Model of Service Quality and Its Implications for Future Research",null,"SERVQUAL: Review, Critique, Research Agenda","Measuring Service Quality: A Reexamination and Extension","The Persuasion Knowledge Model: How People Cope with Persuasion Attempts","Logic and Conversation",null,"Dimensions of Consumer Expertise","Tests of Certain Linear Hypotheses and Their Application to Some Educational Problems","Word of mouse: the role of cognitive personalization in online consumer reviews","Strategic brand management: Building, measuring, and managing brand equity","Role of product-related conversations in the diffusion of a new product","How damaging is negative word of mouth","The intellectual development of management information systems","Social hierarchy: The self-reinforcing nature of power and status","The Secret Life of Pronouns: What Our Words Say About Us","The Development and Psychometric Properties of LIWC2015","The Development and Psychometric Properties of LIWC2015","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Cultures and Organizations: Software of the Mind",null,null,"Belief, Attitude, Inten-tion, and Behavior: An Introduction to Theory and Research","Statistical bibliography or bibliometrics?","The information processing of pictures in print advertisements",null,null,"Social media use in the restaurant industry: A work in progress?",null,"Experiential marketing","The experiential aspects of consumption: consumer fantasies, feelings, and fun","The intellectual development of management information systems","Current comments. Keywords plus-ISIS breakthrough retrieval method. 1. Expanding your searching power on current-contents on diskette",null,null,"A correlated topic model of Science","Scalable recommendation with poisson factorization","A Logit Model of Brand Choice Calibrated on Scanner Data","A model for predictive measurements of advertising effectiveness",null,"Structural equation models with unobservable variables and measurement error: Algebra and statistics","User acceptance of computer technology: A comparison of two theoretical models","Evaluating structural equation models with unobservable variables and measurement error","Experiental marketing","The effect of a market orientation on business profitability","The market orientation: The construct, research propositions, and managerial implications","Critical service encounters: The employee’s viewpoint",null,null,"The world’s most influential CMOs 2017","The world’s most influential CMOs 2018","The world’s most influential CMOs 2019","Cluster analysis in marketing research: review and suggestions for application","Text Mining",null,null,"An exploration of the brand identity-brand image linkage: A communications perspective","The content analysis guidebook","Basic content analysis","Singapore's image as a tourist destination","Content analysis in communication research","An introduction to support vector machines and other kernel-based learning methods","A general psychoevolutionary theory of emotion","Text mining and analysis: Practical methods, examples, and case studies using SAS",null,"Servqual: a multiple-item scale for measuring consumer perceptions of service quality","SERVQUAL: review, critique, research agenda","Modern Optimization with R","Investigating Romanian healthcare consumer behaviour in online communities: qualitative research on negative eWOM","Social ties and word-of-mouth referral behavior","Sample selection bias as a specification error","Conceptualizing, measuring, and managing customer-based brand equity",null,"LDAvis: A method for visualizing and interpreting topics","A correlated topic model of science","Market Orientation: The Construct, Research Propositions, and Managerial Implications","The Commitment-Trust Theory of Relationship Marketing","The Effect of a Market Orientation on Business Profitability","The Capabilities of Market-Driven Organizations","Assessing Advantage: A Framework for Diagnosing Competitive Superiority","Market Orientation: Antecedents and Consequences","Emotion. Handbook of Social Psychology","Predicting the future with social media","The capabilities of market-driven organizations","Prospect theory: An analysis of decision under risk","Disruptive technologies","The commitment-trust theory of relationship marketing",null,null,null,"The brandscape: Converting image into equity","Virtual communities of consumption: Networks of consumer-knowledge and companionship","Information extraction","The voice of the customer","Conceptualizing, measuring and managing customer-based brand equity",null,null,"Reliability measures for qualitative data: theory and implications","Analysis and interpretation of qualitative data in consumer research",null,null,"Marketing as exchange","Time-Oriented advertising: a content analysis of United States magazine advertising, 1890-1988","Content analysis in consumer research","Content-analysis research: an examination of applications with directives for improving research reliability and objectivity","Becoming a consumer society: a longitudinal and cross-cultural content analysis of print ads from Hong Kong, the people’s republic of China, and Taiwan",null,"An analysis of transformations","Consumer selection of motion pictures","Modeling goes to hollywood: predicting individual differences in movie enjoyment","Evaluating structural equation models with unobservable variables and measurement error","The experiential aspects of consumption: consumer fantasies, feelings, and fun","The development and psychometric properties of LIWC2007","Controlling the false discovery rate: a practical and powerful approach to multiple testing",null,null,null,null,"Communicating brand personality: are the websites doing the talking for the top South African business schools?",null,"Structural Equation Models with Unobservable Variables and Measurement Error: Algebra and Statistics",null,null,null,null,"Marketing in new ventures: Theory and empirical evidence",null,null,"Psychographics: a critical review","The forms of capital",null,null,"Full Catastrophe Living (Revised Edition): How to Cope With Stress, Pain and Illness Using Mindfulness Meditation","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining",null,"Store atmosphere: An environmental psychology approach",null,"The experiential aspects of consumption: Consumer fantasies, feelings, and fun",null,"Sentiment analysis of Twitter data","Content-analysis research: An examination of applications with directives for improving research reliability and objectivity",null,null,"Sentiment analysis of Twitter data","Effects of word-of-mouth and product-attribute information on persuasion: an accessibility-diagnosticity perspective",null,null,null,null,null,"Diffusion of innovations","Twittersentimentclassificationusingdistantsupervision.CS224N project report","Deep learning","Supervised sequence labelling with recurrent neural networks","Efficient estimation of word representations in vector space","Learning phrase representations using RNN encoder-decoder for statistical machine translation","The Innovator's dilemma: When new technologies cause great firms to fail","Information and consumer behavior","Advertising as information","Hedonic consumption: Emerging concepts, methods and propositions",null,"Communicating Brand Personality: Are the Websites Doing the Talking for the Top South African Business Schools?",null,null,null,"Social Media’s Impact on Consumer Mindset: When to Use Which Sentiment Extraction Tool","A New Product Growth for Model Consumer Durables","‘All Hits Are Flukes’: Institutionalized Decision Making and the Rhetoric of Network Prime-Time Program Development","How Word-of-Mouth Advertising Works","Dimensions of consumer expertise","The persuasion knowledge model: How people cope with persuasion attempts","SMOG Grading—A New Readability Formula","Measuring Consumer Involvement Profiles","SMOG Grading—A New Readability Formula","LDAvis: A Method for Visualizing and Interpreting Topics","Scaling to Very Very Large Corpora for Natural Language Disambiguation","Strategic orientation of business enterprises: The construct, dimensionality, and measurement","Basic content analysis","Introductory econometrics: A modern approach","Market orientation: Antecedents and consequences","Market orientation: The construct, research propositions, and managerial implications","The effect of a market orientation on business profitability","The capabilities of market-driven organizations","Local Consumer Review Survey 2018","Information and Communication Technologies in Tourism","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","Content Analysis: An Introduction to Its Methodology","Who Is the Celebrity Endorser? Cultural Foundations of the Endorsement Process","The Development and Psychometric Properties of LIWC2007","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Speech Acts: An Essay in the Philosophy of Language","How to Do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Distinction: A Social Critique of the Judgement of Taste","The Forms of Capital","Experiencing Narrative Worlds: On the Psychological Activities of Reading","The capabilities of market-driven organizations","Prospect theory: an analysis of decision under risk","Market orientation: the construct, research propositions, and managerial implications",null,"Call for papers: rise of the machines? Customer engagement through automated service interactions","Rise of the machines?: customer engagement through automated service interactions, call for special section","Pipelines, platforms, and the new rules of strategy","A Correlated Topic Model of Science",null,"The voice of the customer",null,null,null,null,"Conceptualizing, measuring and managing customer-based brand equity",null,null,"An exploration of the brand identity-brand image linkage: A communications perspective",null,"Text Mining","Conceptualizing, measuring, and managing customer-based brand equity","It’s really fascinating work: Differences in evaluative adjectives across academic registers","Text mining","In the mind's eye: Transportation-imagery model of narrative persuasion",null,null,null,null,null,null,"A correlated topic model of science","Online consumer-generated reviews have significant impact on offline purchase behavior",null,"Experiential marketing","Transcendent customer experience and Brand community","The experiential aspects of consumption: consumer fantasies, feelings, and fun",null,null,"Evaluating Service Encounters: The Effects of Physical Surroundings and Employee Responses","The Service Encounter: Diagnosing Favorable and Unfavorable Incidences","Social Ties and Word-of-Mouth Referral Behavior","Consumer perceptions of price, quality, and value: a means-end model and synthesis of evidence","Laddering theory, method, analysis, and interpretation","Product-class effects on brand commitment and brand outcomes: the role of brand trust and brand affect","The experiential aspects of consumption: consumer fantasies, feelings, and fun",null,"On consumer beliefs about quality and taste","Distributional structure","An introduction to latent semantic analysis","Word-of-Mouth Communications: A Motivational Analysis",null,"Neural Networks for Pattern Recognition","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Statistical-Bibliography or bibliometrics?",null,"A script- theoretic analysis of industrial purchasing behavior","Novelty, complexity, and importance as causal determinants of industrial buyer behavior","The Commitment-Trust theory of relationship marketing","Business-to-Business Buying: challenges and opportunities","Social media's mindset: When to use which sentiment extraction tool?","Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon","When words sweat: Identifying signals for loan default in the text of loan applications","A new anew: Evaluation of a word list for sentiment analysis in microblogs","A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","The development and psychometric properties of LIWC2015","Twitter sentiment classification using distant supervision","Gensim-python framework for vector space modelling","Work and/or fun: Measuring hedonic and utilitarian shopping value","Use and Impact of Online Travel Reviews","Destinations’ Information Competition and Web Reputation","Web 2.0: Conceptual foundations and marketing issues",null,"Consumer Selection of Motion Pictures","Modeling Goes to Hollywood: Predicting Individual Differences in Movie Enjoyment",null,null,null,null,null,"A Performative View of Language—Methodological Considerations and Consequences for the Study of Culture","What Does Familiarity Breed? Complexity as a Moderator of Repetition Effects in Advertisement Evaluation","Which hotel attributes matter?","Introduction to information retrieval","Tidytext: Text mining and analysis using tidy data principles in r","Sentiment analysis of twitter data","Twitter sentiment classification using distant supervision","The voice of the customer","Distributional structure","The house of quality","Text Mining: The state of the art and the challenges Concept-based","A correlated topic model of science","Crisp-Dm 1.0",null,null,null,"A conceptual model of service quality and its implications for future research","SERVQUAL: a multiple item scale for measuring consumer perception of service quality","Customer satisfaction, market share and profitability: findings from Sweden","SERVQUAL: review, critique, research agenda","Measuring service quality: a reexamination and extension","SERVPERF versus SERVQUAL: reconciling performance-based and perceptions-minus-expectations measurement of service quality","Advertising as information","The Commitment-Trust Theory of Relationship Marketing","Measuring Emotions in the Consumption Experience","Product-Class Effects on Brand Commitment and Brand Outcomes: The Role of Brand Trust and Brand Affect","'Understanding the Socialized Body: A Poststructuralist Analysis of Consumers' Self-Conceptions, Body Images, and Self-Care Practices, '",null,null,null,null,"'Central and Peripheral Routes to Advertising Effectiveness: The Moderating Role of Involvement, '","'Subcultures of Consumption: An Ethnography of the New Bikers, '","'On Consumer Beliefs About Quality and Taste, '","'Culture and Consumption: A Theoretical Account of the Structure and Movement of the Cultural Meaning of Consumer Goods, '","Quantitative Text Analysis","'Communicating Brand Personality: Are the Websites Doing the Talking for the Top South African Business Schools?'",null,"In the Mind's Eye: Transportation-Imagery Model of Narrative Persuasion","Logic and Conversation","'Content Analysis in Consumer Research, '","'A Paradigm for Developing Better Measures of Marketing Constructs, '","'Hermeneutics and Consumer Research, '","'Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing, '","'An Analysis of Transformations, '",null,null,null,null,null,"Consumer-based brand equity: Development and validation of a measurement instrument","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence",null,null,"Conceptualizing, measuring, and managing customer-based brand equity",null,"WordNet: An electronic lexical database","lda: Collapsed Gibbs Sampling Methods for Topic Models","Introduction to Information Retrieval","LDAvis: A Method for Visualizing and Interpreting Topics","User-generated content and travel: A case study on Tripadvisor. Com","Product/consumption-based affective responses and post-purchase processes","Evaluating service encounters: The effects of physical surroundings and employee responses","Which hotel attributes matter? A review of previous and a framework for future research",null,"Online consumer-generated reviews have significant impact on offline purchase behavior",null,"Measuring Emotions in the Consumption Experience",null,"\"Indirect Speech Acts,\"",null,null,"Dimensions of consumer expertise","Ontology learning from text: Methods, evaluation and applications","The text mining handbook: Advanced approaches in analyzing unstructured data","A new product growth for model consumer durables","Approaches, tools and applications for sentiment analysis and implementation",null,null,null,"Online reviews: Do consumers use them","The Emotions: Facts, Theories, and a New Model","A General Psychoevolutionary Theory of Emotion","Role of Product-related Conversations in the Diffusion of a New Product","Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings","Learning to Classify Text Using Support Vector Machines: Methods, Theory and Algorithms","Biases in dynamic models with fixed effects. Econometrica",null,"Indirect speech acts","Indirect speech acts",null,null,"User-generated content and travel: A case study on TripAdvisor.com","A conceptual model of service quality and its implications for future research","Word-of-mouth communications: A motivational analysis","SERVQUAL: Review, critique, research agenda","Measuring service quality: A reexamination and extension","Use and impact of online travel reviews","Effects of word-of-mouth and product-attribute information on persuasion: An accessibility-diagnosticity perspective","Culture and Consumption: A Theoretical Account of the Structure and Movement of the Cultural Meaning of Consumer Goods","Consumer Perception of Product Quality and the Country-of-Origin Effect",null,null,null,null,"Singapore’s image as a tourist destination","Relationship marketing theory: its roots and direction","Psychographics: A critical review","Effects of word-of-mouth and product-attribute information on persuasion: An accessibility–diagnosticity perspective","Quantitative text analysis","Destinations' information competition and web reputation","Conceptualizing, measuring, and managing customer-based brand equity","What does familiarity breed? Complexity as a moderator of repetition effects in advertisement evaluation",null,"Prospect theory: An analysis of decision under risk","Linguistic cues to deception assessed by computer programs: A meta-analysis","Role of product-related conversations in the diffusion of a new product",null,"Text mining","The brandscape. converting image into equity","Customer-oriented approaches to identifying product-markets","Virtual communities of consumption: Networks of consumer knowledge and companionship","Conceptualizing, measuring and managing customer-based brand equity",null,"Modeling goes to hollywood: Predicting individual differences in movie enjoyment",null,null,"The experiential aspects of consumption: Consumer fantasies, feelings, and fun","A probabilistic choice model for market segmentation and elasticity structure",null,"Role of product-related conversations in the diffusion of a new product","The service encounter: diagnosing favorable and unfavorable incidents","User acceptance of computer technology: a comparison of two theoretical models","Word-of-mouth communications: a motivational analysis","Role of product-related conversations in the diffusion of a new product","A new product growth model for consumer durables","Possessions and the extended self","How damaging is negative word of mouth?","The market maven: a diffuser of marketplace information","Content analysis in consumer research","The service encounter: Diagnosing favorable and unfavorable incidents","Ward's clustering algorithm","Negative word-of-mouth by dissatisfied consumers: A pilot study","Mapping product constellations: A social categorization approach to consumption symbolism","The effect of a market orientation on business profitability",null,"Market orientation: Antecedents and consequences","Market orientation: The construct, research propositions, and managerial implications","Assessing advantage: A framework for diagnosing competitive superiority","Biases in dynamic models with fixed effects",null,"Grounding in communication","Are product attribute beliefs the only mediator of advertising effects on brand attitude","Negative word of mouth by dissatisfied consumers: A pilot study",null,"Conditional random fields: Probabilistic models for segmenting and labeling sequence data","Opinion observer: Analyzing and comparing opinions on the Web",null,"Testing competitive market structures","Identifying competitive product markets: A review of customer oriented approaches","Text mining: Finding nuggets in mountains of textual data",null,null,null,null,null,"The service encounter: diagnosing favorable and unfavorable incidents","Measuring interpersonal influence in online conversations",null,null,"Testing competitive market structure","Commercial use of conjoint analysis: An update","The dimensions of reputation in electronic markets","The voice of the customer","The house of quality","A probabilistic choice model for market segmentation and elasticity structure","Opinion observer: Analyzing and comparing opinions on the web","Opinion observer: Analyzing and comparing opinions on the web","Store atmosphere: An environmental psychology approach","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","Measuring consumer involvement profiles","Understanding the socialised body: A poststructuralist analysis of consumers’ self conceptions, body images, and self care practices",null,"Hermeneutics and consumer research",null,"The service encounter: Diagnosing favorable and unfavorable incidents","Ward’s clustering algorithm","Negative word-of-mouth by dissatisfied consumers: A pilot study",null,null,"AParadigmforDevelopingBetterMeasuresofMarketing Constructs,”","The relationship between statusconsumption and materialism: Across- cultural comparison of Chinese, Mexican and American students,”",null,"Neurolinguistic programming (NLP) and its applications to marketing research","Neuro-linguistic programming: implications for advertising and copy strategy","Neuro-linguistic programming (NLP) and its applications to marketing research","Neuro- linguistic programming: implications for advertising and copy strategy","Content Analysis in Consumer Research","Content-Analysis Research: An Examination of Applications with Directives for Improving Research Reliability and Objectivity","Cluster Analysis in Marketing Research: Review and Suggestions for Application","Content Analysis of Print Ads from Hong Kong, the People's Republic of China, and Taiwan",null],"sourcetitle":["Journal of Consumer Researcch","Linguistic Inquiry and Word Count: LIWC2015","Proceedings of The Workshop on Computational Approaches to Deception Detection","Industrial Marketing Management","Memory (Hove, England)","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","The Development and Psychometric Properties of LIWC2015","SERVQUAL: A Multiple-Item Scale for Measuring Consumer Perceptions of Service Quality",null,null,null,"J. Market.","Philos. Rhetor.",null,null,null,"Diffusion of innovations","Management Science","Econometrica","Managing brand equity","Journal of Consumer Research","Journal of the Academy of Marketing Science","In Perspectives on Socially Shared Cognition","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Neural and Intelligent Systems Integration","Journal of Marketing Research","Ontology Learning from Text: Methods, Evaluation and Applications","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Consumer Research","Journal of Marketing","Proceedings of the 5th ACM SIGKDD international conference on knowledge discovery and data mining","Journal of Consumer Research","Journal of Marketing","Journal of Marketing","Text data management and analysis: a practical introduction to information retrieval and text mining","Full catastrophe living","Journal of Consumer Research","Journal of the Royal Statistical Society: Series B (Methodological)","Linguistic Inquiry and Word Count: LIWC2015","Journal of Marketing Research","Linguistic Inquiry and Word Count: LIWC 2001","Management Science","Journal of Manufacturing Technology Management","International Encyclopedia of Communication","European Journal of Education Studies",null,"Int. J. Comput. Appl.",null,null,"Journal of Political Economy","Journal of Political Economy",null,"Marketing Science Institute Working Paper Series","Journal of Marketing Research",null,null,"Journal of Brand Management","The Transformation, Analysis and Retrieval of Information by Computer","Practical handbook of internet computing","Managing brand equity: Capitalizing on the value of a brand name","Journal of Marketing","Strategic brand management: Building, measuring, and managing brand equity","Strategic Brand Management: Building, measuring and management brand equity","Marketing Science","Journal of Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing Research","Journal of Marketing Research","Management Science","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing Research","A Primer on Partial Least Squares Structural Equation Modeling (PLS-SEM)","Management Information Systems Quarterly","Modern Optimization with R","Journal of Marketing","The Content Analysis Guidebook","Schmalenbach Business Review","Journal of the Royal Statistical Society, Series B (Methodological)","Introduction to information retrieval","Journal of Consumer Research","The development and psychometric properties of LIWC2015","Enriching word vectors with subword information. ArXiv Preprint arxiv:1607.04606v2","ArXiv preprint","A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","Journal of Interactive Advertising","Journal of Marketing","All reviews are not created equal: The disaggregate impact of reviews and reviewers at amazon. Com. Working Paper","Journal of Consumer Research","Management Science","Journal of Consumer Research","Journal of Consumer Research","Introduction to mediation, moderation, and conditional process analysis: A regression-based approach","Journal of Consumer Research","Journal of Consumer Research","Marketing Science Institute Working Paper Series","Journal of Open Source Software","Linguistic inquiry and word count: LIWC2015","The development and psychometric properties of LIWC2015","Journal of Open Source Software","Journal of Open Source Software","Introduction to mediation, moderation, and conditional process analysis: A regression-based approach","Statistical Research Memoirs","Journal of Marketing Research","Journal of Open Source Software","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Roberta: A Robustly Optimized Bert Pretraining Approach","Journal of Consumer Research","Journal of Marketing Research","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Naval Technical Training Command","Research design: Qualitative and quantitative approaches","Journal of Open Source Software","Journal of Marketing","Emerging perspectives in service marketing.","Journal of Retailing","Journal of Consumer Research","Journal of Consumer Research","Journal of Brand Management","Linguistic inquiry and word count: LIWC2015","The Emergence and Evolution of Consumer Language Research,” Journal of Consumer Research (published online February 17), https://doi.org/10.1093/jcr/ucad013","Journal of Consumer Research","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Handbook of Social Psychology","Consumer Psychology Review","The Annals of Applied Statistics","Journal of Direct, Data and Digital Marketing Practice","Social media’s impact on consumer mindset: When to use which sentiment extraction tool","Discourse Processes","Journal of Marketing","Journal of Marketing","Customer Needs and Solutions","The International Encyclopedia of Communication Research Methods","Journal of Marketing","Journal of Marketing","The Annals of Applied Statistics","Handbook of theory and research for the sociology of education","Journal of Marketing","Journal of Consumer Research","The development and psychometric properties of LIWC2015","Diffusion of innovations","Journal of the Royal Statistical Society: Series B (Methodological)","An introduction to support vector machines and other kernel-based learning methods","Social and Personality Psychology Compass","Econometrica","An approach to environmental psychology","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Procedia-Social and Behavioral Sciences","Journal of Consumer Research","Journal of Consumer Research","Proceedings of the workshop on languages in social media. Association for computational linguistics","CNN","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Modern Optimization with R","CS224N Project Report, Stanford","The Journal of Open Source Software","Research design: qualitative, quantitative, and mixed methods approaches","The Journal of Consumer Research",null,"J. Polit. Econ.","J. Polit. Econ.","J. Polit. Econ.",null,null,"Forum Qual. Soc. Res.","Proceedings of the ESWC2011 Workshop on ‘making Sense of Microposts’: Big Things Come in Small Packages","J. Market.","J. Retailing","Journal of Consumer Research","The development and psychometric properties of LIWC2015","Journal of Marketing","Journal of Interactive Advertising","Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding","Econometrica","Linguistic Inquiry and Word Count: LIWC2015","Journal of Marketing","Journal of Marketing","Journal of Consumer Research","Journal of Consumer Research","Journal of Marketing Research","International Journal of Computer Science and Communication Networks","The development and psychometric properties of LIWC2015","Journal of Marketing Management","An Approach to Environmental Psychology","Journal of Marketing Management","Organizational Behavior and Human Decision Processes","The Journal of Marketing","Efficient Estimation of Word Representations in Vector Space. Arxiv Preprint Arxiv","Deep learning","Market segmentation : Conceptual and methodological foundations","Introduction to Modern Information Retrieval","Ontology Learning from Text: Methods, Evaluation and Applications","Marketing Science","Harvard Business Review","Organizational Behavior and Human Decision Processes","Consumer Psychology Review","The Development and Psychometric Properties of LIWC2015","Introduction to Mediation, Moderation, and Conditional Process Analysis, Second Edition: A Regression-Based Approach","Journal of Consumer Research","Journal of Reading",null,null,"Perspectives on socially shared cognition",null,null,"Journal of Marketing Research","Harvard Business Review","Industrial Marketing Management","MIS Quarterly","Belief, attitude, intention, and behavior: An introduction to theory and research","Journal of Marketing","LDAvis: A Method for Visualizing and Interpreting Topic Models","Journal of Marketing","Journal of Consumer Research","The Annals of Applied Statistics","Lda: Collapsed Gibbs Sampling Method for Topic Models","Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research","Journal of Consumer Research","Harvard Business Review",null,null,null,null,"Journal of Marketing","Journal of Consumer Research",null,null,null,"Speech acts",null,null,"NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Journal of the Royal Statistical Society. Series B (Methodological)","Which hotel attributes matter? A review of previous and a framework for future research","Cornell Hotel and Restaurant Administration Quarterly","SSRN Electronic Journal","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","J. Advert. Res.","Market. Sci.",null,null,null,"Proc. NAACL-HLT","Information and Consumer Behavior",null,null,null,null,null,"J. Market. Res.","Content Analysis. An Introduction to Its Methodology","Journal of Marketing","Logic and Conversation,” in Syntax and Semantics: Speech Acts","Journal of Marketing Research","Managing brand equity: Capitalizing on the value of a brand name","The Development and Psychometric Properties of LIWC2015","Journal of Consumer Research","Psychology & Marketing (1986-1998)","Harvard Business Review","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Marketing","Journal of Consumer Research","Journal of Consumer Research","Journal of Marketing","Journal of Consumer Research","A New Anew: Evaluation of a Word List for Sentiment Analysis in Microblogs","National Bureau of Economic Research, https://www.nber.org/system/files/working_papers/w25132/w25132.pdf","Word","Learning to Classify Text Using Support Vector Machines","Cultures and organizations: Software of the mind","The emotions: Facts, theory and a new model","Linguistic Inquiry and Word Count: LIWC2015","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing Research","The Psychology of Personal Constructs: Vol 1 and 2","Journal of Advertising Research","Nudge: Improving decisions about health, wealth, and happiness","International Journal of Computer Science and Communication Networks","The Journal of Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","International Journal of Computer Applications","Sentiment Analysis and Opinion Mining","Journal of Documentation","Neural networks for pattern recognition","Journal of Marketing","Management Science and Engineering","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","Proceedings of the PAKDD Workshop on Knowledge Discovery from Advanced Databases","Sentiment Analysis and Opinion Mining","Neural and Intelligent Systems Integration","The Development and Psychometric Properties of LIWC2015","Sentiment Analysis and Opinion Mining","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Deep Learning","Ontology Learning from Text: Methods, Evaluation and Applications","Handbook of e-Tourism","Handbook of e-Tourism","Handbook of e-Tourism",null,"Journal of Marketing Research","J. Consum. Res.","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","The Development and Psychometric Properties of LIWC2015","European Journal of Education Studies","Scalable Recommendation with Poisson Factorization","Cornell Hotel and Restaurant Administration Quarterly","Linguistic Inquiry and Word Count: LIWC [Computer software]","Journal of Marketing","Journal of Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Introduction to Information Retrieval","WordNet : An Electronic Lexical Database, Language, Speech, and Communication","Correspondence Analysis in Practice","Proceedings of the 39th Annual Meeting on Association for Computational Linguistics - ACL ’01. Presented at the the 39th Annual Meeting, Association for Computational Linguistics","Roberta: A robustly optimized bert pretraining approach","Bert: Pretraining of deep bidirectional transformers for language understanding","Conditional random fields: Probabilistic models for segmenting and labeling sequence data","Bert: Pre-training of deep bidirectional transformers for language understanding","National Research Council","Journal of Open Source Software","Journal of Open Source Software","Advances in Consumer Research","Journal of Open Source Software","Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding","Journal of Documentation","Introduction to modern information retrieval","Content analysis: An introduction to its methodology","Journal of Marketing","Cultures and organizations: Software of the mind","Management Science and Engineering","Management Science","BERT: pre-training of deep bidirectional transformers for language understanding","RoBERTa: A robustly optimized BERT pretraining approach","Learning phrase representations using rnn encoder-decoder for statistical machine translation","Deriva-tion of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Person-nel","Linguistic Inquiry and Word Count: Liwc2015","Proceedings of the LREC 2010 Workshop on New Chal-lenges for NLP Frameworks","In Proceedings of Workshop at ICLR, 2013","A new ANEW: Evaluation of a word list for sentiment analysis in microblogs","The development and psychometric properties of LIWC2015","The development and psychometric properties of LIWC2015","Linguistic inquiry and word count 2015: LIWC2015","The development and psychometric properties of LIWC 2015","Journal of Marketing","Journal of Consumer Research","Linguistics","Academy of Marketing Science Review","Cultures and Organizations: Software of the Mind. Intercultural Cooperation and Its Importance for Survival","An approach to environmental psychology","The Annals of Applied Statistics","How to Do Things with Words","Introduction to Information Retrieval","Bert: Pre-training of Deep Bidirectional Transformers for Language Understanding [J]","Academy of Marketing Science Review","The International Encyclopedia of Communication Research Methods","Journal of Marketing","IBM","Industrial Marketing Management","Cornell Hospitality Report","Introduction to modern information retrieval","Ritsumeikan Social Sciences Review","Ritsumeikan Social Sciences Review","An approach to environmental psychology","Journal of Marketing","The content analysis guidebook","The text mining handbook","Journal of Marketing","L'evoluzione dei fenomeni sociali attraverso la rete","Introduction to Information Retrieval","Proceedings of the Naacl-Hlt 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The Development and Psychometric Properties of LIWC2015","arXiv","Academy of Management Annals","The Development and Psychometric Properties of LIWC2015","Synthese","Journal of Consumer Research","Distinction: A Social Critique of the Judgement of Taste","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Marketing","Derivation of New Readability Formulas (Automated Readability Index, Fog Count, and Flesch Reading Ease Formula) for Navy Enlisted Personnel","The Development and Psychometric Properties of LIWC 2015","Text Mining and Analysis: Practical Methods, Examples, and Case Studies using SAS®","DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","Transactions of the Association for Computational Linguistics","The Innovator’s Dilemma: When New Technologies Cause Great Firms to Fail","Journal of Retailing","Journal of Marketing Management","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Consumer Research","Journal of Marketing","Managing Brand Equity","ACR 2001 Proceedings","Deep Learning","Marketing Sci",null,"J. Consum. Res.",null,"Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces",null,"The Uses of Mass Communications: Current Perspectives on Gratifications Research","Journal of Retailing","Journal of Marketing Research","An Approach to Environmental Psychology, An Approach to Environmental Psychology","Journal of Marketing","Journal of Marketing","Management Science","Journal of Retailing","The Development and Psychometric Properties of LIWC 2015","Journal of Retailing","Journal of Interactive Advertising","Journal of Marketing","Journal of Marketing","Journal of International Marketing","Journal of Political Economy","dplyr: A grammar of data manipulation","Local Consumer Review Survey 2020","The Development and Psychometric Properties of LIWC2007","AI adoption in the enterprise 2020","Matrix completion methods for causal panel data models","J. Marketing","RoBERTa: A robustly optimized BERT pretraining approach","J. Retailing","J. Retailing","Journal of Marketing","Journal of Marketing","Journal of Marketing Research","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Econometric Analysis","Tell me a Story: A New Look at Real and Artificial Memory","Journal of Marketing","Linguistic inquiry and word count (LIWC): LIWC2015","Linguistic inquiry and word count (LIWC): LIWC2007","Harvard Business Review","The innovator’s dilemma. When new technologies cause great firms to fail","When Words Sweat: Identifying Signals for Loan Default in the Text of Loan Applications","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Diffusion of Innovations","Management Science","American Journal of Sociology","Social and Personality Psychology Compass","Journal of Consumer Research","Journal of Brand Management","Language and Computers","Advances in Consumer Research Conference Proceedings","Practical handbook of internet computing","Advances in Consumer Research","Journal of Marketing","Strategic brand management: Building, measuring, and managing brand equity","The Development and Psychometric Properties of LIWC 2015","Journal of the Association for Consumer Research","Journal of the Association for Consumer Research","Journal of Consumer Research","Harvard Business Review","Introduction to mediation, moderation, and conditional process analysis: A regression-based approach","Principles of marketing","The Development and Psychometric Properties of LIWC2015","The economic institutions of capitalism","Journal of Consumer Research","Diffusion of innovations","Journal of Marketing Research","Current Contents","Current Contents","Journal of Consumer Research","Distinction: A social critique of the judgement of taste","J. Market. Res.","J. Market.","Getting Started with SAS® Text Miner",null,"J. Roy. Stat. Soc. B",null,null,null,null,"Journal of Reading","The Development and Psychometric Properties of LIWC 2015","Econometrica","Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks","Text analytics with Python: A practitioner's guide to natural language processing","BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding","WordNet: An electronic lexical database","Journal of Marketing",null,"Journal of Marketing",null,null,null,"Journal of Marketing Theory and Practice","Journal of Marketing",null,"Journal of Consumer Research","Journal of Marketing","Journal of Marketing","Journal of Retailing","Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer","Journal of Marketing","Journal of Marketing","Content Analysis: An Introduction to its Methodology","Association for Computational Linguistics","Journal of Marketing Research","Emerging Perspectives on Services Marketing","Journal of Retailing","Journal of Retailing","Journal of Marketing","The Development and Psychometric Properties of LIWC2015","European Journal of Marketing","Journal of Marketing","Journal of Consumer Research","Syntax and Semantics","Introduction to Mediation, Moderation and Conditional Process Analysis: A Regression-Based Approach","Journal of Consumer Research","Statistical Research Memoirs","Journal of Interactive Advertising",null,"Journal of Marketing Research","Marketing Bulletin","Management Science","The Academy of Management Annals",null,null,null,null,null,"Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding[J]","Roberta: A Robustly Optimized Bert Pretraining Approach[J]","Philosophy and Rhetoric","Journal of Documentation","Journal of Consumer Research","Content analysis: An introduction to its methodology","Satisfaction: A behavioral perspective on the consumer","Center for Hospitality Research Publications","Modern Optimization with R","Journal of Marketing Management","Journal of Consumer Research","Management Science","Current Contents","The biggest data challenges that you might not even know you have","Market segmentation conceptual and methodological foundations","Annals of Applied Statistics","arXiv Preprint","Marketing Science","Journal of Marketing","The development and psychometric properties of LIWC2015","Journal of Marketing Research","Management Science","Journal of Marketing Research","Journal of Marketing Management","Journal of Marketing","Journal of Marketing","Journal of Marketing","The secret life of pronouns: What our words say about us","The development and psychometric properties of LIWC2015","Forbes","Forbes","Forbes","Journal of Marketing Research","Practical Handbook of Internet Computing","Social Media e Sentiment Analysis. L'evoluzione dei fenomeni sociali attraverso la Rete","Strategic Brand Management","Journal of Brand Management",null,null,"International Journal of Tourism Research",null,"An Introduction to Support Vector Machines and Other Kernel-based Learning Methods","Emotion Theory, Research, and Experience",null,"Bert: Pretraining of Deep Bidirectional Transformers for Language Understanding","J. Retailing","Eur. J. Market.",null,"Procedia - Social and Behavioral Sciences","Journal of Consumer Research","Econometrica","Journal of Marketing","Principles of marketing","Proc. Workshop Interactive Language Learn. Visualization Interfaces","Ann. Appl. Statist","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing",null,null,"Journal of Marketing","Econometrica","Harvard Business Review","Journal of Marketing","The Development and Psychometric Properties of LIWC 2015","Automatic text processing: The transformation, analysis, and retrieval of information by computer","Managing brand equity. Capitalizing on the value of a brand names","ADMAP","Doctoral Dissertation","The text mining Handbook: Advanced approaches in analyzing unstructured data","Marketing Science","Journal of Marketing","Strategic brand management: Building, measuring, and managing brand equity","Content analysis. An introduction to its methodology","Journal of Marketing Research","Journal of Consumer Research","CRISP-DM 1.0 step-by-step data mining guide","The Text Mining Handbook","Journal of Marketing","Journal of Marketing","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Basic Content Analysis","Journal of the Royal Statistical Society: Series B (Methodological)","The Motion Picture Mega-Industry","Management Science","Journal of Marketing Research","Journal of Consumer Research","LIWC2007 Manuel","Journal of the Royal Statistical Society: Series B (Methodological))","Content Analysis: An Introduction to Its Methodology","The Content Analysis Guidebook","Speech Acts: An Essay in the Philosophy of Language","Content Analysis: An Introduction to Its Methodology","Journal of Brand Management","Linguistic Inquiry and Word Count: LIWC 2015","Journal of Marketing Research","Econometric Analysis","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Introductory econometrics: A modern approach","The development and psychometric properties of LIWC2015","Schmalenbach Business Review","The Secret Life of Pronouns","The development and psychometric properties of LIWC2015","Journal of Marketing Research","The Handbook of Theory and Research for the Sociology of Education","Research Design: Qualitative, Quantitative, and Mixed Methods Approaches","Correspondence Analysis in Practice",null,null,"The development and psychometric properties of LIWC2015","Journal of Retailing","The text mining handbook: Advanced approaches in analyzing unstructured data","Journal of Consumer Research","Multivariate data analysis","LSM ’11 Proceedings of the Workshop on Languages in Social Media","Journal of Consumer Research","Content Analysis","Basic Content Analysis","Proceedings of the Workshop on Languages in Social Media","Journal of Consumer Research","They Predicted President Trump and Brexit","Local Consumer Review Survey","Diffusion of Innovations","Distributional Structure","Online Consumer-Generated Reviews Have Significant Impact on Offline Purchase Behavior",null,"Stanford",null,null,"arXiv preprint arXiv","arXiv",null,"Journal of Political Economy","Journal of Political Economy","Journal of Marketing","Diffusion of Innovations","Journal of Brand Management","WordStat: Content Analysis Module for SIMSTAT","Linguistic Inquiry and Word Count: LIWC2015","Scalable Recommendation with Poisson Factorization","Marketing Science Institute Working Paper Series","Management Science","American Journal of Sociology","Harvard Business Review","Journal of Consumer Research","Journal of Consumer Research","Journal of Reading","Journal of Marketing Research","Journal of Reading","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics","Management Science",null,null,"The Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing",null,null,"Journal of Consumer Research",null,"Journal of Consumer Research",null,null,null,null,null,null,"Handbookd of Theory and Research for the Sociology of Education",null,"Journal of Marketing","Econometrica","Journal of Marketing","Supervised Sequence Lagelling with Recurrent Neural Networks","Journal of Service Research","Journal of Service Research","Harvard Business Review","Annals of Applied Statistics","The Text Mining Handbook","Marketing Science","Introduction to Information Retrieval","The Development and Psychometric Properties of LIWC2015","Managing Brand Equity. Capitalizing on the Value of a Brand Names","Information Extraction. The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Content Analysis. An Introduction to Its Methodology","The Journal of Brand Management","Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer","Practical Handbook of Internet Computing","Journal of Marketing","Language and Computers","Practical Handbook of Internet Computing","Narrative Impact: Social and Cognitive Foundations","Econometric Analysis, 7th Ed","Introduction to Mediation, Moderation, and Conditional Process Analysis","Content Analysis: An Introduction to Its Methodology","The Development and Psychometric Properties of LIWC2007","All Reviews Are Not Created Equal: The Disaggregate Impact of Reviews and Reviewers at Amazon.com","Experiencing Narrative Worlds: On the Psychological Activities of Reading","The Annals Of Applied Statistics","comScore","An Approach to Environmental Psychology","Journal of Marketing Management","Journal of the Academy of Marketing Science","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Quantitative Analysis of Textual Data","Journal of Marketing","Journal of Marketing","Journal of Consumer Research","J. Mark.","J. Advert. Res.","Brand Manag.","J. Consum. Res.","The development and psychometric properties of LIWC2015","Journal of Consumer Research","Word","Discourse Processes","Advances in Consumer Research",null,null,null,"Journal of Documentation","Market Orientation","Journal of Marketing","Journal of Marketing","Journal of Marketing","Customer Needs and Solutions","Marketing Science Institute working paper series",null,null,null,null,null,"CS224N project report","NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic","Journal of Consumer Research","Information and Communication Technologies in Tourism","Information Technology & Tourism","Journal of Direct, Data and Digital Marketing Practice","Introduction to Information Retrieval","The Motion Picture Mega-Industry","Management Science","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The Development and Psychometric Properties of LIWC2007","Speech Acts: An Essay in The Philosophy of Language","The Effects of Content Characteristics on Consumer Engagement with Branded Social Media Content on Facebook","How to Do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Forum: Qualitative Social Research","Journal of Consumer Research","A review of previous and a framework for future research",null,"The Journal of Open Source Software","Proceeding LSM ‘11 proceedings of the workshop on languages in social media","CS224N project report","Marketing Sci","Word","Harvard Bus. Rev.","Paper Presented in Proceedings of the PAKDD 1999 Workshop on Knowledge Discovery from Advanced Databases","The Annals of Applied Statistics","CRISP-DM Consortium","Linguistic Inquiry and Word Count: LIWC 2001. [computer software]","Sentiment Analysis and Opinion Mining","A new ANEW: evaluation of a word list for sentiment analysis in microblogs","Journal of Marketing","Journal of Retailing","Journal of Marketing","European Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Political Economy","Journal of Marketing","Journal of Consumer Research","Journal of Brand Management","Journal of Consumer Research","WordStat: Content Analysis Module for Simstat","Linguistic Inquiry and Word Count","Linguistic Inquiry and Word Count (LIWC): Liwc2007","The Development and Psychometric Properties of LIWC2015","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Handbook of Multimethod Measurement in Psychology","Journal of Brand Management","Content Analysis: An Introduction to Its Methodology","Narrative Impact: Social and Cognitive Foundations","Syntax and Semantics","Journal of Consumer Research","Journal of Marketing Research","Journal of Consumer Research","Journal of the Royal Statistical Society. Series B (Methodological)","Journal of the Royal Statistical Society. Series B (Methodological)","\"Affective Norms for English Words (Anew): Instruction Manual and Affective Ratings\"","NRC Emotion Lexicon","Sentiment Analysis and Opinion Mining","Principles of Marketing","Marketing Services—Competing through Quality","Journal of Marketing Management","The Journal of Marketing","Managing Brand Equity Capitalizing on the Value of A Brand Name","Managing Brand Equity","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Language","R Package, Version 1.4.2",null,"Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Information and Communication Technologies in Tourism","Journal of Marketing Research","Journal of Marketing","Proceedings of the 9th annual conference of the Asia Pacific Tourism Association (APTA)","Text mining: Finding nuggets in mountains of textual data","comScore","The Development and Psychometric Properties of LIWC2007","Journal of Consumer Research","Speech Acts: An Essay in the Philosophy of Language, Cambridge, UK","ACM SIGART Bulletin, Syntax and Semantics","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Consumer Research",null,null,"Manag. Sci.","International Journal of Computer Applications","The Text Mining Handbook","An Introduction to Information Retrieval","Introduction to Modern Information Retrieval","Advances in Consumer Research",null,"Theories of Emotion","Journal of Marketing Research","Technical Report. Technical Report C-1",null,"J. Econometric Soc","Speech Acts: An Essay in the Philosophy of Language","Syntax and Semantics 3: Speech Acts","Synthese","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Content Analysis: An Introduction to its Methodology","Information and Communication Technologies in Tourism 2008, 2","The Journal of Marketing","Advances in Consumer Research","European Journal of Marketing","The Journal of Marketing","Information and Communication Technologies in Tourism 2008, 2","Journal of Consumer Research","Journal of Consumer Research","Journal of International Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Econometric Analysis","Cultures and Organizations: Software of the Mind","Multivariate data analysis: A global perspective","International Journal of Tourism Research","Journal of Marketing Management","Journal of Marketing Research","Journal of Consumer Research","Handbook of multimethod measurement in psychology","Information Technology & Tourism","The Journal of Marketing","Journal of Consumer Research","An introduction to mediation, moderation, and conditional process analysis: A regression-based approach","Econometrica","Proceedings of the European Chapter for the Association for Computational Linguistics: Computational Approaches to Deception Detection Workshop","Journal of Marketing Research","WordNet: An Electronic Lexical Database","Practical Handbook of Internet Computing",null,"Journal of Marketing",null,"Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Management Science","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Multivariate Data Analysis","Journal of Consumer Research","Journal of Marketing Research","Diffusion of Innovations","J. Market. Res.","J. Market.","Manag. Sci.","Adv. Consum. Res.","J. Mark. Res.","Manage. Sci.","J. Consum. Res.","Mark. Bull.","J. Mark.","J. Consum. Res.","Journal of Marketing","Encyclopedia of Statistical Sciences","Journal of Marketing","Psychology and Marketing","J. Marketing","Introductory Econometrics: A Modern Approach","J. Marketing","J. Marketing","J. Marketing","Econometrica","The Development and Psychometric Properties of LIWC 2007","Perspectives on Socially Shared Cognition","Journal of Marketing Research","Journal of Marketing","Diffusion of innovations","Proc. 18th Internat. Conf. Machine Learn","Proc. 14th Internat. Conf. World Wide Web","Introduction to Modern Information Retrieval","Marketing Sci","J. Marketing","Proc. Fifth ACM SIGKDD Internat. Conf. Knowledge Discovery Data Mining","Measuring Interpersonal Influence in Online Conversations","The Text Mining Handbook","Wordnet: An Electronic Lexical Database","The Dimensions of Reputation in Electronic Markets","Predicting the Future with Social Media","Journal of Marketing",null,"Content Analysis: An Introduction to Its Methodology","Introduction to Modern Information Retrieval","Marketing Science","Journal of Marketing","NYU Center for Digital Economy Research Working Paper No. CeDER-06-02","Marketing Science","Harvard Business Review","Journal of Marketing Research","WWW '05: Proceedings of the 14th International Conference on World Wide Web","Proceedings of the 14th International Conference on World Wide Web","Journal of Retailing","Journal of Consumer Research","Journal of Marketing Research","Journal of Consumer Research","\"Speech Act: An Essay in the Philosophy of Language\".","J. Cons. Res.","Sensemaking in Organizations","Journal of Marketing","Encyclopedia of Statistical Sciences","Journal of Marketing","Basic Content Analysis","Contentanalysis Incommunicationresearch","Journal of Marketing Research","Journal of Marketing Theory and Practice","Automatic Text Processing: the Transformation, Analysis, and Retrieval of Information by Computer, Addison-Wesley Publishing Company, Inc. USA","Canadian Journal of Marketing Research","Proceedings of the 1990 Conference of the American Academy of Advertising","Canadian Journal of Marketing Research","Proceedings of the 1990 Conference of the American Academy of Advertising","Journal of Consumer Research","Journal of Consumer Research","Journal of Marketing Research","Journal of Consumer Research","Basic Content Analysis"],"year":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],"author-list.author.ce:indexed-name":["Wells W.","Pennebaker James W.","Hauch Valerie","Kauffmann Erick","Fellbaum Christiane","Hayes A.F.","Pennebaker J.","Parasuraman A.","Sarkar D.","Mehrabian A.","Oliver R.L.","Cronin J.J.J.","Fishbein M.","Greenacre M.","Hair J.","Cresswell J.W.","Rogers E.","Bass F.M.","Holtz-Eakin D.","Aaker D.A.","Belk R.W.","Schouten J.W.",null,"Hayes A.F.","Soucek B.","Kamakura W.A.","Buitelaar P.","Feldman R.","Herr P.M.","Zeithaml V.A.","Dorre J.","Belk R.W.","Fornell C.","Parasuraman A.","Zhai C.","Kabat-Zinn J.","Novak T.P.","Tibshirani R.","Pennebaker J.W.","Churchill G.A.","Pennebaker J.W.","Davis F.D.","Fornell C.","Krippendorff K.","Queiros A.","Sanh V.","D'Andrea A.","Devlin J.","Wooldridge J.M.","Nelson P.","Nelson P.","Salton G.","Kubler R.V.","Laurent G.","Liu B.","Manning C.D.","Nandan S.","Salton G.","Witten I.H.","Aaker D.A.","Keller K.L.","Keller K.L.","Keller K.L.","Urban G.L.","Day G.S.","Feldman R.","Hauser J.R.","Kamakura W.A.","Venkatraman N.","Jaworski B.J.","Day G.S.","Day G.S.","Fornell C.","Hair J.F.","Webster J.","Cortez P.","Narver J.C.","Neuendorf K.A.","Gruber M.","Tibshirani R.","Manning C.D.","Novak T.","Pennebaker J.W.","Bojanowski P.","Devlin J.","Pang B.","Xia L.","Zeithaml V.A.","Chen P.Y.","Edell J.A.","Eliashberg J.","Ford G.T.","Holbrook M.B.","Hayes A.F.","Packard G.","Packard G.","Stephen A.T.","Kearney M.W.","Pennebaker J.W.","Pennebaker J.W.","Barrie C.","Benoit K.","Hayes A.F.","Johnson P.O.","Westbrook R.A.","Benoit K.","Devlin J.","Liu Y.","Edell J.A.","Fornell C.","Hayes A.F.","Kincaid J.P.","Creswell J.W.","Benoit K.","Cronin J.J.","Lewis C.","Parasuraman A.","Belk R.W.","Packard G.","Opoku R.","Pennebaker J.W.","Packard G.","Packard G.","Pennebaker J.W.","Pennebaker J.W.","Keltner D.","Moore S.G.","Blei D.M.","Constantinides E.","Kubler R.","Landauer T.K.","McQuiston D.H.","Morgan R.M.","Grewal R.","Breuer J.","Crosby L.A.","Zeithaml V.A.","Blei D.M.","Bourdieu P.","Keller K.L.","Packard G.","Pennebaker J.W.","Rogers E.M.","Tibshirani R.","Cristianini N.","Kashima Y.","Kahneman D.","Mehrabian A.","Petty R.","Richins M.L.","Babin B.J.","Gheorghe I.R.","Herr P.M.","Holbrook M.B.","Agarwal A.","McKenzie D.","Devlin J.","Cortez P.","Go A.","Silge J.","Creswell J.W.","Friestad M.","Katz E.","Nelson P.","Nelson P.","Nelson P.","Searle J.R.","Austin J.L.","Barinaga E.","Nielsen F.A.","Parasuraman A.","Parasuraman A.","McAlister L.","Pennebaker J.W.","Parasuraman A.","Krishnamurthy S.","Devlin J.","Heckman James J.","Pennebaker James A","Zeithaml V.A.","Keller K.L.","McCracken G.","Sirgy M.J.","Fornell C.","Vijayarani S.","Pennebaker J.W.","Schmitt B.","Mehrabian A.","Moller K.","Small D.A.","Bagozzi R.P.","Mikolov T.","Goodfellow I.","Wedel M.","Salton G.","Buitelaar P.","Griffin A.","Hauser J.R.","Small Deborah A.","Moore Sarah G.","Pennebaker James W.","Hayes Andrew F.","Herr Paul M.","McLaughlin H.G.","Pennebaker J.W.","Searle J.R.","Clark H.H.","Pennebaker J.W.","Pennebaker J.W.","Spiro R.L.","Mayer D.","Kauffmann E.","Webster J.","Fishbein M.","Hirschman E.C.","Sievert C.","Zeithaml V.A.","Belk R.W.","Blei D.M.","Chang J.","Fishbein M.","Holbrook M.B.","Mayer D.","Pennebaker J.W.","Pennebaker J.W.","Schank R.C.","Weick K.E.","Day G.S.","Kassarjian H.H.","Krippendorff K.","Williamson O.","Pennebaker J.W.","Grice H.P.","Krippendorff K.","Benoit K.","Rehurek R.","Sievert C.","Benjamini Y.","Dolnicar S.","Gundersen M.G.","Chen P.-Y.","Hayes A.F.","Reynolds T.J.","Urban G.L.","Kelly G.A.","Kotler P.","Magoulas R.","Mohammad S.","Nelson P.","Peladeau N.","Pennebaker J.W.","Pennebaker J.W.","Aaker D.A.","Hair J.F.","Hauser J.R.","Krippendorff K.","Crosby L.A.","Grice H.P.","Mitchell A.A.","Aaker D.A.","Pennebaker James W.","Sirgy M. Joseph",null,"Van Alstyne Marshall W.","Hayes Andrew F.","Keller Kevin Lane","McCracken Grant",null,"Bagozzi Richard P.","Belk Russell W.","Nielsen F.A.","Athey S.","Harris Z.S.","Joachims T.","Hofstede G.","Plutchik R.","Pennebaker J.W.","Feldman R.","Hauser J.R.","Kelly G.A.","Reynolds T.J.","Thaler R.H.","Vijayarani S.","Anderson E.W.","Feldman R.","D'Andrea A.","Liu B.","Pritchard A.","Bishop C.M.","Lavidge R.","Chen T. B.","Zhai C. X.","Tan A.-H.","Liu B.","Soucek B.","Pennebaker J.W.","Liu B.","Feldman R.","Goodfellow I.","Buitelaar P.","Pearce P.L.","Pesonen J.","Fuchs M.","Fishbein M.","Fornell C.","Ford G.T.","Sievert Carson","Pennebaker James W.","Queiros Andre","Gopalan Prem","Gundersen Marit G.","Pennebaker J.W.","Bitner M.J.","Leigh T.W.","Feldman R.","Manning C.D.","Fellbaum C.","Greenacre M.","Banko M.","Liu Y.","Devlin J.","Lafferty J.","Devlin J.","Mohammad S.M.","Silge J.","Barrie C.","Beckham D.","Kearney M.W.","Devlin J.","Pritchard A.","Salton G.","Krippendorff K.","Morgan R.M.","Hofstede G.","Chen T.B.","Culnan M.J.","Devlin J.","Liu Y.","Cho K","Kincaid JP","Pennebaker J","Rehurek R","Mikolov T.K.","Nielsen F.A.","Pennebaker J.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Gross B.L.","Spiller S.A.","Harris Z.","Wiedmann K.P.","Hofstede G.","Mehrabian A.","Blei D.M.","Austin J.L.","Manning C.","Devlin J.","Wiedmann K.-P.","Breuer J.","Hirschman E.C.","Schneider C.","Kauffmann E.","Needles A.","Salton G.","Higuchi K.","Higuchi K.","Mehrabian A.","Keller K.L.","Neuendorf K.","Feldman R.","Hirschman E.C.","CERON A.","MANNING D. CH.","MOHAMMAD S.M.","ZHAI CH.","Pennebaker J.W.","Liu Y.","Magee J.C.","Pennebaker J.W.","Asher N.","Babin B.J.","Bourdieu P.","Hayes A.F.","Hayes A.F.","Feick L.F.","Kincaid J.P.","Pennebaker J.W.","Chakraborty G.","Sanh V.","Bojanowski P.","Christensen C.M.","Parasuraman A.","Vazquez R.","Hayes A.F.","Herr P.M.","Keller K.L.","Aaker D.A.","Chatterjee P.","Goodfellow I","Guadagni PM","Pennebaker J.W.","Babin B.J.","Wickham H.","Mohammad S.","Sievert C.","Silge J.","Katz E.","Parasuraman A.","Punj G.","Mehrabian A.","Hirschman E.C.","Cronin J.J.","Davis F.D.","Donovan R.J.","Pennebaker James W.","Parasuraman A.","Krishnamurthy S.","Parasuraman A.","Bitner M.J.","Elliott G.R.","Nelson P.","Wickham H.",null,"Pennebaker J.W.",null,"Athey S","Cronin JJ","Liu Y","Parasuraman A","Parasuraman AA","Wittink D.R.","Keller K.L.","Rust R.T.","Spiggle S.","Wells W.D.","Alba J.W.","Greene W.H.","Schank R.C.","Bagozzi R.P.","Pennebaker J.","Pennebaker J.","Bower J.","Christensen C.","Netzer Oded","Pennebaker J. W.","Pennebaker J.W.","Rogers Everett M.","Bass Frank","Bielby William T.","Kashima Yoshihisa","McAlister Leigh","Nandan S.","Swales J.M.","Voyer B.G.","Witten I.H.","Beckham D.","Keller K.L.","Keller K.L.","Pennebaker James W.","Van Esch Patrick","Zimmermann Laura","Brown J.J.","Dichter E.","Hayes A.F.","Kotler P.","Pennebaker J.W.","Williamson O.E.","Schouten J.W.","Rogers E.M.","Fornell C.","Garfield E.","Garfield E.","Belk R.W.","Bourdieu P.","Kamakura W.A.","Richins M.L.","SAS","Soucek B.","Tibshirani R.","Wedel M.","Buitelaar P.","Feldman R.","Greene W.H.","McLaughlin G.H.","Pennebaker J.W.","Holtz-Eakin D.","Rehureksojka R.P.","Sarkar D.","Devlin J.M.W.","Fellbaum C.","Kohli A.K.","Thaler R.H.","Zeithaml V.A.","Pennebaker J.W.","SAS","Berry L.L.","Eastman J.K.","Feick L.F.","Feldman R.","Friestad M.","Zeithaml V.","Parasuraman A.","Parasuraman A.","Salton G.","Cronin J.J.","Cronin J.J.","Krippendorff K.","Carson S.","Spiro Rosann L.","Lewis Robert C.","Parasuraman A.",null,"Parasuraman A.","Pennebaker James W.","Buttle Francis","Cronin J. Joseph","Friestad Marian","Grice Herbert P.","Hayes Andrew F.","Alba Joseph W.","Johnson Palmer O.","Xia L.","Keller K.L.","Arndt J.","Charlett D.","Culnan M.","Magee J.C.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Hayes A.F.","Hofstede G.","Devlin J.","Liu Y.","Fishbein Martin","Pritchard A.","Edell J.A.","Krippendorff K.","Oliver R.L.","Needles A.","Cortez P.","Schmitt B.","Holbrook M.B.","Culnan M.","Garfield E.","Schneider C.","Wedel M.","Blei D.M.","Gopalan P.K.","Guadagni P.M.","Lavidge R.J.","Pennebaker J.W.","Fornell C.","Davis F.D.","Fornell C.","Schmitt B.","Narver J.C.","Kohli A.K.","Bitner M.J.","Pennebaker J.W.","Pennebaker J.W.","Rooney J.","Rooney J.","Rooney J.","Punj G.","WITTEN I.H.","CERON A.","KELLER K.L.","NANDAN S.","Neuendorf K.A.","Weber R.","Hui T.K.","Berelson B.","Shawe-Taylor J.","Plutchik R.","Chakraborty G.","Devlin J.","Parasuraman A.","Buttle F.","Cortez P.","Gheorghe L.R.","Johnson-Brown J.","Heckman J.J.","Keller K.L.","Kotler P.","Sievert C","Blei DM","Kohli A.K.","Morgan R.M.","Narver J.C.","Day G.S.","Day G.S.","Jaworski B.J.","Keltner D.","Asur S.","Day G.S.","Kahneman D.","Bower J.L.","Morgan R.M.","Pennebaker J.W.","Salton G.","Aaker D.A.","Biel A.L.","De Valck K.","Feldman R.","Griffin A.","Keller K.L.","Keller K.L.","Krippendorff K.","Rust R.T.","Spiggle S.","Chapman P.","Feldman R.","Bagozzi R.P.","Gross B.L.","Kassarjian H.H.","Kolbe R.H.","Tse D.K.","Weber R.P.","Box G.E.P.","De Silva I.","Eliashberg J.","Fornell C.","Holbrook M.B.","Pennebaker J.W.","Benjamini Y.","Krippendorf K.","Neuendorf K.A.","Searle J.R.","Krippendorff K.","Opoku R.","Pennebaker J.W.","Fornell C.","Greene W.H.","Hayes A.F.","Wooldridge J.","Pennebaker J.W.","Gruber M.","Pennebaker J.W.","Pennebaker J.W.","Wells W.D.","Bourdieu P.","Creswell J.W.","Greenacre M.","Kabat-Zinn J.","Zhai C.X.","Pennebaker J.W.","Donovan R.","Feldman R.","Holbrook M.B.","Hair J.F.","Agarwal A.","Kolbe R.H.","Krippendorff K.","Weber R.","Agarwal A.","Herr P.M.","McKenzie D.",null,"Rogers E.M.","Harris Z.",null,"Rogers E.M.","Go A.","Goodfellow I.","Graves A.","Mikolov T.","Cho K.","Christensen C.M.","Nelson P.","Nelson P.","Hirschman E.C.","Rogers E.M.","Opoku R.","Peladeau N.","Pennebaker J.W.","Gopalan P.","Kubler R.V.","Bass F.M.","Bielby W.","Dichter E.","Alba J.","Friestad M.","McLaughlin G.H.","Laurent G.","McLaughlin G.H.","Sievert C.","Banko M.","Venkatraman N.","Weber R.P.","Wooldridge J.M.","Jaworski B.J.","Kohli A.K.","Narver J.C.","Day G.S.","BrightLocal","Gretzel U.","Herr P.M.","Krippendorff K.","McCracken G.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Searle J.R.","Austin J.L.","Bourdieu P.","Bourdieu P.","Gerrig R.J.","Day G.S.","Kahnemann D.","Kohli A.K.","Graves A.","Hollebeek L.D.","Hollebeek L.","Van Alstyne M.W.","Blei D.M.","Feldman R.","Griffin A.","Manning D.","Pennebaker J.","AAker D.A.","FelDMAN r.","keller k.l.","keller k.l.","krippeNDorFF k.","NANDAN S.","SAlToN G.","WiTTeN i.H.","KELLER K.L.","SWALES J.M.","WITTEN I.H.","Green M.C.","Greene W.H.","Hayes A.F.","Krippendorff K.","Pennebaker J.W.","Chen P.-Y.","Gerrig R.J.","Blei D.M.","Lipsman A.","Mehrabian A.","Schmitt B.H.","Schouten J.W.","Holbrook M.B.","Pennebaker J.","Benoit K.","Bitner M.J.","Bitner M.J.","Brown J.J.","Zeithaml V.A.","Reynolds T.J.","Chaudhuri A.","Holbrook M.B.","Pennebaker J.W.","Spiller S.A.","Harris Z.S.","Landauer T.K.","Sundaram D.S.","Tan A.H.","Bishop C.M.","Feldman R.","Pritchard J.","Ajay K.","Leigh T.W.","McQuiston D.H.","Morgan R.M.","Grewal R.","Kubler R.V.","Mohammad S.M.","Netzer O.","Nielsen F.","Pang B.","Pennebaker J.W.","Go A.","Rehurek R.","Babin B.J.","Gretzel U.","Inversini A.","Constantinides E.","Manning C.D.","De Silva I.","Eliashberg J.","Zhai C.X.","Pennebaker J.W.","Searle J.","Stephen A.T.","Austin J.L.","Barinaga E.","Cox D.S.","Dolnicar S.","Manning C.","Silge J.","Agarwal A.","Go A.","Griffin A.","Harris Z.S.","Hauser J.R.","Tan A.","Blei D.M.","Chapman P.","Pennebaker J.W.","Liu B.","Nielsen F.A.","Parasuraman A.","Parasuraman A.","Anderson E.W.","Buttle F.","Cronin J.J.","Cronin J.J.","Nelson P.","Morgan Robert","Richins Marsha L.","Chaudhuri Arjun","Thompson C.J.","Peladeau N.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Petty R.E.","Schouten J.W.","Spiller S.A.","McCracken G.","Mehl M.R.","Opoku R.","Krippendorff K.","Green M.C.","Grice H.P.","Kassarjian H.H.","Churchill G.A.","Arnold S.J.","Benjamini Y.","Box G.E.P.","Bradley M.M.",null,"Liu B.","Kotler P.","Berry L.","Vazquez R.","Zeithaml V.A.","Aaker D.A.","Aaker D.A.","Keller K.L.","Keller K.L.","Fellbaum C.","Chang J.","Manning C.D.","Sievert C.","O'Connor P.","Westbrook R.A.","Bitner M.J.","Dolnicar S.","Dorre J.","Lipsman A.","Pennebaker James W.","Richins Marsha L.","Searle J.R.","Searle J.R.","Austin J.L.","Feldman R.","Alba J.W.","Buitelaar P.","Feldman R.","Bass F.M.","D'Andrea A.","Feldman R.","Manning C.D.","Salton G.","Chatterjee P.","Plutchik R.","Plutchik R.","Arndt J.","Bradley M.M.","Joachims T.","Nickell S.","Searle J.R.","Searle J.","Asher N.","Austin J.L.","Krippendorff K.","O'Connor P.","Parasuraman A.","Sundaram D.S.","Buttle F.","Cronin J.J.","Gretzel U.","Herr P.M.","Grant M.","Elliott G.R.","Feldman R.","Greene W.H.","Hofstede G.","Hair J.F.","Hui T.K.","Moller K.","Wells W.D.","Herr P.M.","Mehl M.R.","Inversini A.","Keller K.L.","Cox D.S.","Hayes A.F.","Kahnemann D.","Hauch V.","Arndt J.","Fellbaum C.","Witten I.H.","Biel A.L.","Day G.S.","de Valck K.","Keller K.L.","Keller K.L.","Eliashberg J.","Feldman R.","Hair J.","Holbrook M.B.","Kamakura W.A.","Rogers E.M.","Arndt J.","Bitner M.J.","Davis F.D.","Sundaram D.S.","Arndt J.","Bass F.","Belk R.W.","Charlett D.","Feick L.F.","Kassarjian H.H.","Bitner M.J.","Mojena R.","Richins M.L.","Solomon M.R.","Narver J.C.","Wooldridge J.","Jaworski B.J.","Kohli A.K.","Day G.S.","Nickell S.","Pennebaker J.W.","Clark H.H.","Mitchell A.A.","Richins M.L.","Rogers E.","Lafferty J.","Liu B.","Salton G.","Urban G.L.","Day G.","Dorre J.","Dwyer P.","Feldman R.","Fellbaum C.","Ghose A.","Asur S.","Bitner M.","Dwyer P.","Krippendorff K.","Salton G.","Johnson P.L.","Wittink D.R.","Ghose A.","Griffin A.","Hauser J.R.","Kamakura W.A.","Liu B.","Lui B.","Donovan R.J.","Holbroock M.","Laurent G.","Thompson C.","Searle J.R.","Arnold S.J.","Weick K.E.","Bitner M.J.","Mojena R.","Richins M.L.","Weber R.","Berelson B.","Churchill G.A.","Eastman J.K.","Salton G.","Chakrapani C.","Orr B.H.","Chakrapani C.","Orr B.H.","Kassarjian H.H.","Kolbe R.H.","Punj G.","Tse D.K.","Weber R.P."]},"columns":[{"id":"scopus_id","name":"scopus_id","type":"character","minWidth":100,"maxWidth":200},{"id":"citing_art","name":"citing_art","type":"character","minWidth":100,"maxWidth":200},{"id":"title","name":"title","type":"character","minWidth":250,"maxWidth":200},{"id":"sourcetitle","name":"sourcetitle","type":"character","minWidth":100,"maxWidth":200},{"id":"year","name":"year","type":"character","minWidth":100,"maxWidth":200},{"id":"author-list.author.ce:indexed-name","name":"author-list.author.ce:indexed-name","type":"character","minWidth":100,"maxWidth":200}],"groupBy":["scopus_id"],"striped":true,"dataKey":"b79871b24b26457e8e1765849d00bd11"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</section>
<section id="correct-inconsistencies" class="level4" data-number="5.1.3">
<h4 data-number="5.1.3" class="anchored" data-anchor-id="correct-inconsistencies"><span class="header-section-number">5.1.3</span> Correct inconsistencies</h4>
<p>We correct inconsistencies in the data. Some <code>scopus_id</code> identifiers have multiple different values of title, sourcetitle, authorname, etc. (even only minor differences). For data consistency and future plot of networks, we need to have only one unique value for each variable of <code>scopus_id</code>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standardize_values(df, groupby_column, value_column):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Standardize the values of the specified column based on the most frequent non-empty value and fewest characters </span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co">    within each group.</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - df: DataFrame</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - groupby_column: The column by which we group data.</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - value_column: The column whose values we want to standardize based on the rules.</span></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co">    - DataFrame with standardized values.</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> custom_mode(series):</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Remove NA values and other representations of NA</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>        series <span class="op">=</span> series.dropna()</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>        series <span class="op">=</span> series[<span class="op">~</span>series.isin([<span class="st">''</span>, <span class="st">'NA'</span>])]</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If all values were NA or empty</span></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> series.empty:</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> np.nan  <span class="co"># Using numpy's nan for consistency</span></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get value counts</span></span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> series.value_counts()</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there's a single most common value, return it</span></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(counts) <span class="op">==</span> <span class="dv">1</span> <span class="kw">or</span> counts.iloc[<span class="dv">0</span>] <span class="op">!=</span> counts.iloc[<span class="dv">1</span>]:</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> counts.idxmax()</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If multiple values have the same max count, apply further rules</span></span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>        top_values <span class="op">=</span> counts[counts <span class="op">==</span> counts.iloc[<span class="dv">0</span>]].index.tolist()</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sort by fewest characters</span></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a>        sorted_by_chars <span class="op">=</span> <span class="bu">sorted</span>(top_values, key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">len</span>(x))</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there's a single value with the fewest characters, return it</span></span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(sorted_by_chars) <span class="op">==</span> <span class="dv">1</span> <span class="kw">or</span> <span class="bu">len</span>(sorted_by_chars[<span class="dv">0</span>]) <span class="op">!=</span> <span class="bu">len</span>(sorted_by_chars[<span class="dv">1</span>]):</span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> sorted_by_chars[<span class="dv">0</span>]</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the column is not the author's name, apply the uppercase letter rule.</span></span>
<span id="cb37-42"><a href="#cb37-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> value_column <span class="op">!=</span> <span class="st">"author_name"</span>:  <span class="co"># adjust "author_name" to the correct column name if necessary</span></span>
<span id="cb37-43"><a href="#cb37-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">sorted</span>(sorted_by_chars, key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> c <span class="kw">in</span> x <span class="cf">if</span> c.isupper()), reverse<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb37-44"><a href="#cb37-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb37-45"><a href="#cb37-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> sorted_by_chars[<span class="dv">0</span>]</span>
<span id="cb37-46"><a href="#cb37-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-47"><a href="#cb37-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the most common value for each group based on the custom mode</span></span>
<span id="cb37-48"><a href="#cb37-48" aria-hidden="true" tabindex="-1"></a>    most_common_value <span class="op">=</span> df.groupby(groupby_column)[value_column].<span class="bu">apply</span>(custom_mode).to_dict()</span>
<span id="cb37-49"><a href="#cb37-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-50"><a href="#cb37-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Map the most common values to the dataframe based on the group</span></span>
<span id="cb37-51"><a href="#cb37-51" aria-hidden="true" tabindex="-1"></a>    df[value_column] <span class="op">=</span> df[groupby_column].<span class="bu">map</span>(most_common_value)</span>
<span id="cb37-52"><a href="#cb37-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-53"><a href="#cb37-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb37-54"><a href="#cb37-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-55"><a href="#cb37-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-56"><a href="#cb37-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage example:</span></span>
<span id="cb37-57"><a href="#cb37-57" aria-hidden="true" tabindex="-1"></a>list_references_standardized <span class="op">=</span> standardize_values(list_references, <span class="st">'scopus_id'</span>, <span class="st">'title'</span>)</span>
<span id="cb37-58"><a href="#cb37-58" aria-hidden="true" tabindex="-1"></a>list_references_standardized <span class="op">=</span> standardize_values(list_references_standardized, <span class="st">'scopus_id'</span>, <span class="st">'sourcetitle'</span>)</span>
<span id="cb37-59"><a href="#cb37-59" aria-hidden="true" tabindex="-1"></a>list_references_standardized <span class="op">=</span> standardize_values(list_references_standardized, <span class="st">'scopus_id'</span>, <span class="st">'author-list.author.ce:indexed-name'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="check-inconsistencies" class="level4" data-number="5.1.4">
<h4 data-number="5.1.4" class="anchored" data-anchor-id="check-inconsistencies"><span class="header-section-number">5.1.4</span> Check inconsistencies</h4>
<p>We check that the inconsistencies have been corrected.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>check_inconsistencies <span class="ot">&lt;-</span> py<span class="sc">$</span>list_references_standardized <span class="sc">%&gt;%</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(scopus_id <span class="sc">%in%</span> py<span class="sc">$</span>inconsistent_scopus_id) <span class="sc">%&gt;%</span> <span class="co">#we take the inconsistent scopus_id from python by using reticulate</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(scopus_id, citing_art, title, sourcetitle, year, <span class="st">`</span><span class="at">author-list.author.ce:indexed-name</span><span class="st">`</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>  check_inconsistencies,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">groupBy =</span> <span class="st">"scopus_id"</span>,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">100</span>, <span class="at">maxWidth =</span> <span class="dv">200</span>),  <span class="co"># Adjust these values as needed</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">columns =</span> <span class="fu">list</span>(</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">250</span>)  <span class="co"># Adjust this value based on the length of your titles</span></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div class="reactable html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-324c6b8fb24021ad7d31" style="width:auto;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-324c6b8fb24021ad7d31">{"x":{"tag":{"name":"Reactable","attribs":{"data":{"scopus_id":["21144479982","0003710039","84870885352","85098710831","0004289791","84870854437","64949089948","0001312089","85033687876","0003667583","0003868827","0002381637","0003248898","34249879981","84870388697","0141988044","0003584083","0001449665","0002816448","0004048902","84936628342","67649153594","0001927247","84870854437","0003517644","0000917415","33646714870","38149091464","0001559313","0002667763","0012960262","84936628342","0002469577","0001312089","85013304526","0003608927","85153747795","0001287271","0003710039","0001878819","0003710039","84936823933","0002469577","0004040339","85044163613","85083322291","85013120533","85057019815","0003678180","0000424077","0001181569","0003653039","85055278050","0002183204","84862732380","34548080780","33646864881","0003882234","84872195089","0004048902","21144478550","0004266342","0004266342","0001721941","0002546379","38149091464","0000392294","0000917415","0000102571","21144463066","0040984002","0002607378","0000009769","84870388697","0012903874","84923351534","0002954788","0004230731","33645675879","0001287271","34548080780","85153747795","64949089948","85031013784","85057019815","84964770022","78649311561","0002667763","77649141031","0002680840","0000659566","0000771343","0002126713","84870854437","85158837449","85150697324","85015236485","85085117614","0003710039","64949089948","85116889672","85059176675","84870854437","0002074493","0000922949","85059176675","85057019815","85076489289","0002680840","0000009769","84870854437","0004029218","0141988044","85059176675","0007744069","0001925995","0001312089","84936628342","85158837449","70349460990","0003710039","85158837449","85150697324","0003710039","64949089948","78650393330","85082024558","52449116403","63349083646","85055278050","80053431219","0002671212","21344475322","85020481177","85090707944","0003056894","0002667763","52449116403","0002538481","21144478550","85150697324","64949089948","0003584083","0001287271","0003798635","66249144220","0000125532","0003667583","0000428577","21744438808","21344485409","84940046213","0001559313","0002126713","84856343452","85099424156","85057019815","84923351534","79953762206","85021643438","0141988044","21344490393","0002535326","0000424077","0001181569","0001181569","0003488717","0003586486","85055363420","84875062524","0002408510","0001312089","0000200753","64949089948","0002408510","80055049753","85057019815","0000125534","0003710039","0002667763","21144478550","0001469895","0001561946","0000009769","84973537408","64949089948","0013168260","0003667583","0001884325","34548820027","21344477997","84903761492","84944735469","0003550676","0003653039","33646714870","0004816858","0001772263","34548820027","85082024558","64949089948","84870854437","0001559313","0001736594","64949089948","0003488717","0001927247","64949089948","0003710039","0002373795","0010737688","85098710831","0012903874","0003551671","0002020889","84956473495","0002667763","84936628342","52449116403","83055176929","0003551671","0002126713","0010737688","0003710039","64949089948","0003670522","0003767234","0002607378","0002934032","0004040339","0003531998","64949089948","0000534475","0004040339","84989220223","84893112707","84956473495","0001677717","10644254015","33846300647","77649141031","84870854437","0003054392","0001721941","0003654618","0004079982","85083439798","79958249386","0000424077","0002059221","64949089948","64949089948","0004048902","84905120851","0000392294","0004040339","0003056894","0000534475","0000292017","0004048902","64949089948","0001561946","0001494664","85042481189","84870854437","21144478550","0001836974","0001469895","61449210975","84936628342","84875062524","85051108531","0000679216","0038167128","0003443980","0003634344","0003710039","38149091464","0000392294","0003654618","0003054392","44949090262","84973537408","0011939750","38149091464","85013120533","84862732380","0000696527","0003487601","0002534963","79954453991","85013304526","0038052185","84862732380","0003517644","64949089948","84862732380","38149091464","84944735469","33646714870","85087429358","85087429358","85087429358","0003551671","0000009769","0000771343","84956473495","64949089948","85044163613","84919895840","33846300647","0003710039","21844492054","0002125623","38149091464","34548080780","0004289791","34249879981","0345570094","85076489289","85057019815","0142192295","85057019815","84923339908","85021643438","85116889672","85013457817","85085117614","85057019815","0000696527","0003653039","0004040339","21344475322","0003443980","79954453991","0001227919","85057019815","85076489289","84919728106","0004029218","0003710039","78649933846","84903761492","84875062524","64949089948","64949089948","0003710039","64949089948","0002273385","85041661023","0000679216","68049107819","0003443980","0003667583","52449116403","0003586486","34548080780","85057019815","68049107819","85090707944","0002020889","85017111309","85098710831","84934877092","0003653039","85042201824","85042201824","0003667583","21144478550","0004230731","38149091464","0002020889","84942299268","34548080780","79958249386","85013304526","64949089948","85076489289","56549123473","64949089948","84937332636","21344485409","0003583974","84870854437","84870854437","0003018358","0004029218","64949089948","84938966245","85083322291","85031013784","0003768768","0001312089","1442352079","84870854437","0001559313","21144478550","0004048902","4744338583","84944735469","0000257156","64949089948","21344485409","84906270125","79958249386","84956473495","85021643438","0002535326","0001312089","0000470917","0003667583","0002020889","0007744069","84936823933","0001951371","64949089948","0001312089","80055049753","0002408510","0002866667","0002450279","0000424077","84906270125","84994563407","64949089948","85083439798","85051108531","0002381637","85076489289","0001312089","0001261094","0002338132","21144478550","21344476404","21844510415","21144479982","0000607236","0004296209","0003670522","21344477997","0003710039","0003710039","0002466427","0003768768","85029459334","0003710039","64949089948","0003584083","0001449665","84937306801","66249144220","0000200753","33646864881","33744918656","85013457817","84872195089","85013457817","21144478550","0004266342","64949089948","85108665491","85108665491","84935533832","0039013204","84870854437","0004079982","64949089948","0003531998","21844511586","0003584083","0000009769","0001995742","0001995742","84936628342","0003583974","0000917415","0002604811","84904895360","0003517644","0001287271","0003550676","33646714870","38149091464","0004296209","0001736594","64949089948","0002816448","78649933846","85033687876","85057019815","0004289791","0003048219","44949090262","0002667763","64949089948","84904895360","0003807877","0042429461","0003018358","38149091464","21344490393","0002667763","0002408510","0001312089","0003882234","0002381637","0007744069","0004040339","84956473495","0002373795","0001925995","0001312089","0001261094","0002408510","64949089948","0002098156","0002381637","21344490393","0000534475","84870854437","0000607236","0002074493","78649311561","0004266342","0001728801","23944509647","0001227919","56549123473","84857211130","64949089948","64949089948","84870854437","0003443980","85057019815","85076489289","0003248898","0000696527","0002680840","0004040339","0003868827","84934877092","84923351534","0013168260","0002126713","0001227919","0001995742","85017111309","0003550676","52449116403","84919895840","0000257156","0002534963","64949089948","0000009769","84936823933","0000009769","0013168260","0002954788","0003048219","21844492054","84857211130","64949089948","85076459055","85076459055","85076459055","0000470917","84872195089","84942299268","0004266342","33646864881","0004230731","0003797465","33745100403","0003954922","0003798635","0002487848","84938966245","85057019815","0001312089","0002098156","84923351534","84940046213","84935533832","0000125534","21144478550","0004079982","84956473495","52449116403","0003048219","21344475322","0002954788","0040984002","0002607378","21144463066","78650393330","77958044443","0040984002","0000125532","0002466427","21344475322","64949089948","0003882234","0004048902","0344885597","37149021640","38149091464","0004816858","21144478550","0004266342","0004040339","21344476404","21844510415","0004042547","38149091464","61449210975","0002273385","0002934032","0000881830","84936823859","0003797465","0000133998","0242300515","0000659566","0000009769","0002126713","64949089948","0001677717","0004040339","0004230731","0003488717","0004040339","70349460990","0003710039","0000009769","0004296209","84870854437","0003678180","64949089948","33645675879","84857211130","64949089948","0000640211","0002538481","0141988044","34249879981","0003608927","85013304526","64949089948","0001951371","38149091464","0002126713","84905120851","84856343452","0000881830","0004040339","0003797465","84856343452","0001559313","85099424156","84994563407","0003584083","0000679216","77949504413","0003584083","79953762206","84944735469","70349284484","84903761492","84919728106","0003768768","0000424077","0001181569","0002020889","0003584083","70349460990","0002059221","0003710039","84919895840","85055278050","0001449665","84937306801","0039013204","0000607236","21344490393","0001736594","0002183204","0001736594","84956473495","0345570094","0000102571","0003797465","0003678180","21144463066","0003048219","0002954788","0040984002","84994563407","55549105509","0001559313","0004040339","0001469895","64949089948","0003710039","64949089948","0003488717","0003586486","0003583974","0002538481","0004104263","0040984002","0000125532","0003048219","70349284484","85062069097","85062069097","85042481189","52449116403","38149091464","0004816858","34548080780","64949089948","0004048902","38149091464","21144478550","0004266342","0004040339","33646864881","0003882234","84872195089","21144478550","33744918656","84872195089","0242704919","0004296209","84870854437","0004040339","64949089948","77649141031","0004104263","52449116403","77949504413","0003667583","0013168260","67649153594","0002126713","64949089948","84989220223","0002866667","0001965293","84935533832","0002667763","0003054392","19944373443","0002126713","64949089948","85041661023","0000679216","80053431219","0010335445","0038052185","0003487601","38149091464","0000696527","0003048219","0002125623","0002671212","21344475322","85020481177","85055278050","79958249386","85029459334","84875062524","84964770022","64949089948","79953762206","84893112707","21344485409","55549105509","79251522945","63349083646","34548080780","0242300515","0000659566","85013304526","64949089948","0003488717","85015236485","0003586486","85055363420","0000268040","10644254015","34548080780","85021643438","84856343452","79953762206","0004816858","0000679216","0001772263","0038052185","52449116403","0004042547","0003710039","84862732380","84875062524","0002408510","0001312089","0011939750","0002098156","0002381637","0007744069","0001181569","21344475322","21744438808","19944373443","84937293064","0002059221","0003710039","0003710039","64949089948","0000428577","21844511586","85041661023","0001836974","34548831762","70349460990","0004040339","0242704919","0000534475","0002934032","0001878819","21344475283","0001677717","0000133998","0004311812","84923339908","84862732380","0004079982","0003807877","1442352079","0002667763","0004048902","0004048902","21144478550","0004266342","0004289791","83055176929","34548080780","84956473495","51849155463","0000922949","0002866667","10644254015","0012960262","77949504413","64949089948","21744438808","0003488717","0001819160","0003586486","38149091464","0000607236","33646714870","38149091464","0001449665","85013120533","38149091464","34548080780","0003653039","4744338583","0003634344","0002487848","0001728801","0004311812","0038167128","0000604269","0003488717","0001819160","84937332636","0003586486","0004040339","51849155463","0002408510","0010335445","0002098156","0002381637","55549105509","0001559313","0001836974","0002450279","38149091464","0004296209","0003443980","84905120851","33745100403","0001884325","0000640211","0001559313","34548831762","79251522945","21144478550","0000268040","84870854437","0000125532","84870885352","0001728801","0004289791","84872195089","0344885597","0002546379","37149021640","21144478550","0004266342","0000659566","38149091464","84905120851","0002126713","0000917415","0003584083","0001728801","0001965293","84936823933","0010335445","0001728801","0001449665","84936628342","23944509647","0003018358","0002934032","0002866667","85023700532","0002604811","0001494664","0002954788","0003678180","21144463066","0003048219","0002607378","0000604269","64949089948","0001927247","0000292017","0002604811","0003584083","0142192295","33746036191","0003653039","0001721941","0002546379","0012960262","77955641068","38149091464","0004289791","33750343272","77958044443","0001965293","77955641068","0004040339","0003653039","0001721941","0002338132","33750343272","0004816858","0001772263","0000917415","33746036191","33746036191","0001951371","0002126713","0002183204","84937293064","0003488717","21344475283","0003767234","0001965293","85023700532","0002604811","0003797465","0003954922","0001878819","0042429461","0003882234","77957885953","0344670826","77957885953","0344670826","0002934032","0000881830","0000470917","84936823859","0003797465"],"citing_art":["85144463165","85166572932","85166572932","85166572932","85166572932","85148341584","85148341584","85153514480","85153514480","85153514480","85153514480","85153514480","85153514480","85153514480","85151004351","85151004351","85150347354","85150347354","85150347354","85149572870","85149572870","85132327378","85132327378","85132327378","85126047177","85126047177","85126047177","85126047177","85126047177","85146949978","85139387322","85138717027","85138717027","85146998548","85158110075","85158110075","85158110075","85150498750","85150498750","85150498750","85126071763","85143761358","85143761358","85143761358","85141511083","85141511083","85141511083","85141511083","85136274594","85131811168","85131811168","85131811168","85131811168","85131811168","85131811168","85131811168","85124730460","85124730460","85124730460","85124730460","85124730460","85124730460","85124730460","85124726420","85124726420","85124726420","85124726420","85124726420","85143324979","85143324979","85143324979","85143324979","85143324979","85143324979","85139679546","85139679546","85137669788","85137669788","85137669788","85167334948","85167334948","85167334948","85167334948","85167334948","85167334948","85166630306","85166630306","85166630306","85166630306","85166630306","85166630306","85166630306","85166630306","85166624123","85165569386","85165569386","85165413235","85165413235","85165413235","85165413235","85165413235","85165413235","85165413235","85165413235","85165395672","85165395672","85163206315","85163206315","85162774955","85162774955","85162774955","85162774955","85161509158","85160700281","85160700281","85160700281","85160700281","85159567297","85159567297","85159489905","85159489905","85158148454","85158148454","85158148454","85158148454","85158148454","85152800674","85152800674","85151960432","85151960432","85151960432","85151620034","85151620034","85151620034","85151620034","85151620034","85150855178","85150855178","85150855178","85150855178","85150739173","85150739173","85150739173","85150739173","85150739173","85150739173","85150606964","85150606964","85150606964","85150606964","85150606964","85150606964","85150606964","85150606964","85149420983","85149420983","85149113734","85147809278","85147513245","85147513245","85147100431","85143898085","85141229738","85141229738","85141229738","85139737257","85139737257","85139737257","85139737257","85139736022","85139736022","85139736022","85135121811","85135121811","85100900429","85100900429","85120649487","85153078307","85153078307","85140003141","85140003141","85140003141","85140003141","85140003141","85112524940","85120610290","85146299830","85146299830","85139848262","85136100401","85136100401","85126047472","85126047472","85124378925","85119271011","85119271011","85119271011","85119271011","85149071663","85149071663","85149071663","85149071663","85149071663","85138073856","85138073856","85138073856","85138073856","85137626292","85137626292","85137626292","85137626292","85136468469","85127426396","85127426396","85127426396","85127280924","85127280924","85127280924","85127280924","85127280924","85127280924","85127280924","85134811050","85134811050","85134811050","85134811050","85134811050","85134811050","85134811050","85134811050","85134523493","85134523493","85134523493","85134523493","85134523493","85146302485","85146302485","85146232194","85146232194","85146232194","85116722502","85116722502","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85128237357","85117146222","85117146222","85117146222","85113192675","85113192675","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85132856525","85122333187","85122333187","85122333187","85122333187","85118651091","85118651091","85114853462","85131319256","85131319256","85131319256","85131319256","85109761157","85122354292","85122354292","85122354292","85121749320","85121749320","85120872880","85120872880","85128482011","85127638085","85127638085","85127638085","85127638085","85126476246","85126476246","85126476246","85126476246","85126476246","85126476246","85123013062","85123013062","85123013062","85122507035","85111638251","85102511342","85117124447","85117124447","85117124447","85117124447","85117124447","85107472686","85107472686","85107472686","85104078942","85150089813","85150089813","85150089813","85150089813","85147259597","85147249097","85147249097","85146879074","85145840941","85145840941","85145840941","85145840941","85145840941","85142372695","85139115612","85139115612","85139115612","85139115612","85139115612","85139115612","85139115612","85138704935","85138704935","85138684672","85138684672","85138684672","85138684672","85136591503","85136591503","85136591503","85136515369","85136458993","85136458993","85136458993","85131678809","85131678809","85127939086","85127939086","85127334186","85127334186","85127018562","85126975314","85126946402","85126333013","85126333013","85126333013","85125102701","85125102701","85121317003","85121317003","85116556264","85116556264","85116556264","85100059556","85100059556","85100059556","85094879481","85130623788","85130623788","85130623788","85130623788","85117069469","85117069469","85116899884","85116899884","85116899884","85116899884","85116899884","85116899884","85114512213","85114464568","85114464568","85114464568","85103952432","85101453495","85101453495","85101077323","85108345184","85108345184","85108345184","85108345184","85108345184","85108345184","85108345184","85121141262","85121141262","85111740562","85111740562","85109633827","85109633827","85109633827","85109633827","85109633827","85116481460","85116481460","85116481460","85116481460","85116481460","85116481460","85116481460","85116438673","85104041731","85104041731","85104041731","85104041731","85104041731","85128903955","85128903955","85128903955","85128903955","85128903955","85118220280","85118220280","85118220280","85118220280","85118220280","85113266808","85113266808","85113266808","85105755765","85105755765","85105755765","85105755765","85104394128","85104394128","85114046286","85114046286","85114046286","85114046286","85108701962","85108701962","85108701962","85108701962","85108701962","85108701962","85108701962","85108701962","85158949640","85158949640","85158949640","85158949640","85158949640","85158949640","85158949640","85105653818","85105653818","85105653818","85103167358","85103167358","85103167358","85103167358","85103167358","85102463024","85102463024","85102463024","85102463024","85102463024","85102463024","85102463024","85102463024","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85102316531","85107287236","85105488569","85105488569","85101739989","85101739989","85101739989","85101739989","85101739989","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85089982084","85088692184","85087053077","85087053077","85087053077","85087053077","85087053077","85087053077","85099389536","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100868810","85100845405","85100845405","85091634199","85091634199","85091634199","85091634199","85091634199","85090731774","85090731774","85090731774","85090731774","85090731774","85090731774","85101263846","85101263846","85138633642","85111091672","85111091672","85108978849","85108978849","85107991873","85107991873","85106315113","85106315113","85106315113","85106315113","85101480021","85101480021","85101480021","85101480021","85094632972","85092346299","85092346299","85091434156","85083557523","85083557523","85077154834","85077154834","85077154834","85077154834","85076455134","85076455134","85076455134","85076455134","85076455134","85097615908","85153031128","85153031128","85153031128","85153031128","85090359625","85090359625","85090359625","85090359625","85101930421","85098887052","85075881467","85098461241","85087421838","85087421838","85087421838","85085967799","85085967799","85064900712","85064900712","85073826575","85088942130","85088928551","85085975972","85085975972","85085975972","85085975972","85085975972","85085975972","85084418343","85059850575","85059850575","85059850575","85082966401","85082966401","85082131009","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85080132492","85078887027","85078887027","85078887027","85078887027","85081279279","85081279279","85081279279","85081279279","85081279279","85079822358","85079822358","85079822358","85079822358","85079822358","85079822358","85079822358","85079130868","85079130868","85079130868","85079130868","85076535289","85076535289","85078424831","85078424831","85078424831","85078424831","85069448021","85069448021","85069448021","85106373785","85106373785","85106373785","85106373785","85106373785","85106373785","85072713622","85072713622","85078470711","85078470711","85078470711","85078470711","85147599237","85125179733","85125179733","85125179733","85125179733","85099410916","85099410916","85099410916","85096041672","85096041672","85082868407","85082747260","85077710168","85077710168","85077710168","85077710168","85077710168","85077710168","85077710168","85076367036","85076367036","85076367036","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85071944121","85059464256","85059464256","85083648310","85083648310","85071915138","85071915138","85071915138","85060661202","85060661202","85060661202","85060661202","85060661202","85060661202","85060661202","85068532597","85068532597","85068532597","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85068385061","85067848547","85067848547","85067848547","85081956713","85062084132","85068046590","85068046590","85070983662","85063587453","85063587453","85063587453","85063587453","85149382137","85149382137","85149382137","85149382137","85149382137","85149382137","85149382137","85149382137","85130629588","85130629588","85130629588","85083803034","85083803034","85083803034","85083803034","85083803034","85083803034","85083803034","85065886742","85065886742","85064056437","85064056437","85064056437","85064056437","85067034290","85067034290","85067034290","85067034290","85067034290","85061812010","85061812010","85061812010","85061812010","85065283005","85065283005","85065283005","85065283005","85069470449","85058647683","85058647683","85058647683","85055525406","85055525406","85055525406","85055525406","85055525406","85055525406","85055277517","85055277517","85055277517","85055277517","85055277517","85055277517","85055277517","85063434374","85063434374","85052138805","85052138805","85052138805","85071937753","85071937753","85071937753","85059696197","85059696197","85059696197","85059696197","85059696197","85059696197","85059696197","85148555309","85070922144","85070922144","85070922144","85070922144","85063814803","85063814803","85063814803","85042353149","85042353149","85042353149","85048377287","85047658500","85047658500","85047658500","85047658500","85047658500","85047658500","85047658500","85047658500","85047653646","85062666532","85062666532","85062666532","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85044845432","85048740946","85048740946","85059376135","85059376135","85045397801","85045397801","85045397801","85045397801","85045397801","85045397801","85040710229","85030455391","85030455391","85030455391","85018173060","84981276334","84981276334","84981276334","84981276334","84981276334","85017215318","85017215318","85017215318","85017215318","85017215318","85017215318","85008145276","85008145276","85008145276","84994761908","85027195392","85010894617","85010894617","85010894617","84995546450","84979529977","84979529977","84979529977","84979529977","84979529977","84969884848","84961590428","84961590428","84961590428","84961590428","84961590428","84954393300","84954393300","84954393300","84954393300","84954393300","84954393300","84954393300","85040798247","85040798247","85040798247","85040798247","85040798247","84939550750","84939550750","84930898445","85009157659","84887334076","84887334076","84945465077","84945465077","84913539983","84913539983","84913539983","85031497817","85017727085","85017727085","84929661398","84929661398","84929661398","84929661398","84929661398","84929661398","84928152140","84928152140","84928152140","84928152140","84928152140","84905976163","84905976163","84905976163","84905976163","84902263102","84902263102","84902263102","84902263102","84902263102","84902263102","84902263102","85099664609","85099664609","85099664609","84879522483","84873301123","84873301123","84873301123","84873301123","84873301123","84873287978","84873287978","84873287978","84864568988","84864568988","84864568988","84861707692","84861707692","84861707692","84861707692","84861707692","84861707692","84861707692","84861707692","84861665218","84861665218","80155123627","79960572874","79957661901","79957661901","80855129394","80855129394","80855129394","80855129394","80855129394","80855129394","80855129394","80855129394","78649710947","84886874793","84886874793","84886874793","84886874793","33750123489","27844554380","27844554380","60849095262","60849095262","60849095262","84986046302","84986046302","84986046302","84986046302","0032003546","84986047357","84986047357","84986116844","84986116844","2342460439","2342460439","2342460439","2342460439","2342460439"],"title":["Discovery-Oriented Consumer Research","Linguistic Inquiry and Word Count: LIWC2015","Linguistic Cues to Deception Assessed by Computer Programs: A Meta-Analysis","A Framework for Big Data Analytics in Commercial Social Networks: A Case Study on Sentiment Analysis and Fake Review Detection for Marketing Decision-Making","WordNet: An Electronic Lexical Database","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","The development and psychometric properties of LIWC2015","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Text Analytics with python","An Approach to Environmental Psychology","Satisfaction: A Behavioral Perspective on Customer","Measuring service quality: a reexamination and extension","Belief, attitude, intention, and behavior: an introduction to theory and research","Correspondence Analysis in Practice","A Primer on Partial Least Squares Structural Equation Modeling","Research Design: Qualitative, Quantitative, and Mixed Methods Approaches","Diffusion of innovations","A New Product Growth for Model Consumer Durables","Estimating Vector Autoregressions with Panel Data","Managing Brand Equity","Possessions and the extended self","Transcendent customer experience and Brand community","Grounding in communication","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Neural and Intelligent Systems Integration","A probabilistic choice model for market segmentation and elasticity structure","Ontology Learning from Text: An Overview,” in","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","Text mining: Finding nuggets in mountains of textual data","Possessions and the extended self","A national customer satisfaction barometer: The Swedish experience","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","Full Catastrophe Living (Revised Edition): How to Cope With Stress, Pain and Illness Using Mindfulness Meditation","Automation assemblages in the internet of things: Discovering qualitative practices at the boundaries of quantitative change","Regression shrinkage and selection via the lasso","Linguistic Inquiry and Word Count: LIWC2015","AParadigmforDevelopingBetterMeasuresofMarketing Constructs,”","Linguistic Inquiry and Word Count: LIWC2015","User acceptance of computer technology: a comparison of two theoretical models","A national customer satisfaction barometer: The Swedish experience","Content analysis","Strengths and Limitations of Qualitative and Quantitative Research Methods","DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","Approaches, Tools and Applications for Sentiment Analysis Implementation","BERT: pre-training of deep bidirectional Transformers for language understanding","Introductory econometrics: A modern approach","Information and consumer behavior","Advertising as information","Introduction to Modern Information Retrieval","Social media's mindset: When to use which sentiment extraction tool?","Measuring consumer involvement profiles","Sentiment Analysis and Opinion Mining","Introduction to Information Retrieval","An exploration of the brand identity-brand image linkage: A communications perspective","Automatic text processing","Text mining","Managing Brand Equity","Conceptualizing, measuring, and managing customer-based brand equity","Strategic brand management: Building, measuring, and managing brand equity","Strategic brand management: Building, measuring, and managing brand equity","Testing competitive market structures","Customer-oriented approaches to identifying product-markets","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Alternative Perceptual Mapping Techniques: Relative Accuracy and Usefulness","A probabilistic choice model for market segmentation and elasticity structure","Strategic orientation o business enterprises: the construct, dimensionality and measurement","Market orientation: Antecedents and consequences","The capabilities of market-driven organizations","Assessing advantage: A framework for diagnosing competitive superiority","Evaluating structural equation models with unobservable variables and measurement error","A Primer on Partial Least Squares Structural Equation Modeling","Analyzing the past to prepare for the future: Writing a literature review","Modern Optimization with R","The effect of a market orientation on business profitability","The content analysis guidebook","Marketing in new ventures: Theory and empirical evidence","Regression shrinkage and selection via the lasso","Introduction to Information Retrieval","Automation assemblages in the internet of things: Discovering qualitative practices at the boundaries of quantitative change","The development and psychometric properties of LIWC2015","Enriching word vectors with subword information","BERT: pre-training of deep bidirectional Transformers for language understanding","A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","Word of mouse: The role of cognitive personalization in online consumer reviews","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","All reviews are not created equal: the disaggregate impact of reviews and reviewers at Amazon.Com","The information processing of pictures in print advertisements","Modeling Goes to Hollywood: Predicting Individual Differences in Movie Enjoyment","Consumer skepticism of advertising claims: Testing hypotheses from economics of information","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","The emergence and evolution of consumer language research","How verb tense shapes persuasion","The effects of content characteristics on consumer engagement with branded social media content on Facebook","Rtweet: Collecting and analyzing Twitter data","Linguistic Inquiry and Word Count: LIWC2015","The development and psychometric properties of LIWC2015","academictwitteR: An rpackage to access the twitter academic research","Quanteda: An R package for the quantitative analysis of textual data","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Tests of Certain Linear Hypotheses and Their Application to Some Educational Problems","Product consumption-based affective responses and post-purchase processes","Quanteda: An R package for the quantitative analysis of textual data","BERT: pre-training of deep bidirectional Transformers for language understanding","RoBERTa: A Robustly Optimized BERT Pretraining Approach","The information processing of pictures in print advertisements","Evaluating structural equation models with unobservable variables and measurement error","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel","Research Design: Qualitative, Quantitative, and Mixed Methods Approaches","Quanteda: An R package for the quantitative analysis of textual data","SERVPERF versus SERVQUAL: reconciling performance-based and perceptions-minus-expectations measurement of service quality","The Marketing Aspects of Service Quality","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Possessions and the extended self","The emergence and evolution of consumer language research","Communicating Brand Personality: Are the Websites Doing the Talking for the Top South African Business Schools?","Linguistic Inquiry and Word Count: LIWC2015","The emergence and evolution of consumer language research","How verb tense shapes persuasion","Linguistic Inquiry and Word Count: LIWC2015","The development and psychometric properties of LIWC2015","Emotion","How Online Word-of-Mouth Impacts Receivers","A correlated topic model of science","Web2.0: Conceptual foundations and marketinngissues","Social media's mindset: When to use which sentiment extraction tool?","Introduction to latent semantic analysis","Novelty, Complexity, and Importance as Causal Determinants of Industrial Buyer Behavior","The commitment-trust theory of relationship marketing","Business-to-Business Buying: Challenges and Opportunities","R (Software)","Relationship Quality in Services Selling: An Interpersonal Influence Perspective","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","A correlated topic model of science","The forms of capital","Conceptualizing, measuring, and managing customer-based brand equity","How verb tense shapes persuasion","The development and psychometric properties of LIWC2015","Diffusion of innovations","Regression shrinkage and selection via the lasso","An introduction to support vector machines and other kernel-based learning methods","A Social Psychology of Cultural Dynamics: Examining How Cultures Are Formed, Maintained, and Transformed","Prospect theory: An analysis of decision under risk","An Approach to Environmental Psychology","Central and peripheral routes to advertising effectiveness: The moderating role of involvement","Measuring Emotions in the Consumption Experience","Work and/or fun: Measuring hedonic and utilitarian shopping value","Investigating Romanian healthcare consumer behaviour in online communities: Qualitative research on negative eWOM","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","Sentiment analysis of Twitter data","They predicted president trump and brexit","BERT: pre-training of deep bidirectional Transformers for language understanding","Modern Optimization with R","Twitter sentiment classification using distant supervision","tidytext: Text Mining and Analysis Using Tidy Data Principles in R","Research Design: Qualitative, Quantitative, and Mixed Methods Approaches","The Persuasion Knowledge Model: How People Cope with Persuasion Attempts","Utilization of mass communication by the individual","Information and consumer behavior","Advertising as information","Advertising as information","Speech Acts: An Essay in the Philosophy of Language","How to Do Things with Words","A Performative View of Language—Methodological Considerations and Consequences for the Study of Culture","A new ANEW: evaluation of a word list for sentiment analysis in microblogs","A conceptual model of service quality and its implications for future research","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Variety Seeking Behavior: An Interdisciplinary Review","The development and psychometric properties of LIWC2015","A conceptual model of service quality and its implications for future research","Note from special issue editors","BERT: pre-training of deep bidirectional Transformers for language understanding","Sample Selection Bias as a Specification Error","Linguistic Inquiry and Word Count: LIWC2015","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","Conceptualizing, measuring, and managing customer-based brand equity","Who Is the Celebrity Endorser? Cultural Foundations of the Endorsement Process","Self-Concept in Consumer Behavior: A Critical Review","Evaluating structural equation models with unobservable variables and measurement error","Preprocessing techniques for text mining-an overview","The development and psychometric properties of LIWC2015","Experiential marketing","An Approach to Environmental Psychology","Relationship marketing theory: Its roots and direction","Sympathy and Callousness: The Impact of Deliberative Thought on Donations to Identifiable and Statistical Victims","Public service advertisements: emotions and empath guide prosocial behavior","Efficient estimation of word representations in vector space","Deep learning","Market Segmentation: Conceptual and Methodological Foundations","Introduction to Modern Information Retrieval","Ontology Learning from Text: An Overview,” in","The voice of the customer","The house of quality","Sympathy and Callousness: The Impact of Deliberative Thought on Donations to Identifiable and Statistical Victims","How Online Word-of-Mouth Impacts Receivers","The development and psychometric properties of LIWC2015","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","SMOG Grading—A New Readability Formula","The development and psychometric properties of LIWC2015","Speech Acts: An Essay in the Philosophy of Language","Grounding in communication","The development and psychometric properties of LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","Adaptive Selling: Conceptualization, Measurement, and Nomological Validity","What makes a good salesman","A Framework for Big Data Analytics in Commercial Social Networks: A Case Study on Sentiment Analysis and Fake Review Detection for Marketing Decision-Making","Analyzing the past to prepare for the future: Writing a literature review","Belief, attitude, intention, and behavior: An introduction to theory and research","Hedonic consumption: Emerging concepts, methods and propositions","LDAvis: A Method for Visualizing and Interpreting Topics","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","Possessions and the extended self","A correlated topic model of science","lda: Collapsed Gibbs Sampling Methods for Topic Models","Belief, attitude, intention, and behavior: An introduction to theory and research","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","What makes a good salesman","Linguistic Inquiry and Word Count: LIWC2015","The development and psychometric properties of LIWC2015","Tell me a story: A new look at real and artificial memory","Sensemaking in organizations","Assessing advantage: A framework for diagnosing competitive superiority","Content analysis in consumer research","Content analysis","The economic institutions of capitalism","The development and psychometric properties of LIWC2015","Logic and Conversation","Content analysis","Quantitative analysis of textual data","Gensim–Python framework for vector space modelling","LDAvis: A Method for Visualizing and Interpreting Topics","Controlling the false discovery rate: a practical and powerful approach to multiple testing","Which hotel attributes matter?","Hotel Guest Satisfaction among Business Travelers: What Are the Important Factors?","All reviews are not created equal: the disaggregate impact of reviews and reviewers at Amazon.Com","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Laddering theory, method, analysis, and interpretation","Testing competitive market structures","The Psychology of Personal Constructs","Principles of Marketing","AI adoption in the enterprise 2020","Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon","Information and consumer behavior","WordStat: Content Analysis Module for SIM- STAT","The development and psychometric properties of LIWC2015","The development and psychometric properties of LIWC2015","Managing Brand Equity","Multivariate Analysis","Alternative Perceptual Mapping Techniques: Relative Accuracy and Usefulness","Content analysis","Relationship Quality in Services Selling: An Interpersonal Influence Perspective","Logic and Conversation","Are product attribute beliefs the only mediator of advertising effects on brand attitude","Managing Brand Equity","The development and psychometric properties of LIWC2015","Self-Concept in Consumer Behavior: A Critical Review","Mapping Product Constellations: A Social Categorization Approach to Consumption Symbolism","Pipelines, Platforms, and the New Rules of Strategy","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Conceptualizing, measuring, and managing customer-based brand equity","Culture and Consumption: A Theoretical Account of the Structure and Movement of the Cultural Meaning of Consumer Goods","Who Is the Celebrity Endorser? Cultural Foundations of the Endorsement Process","Marketing as Exchange","Possessions and the extended self","A new ANEW: evaluation of a word list for sentiment analysis in microblogs","Matrix Completion Methods for Causal Panel Data Models. Technical Report","Distributional structure","Learning to Classify Text Using Support Vector Machines: Methods, Theory and Algorithms","Cultures and Organizations: Software of the Mind","The Emotions: Facts, Theories, and a New Model","Linguistic Inquiry and Word Count: LIWC2015","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Alternative Perceptual Mapping Techniques: Relative Accuracy and Usefulness","The Psychology of Personal Constructs","Laddering theory, method, analysis, and interpretation","Nudge: Improving decisions about health, wealth, and happiness","Preprocessing techniques for text mining-an overview","Customer satisfaction, market share and profitability: findings from Sweden","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Approaches, Tools and Applications for Sentiment Analysis Implementation","Sentiment Analysis and Opinion Mining","Statistical bibliography or bibliometrics","Neural Networks for Pattern Recognition","A model of predictive measurements of advertising effectiveness","Attitude towards the environment and green products: Consumers' perspective","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","Text mining: the state of the art and the challenges","Sentiment Analysis and Opinion Mining","Neural and Intelligent Systems Integration","The development and psychometric properties of LIWC2015","Sentiment Analysis and Opinion Mining","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Deep learning","Ontology Learning from Text: An Overview,” in","Smart tourists and intelligent behavior","Smart tourists and intelligent behavior","Smart tourists and intelligent behavior","Belief, attitude, intention, and behavior: An introduction to theory and research","Evaluating structural equation models with unobservable variables and measurement error","Consumer skepticism of advertising claims: Testing hypotheses from economics of information","LDAvis: A Method for Visualizing and Interpreting Topics","The development and psychometric properties of LIWC2015","Strengths and Limitations of Qualitative and Quantitative Research Methods","Scalable recommendation with poisson factorization","Hotel Guest Satisfaction among Business Travelers: What Are the Important Factors?","Linguistic Inquiry and Word Count: LIWC2015","Critical Service Encounters: The Employee’s Viewpoint","A Script-Theoretic Analysis of Industrial Purchasing Behavior","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Introduction to Information Retrieval","WordNet: An Electronic Lexical Database","Correspondence Analysis in Practice","Scaling to Very Very Large Corpora for Natural Language Disambiguation","RoBERTa: A Robustly Optimized BERT Pretraining Approach","BERT: pre-training of deep bidirectional Transformers for language understanding","Conditional random fields: Probabilistic models for segmenting and labeling sequence data","BERT: pre-training of deep bidirectional Transformers for language understanding","Nrc emotion lexicon","tidytext: Text Mining and Analysis Using Tidy Data Principles in R","academictwitteR: An rpackage to access the twitter academic research","Can sustainability be luxurious? A mixed-method investigation of implicit and explicit attitudes towards sustainable luxury consumption","Rtweet: Collecting and analyzing Twitter data","BERT: pre-training of deep bidirectional Transformers for language understanding","Statistical bibliography or bibliometrics","Introduction to Modern Information Retrieval","Content analysis","The commitment-trust theory of relationship marketing","Cultures and Organizations: Software of the Mind","Attitude towards the environment and green products: Consumers' perspective","The intellectual development of management information systems","BERT: pre-training of deep bidirectional Transformers for language understanding","RoBERTa: A Robustly Optimized BERT Pretraining Approach","Learning phrase representations using RNN encoder-decoder for statistical machine translation","Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel","Linguistic Inquiry and Word Count: LIWC2015","Software Framework for Topic Modelling with Large Corpora","Efficient estimation of word representations in vector space","A new ANEW: evaluation of a word list for sentiment analysis in microblogs","The development and psychometric properties of LIWC2015","The development and psychometric properties of LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","The development and psychometric properties of LIWC2015","Time-Oriented Advertising: A content analysis of United States magazine advertising, 1890-1988","On consumer beliefs about quality and taste","Distributional structure","Measuring consumers’ luxury value perception: A cross-cultural framework","Cultures and Organizations: Software of the Mind","An Approach to Environmental Psychology","A correlated topic model of science","How to Do Things with Words","Introduction to Information Retrieval","BERT: pre-training of deep bidirectional Transformers for language understanding","Measuring consumers’ luxury value perception: A cross-cultural framework","R (Software)","Hedonic consumption: Emerging concepts, methods and propositions","The biggest data challenges that you might not even know you have","A Framework for Big Data Analytics in Commercial Social Networks: A Case Study on Sentiment Analysis and Fake Review Detection for Marketing Decision-Making","Social media use in the restaurant industry: A work in progress","Introduction to Modern Information Retrieval","A two-step approach to quantitative content analysis: KH coder tutorial using Anne of Green gables (Part I)","A two-step approach to quantitative content analysis: KH coder tutorial using Anne of Green gables (Part I)","An Approach to Environmental Psychology","Conceptualizing, measuring, and managing customer-based brand equity","The content analysis guidebook","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Hedonic consumption: Emerging concepts, methods and propositions","Social media e sentiment analysis","Introduction to Information Retrieval","Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The development and psychometric properties of LIWC2015","RoBERTa: A Robustly Optimized BERT Pretraining Approach","Social Hierarchy: The Self-Reinforcing Nature of Power and Status","The development and psychometric properties of LIWC2015","Indirect Speech Acts","Work and/or fun: Measuring hedonic and utilitarian shopping value","Distinction: A Social Critique of the Judgement of Taste","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","The Market Maven: A Diffuser of Marketplace Information","Derivation of New Readability Formulas (Automated Readability Index, Fog Count and Flesch Reading Ease Formula) for Navy Enlisted Personnel","The development and psychometric properties of LIWC2015","Text mining and analysis: Practical methods, examples, and case studies using SAS","DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","Enriching word vectors with subword information","The Innovator's dilemma: When new technologies cause great firms to fail","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Consumer-based brand equity: Development and validation of a measurement instrument","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","Conceptualizing, measuring, and managing customer-based brand equity","Managing Brand Equity","Online reviews: Do consumers use them","Deep learning","A Logit Model of Brand Choice Calibrated on Scanner Data","The development and psychometric properties of LIWC2015","Work and/or fun: Measuring hedonic and utilitarian shopping value","Dplyr: A Grammar of Data Manipulation","Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon","LDAvis: A Method for Visualizing and Interpreting Topics","tidytext: Text Mining and Analysis Using Tidy Data Principles in R","Utilization of mass communication by the individual","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Cluster analysis in marketing research: review and suggestions for application","An Approach to Environmental Psychology","Hedonic consumption: Emerging concepts, methods and propositions","SERVPERF versus SERVQUAL: reconciling performance-based and perceptions-minus-expectations measurement of service quality","User acceptance of computer technology: a comparison of two theoretical models","Store atmosphere: An environmental psychology approach","The development and psychometric properties of LIWC2015","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Note from special issue editors","A conceptual model of service quality and its implications for future research","The service encounter: Diagnosing favorable and unfavorable incidents","Consumer Perception of Product Quality and the Country-of-Origin Effect","Information and consumer behavior","Dplyr: A Grammar of Data Manipulation","Local Consumer Review Survey 2018","The development and psychometric properties of LIWC2015","AI adoption in the enterprise 2020","Matrix Completion Methods for Causal Panel Data Models. Technical Report","Measuring service quality: a reexamination and extension","RoBERTa: A Robustly Optimized BERT Pretraining Approach","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Refinement and Reassessment of the SERVQUAL Scale","Commercial Use of Conjoint Analysis: An Update","Conceptualizing, measuring, and managing customer-based brand equity","Reliability Measures for Qualitative Data: Theory and Implications","Analysis and Interpretation of Qualitative Data in Consumer Research","Discovery-Oriented Consumer Research","Dimensions of Consumer Expertise","Econometric Analysis","Tell me a story: A new look at real and artificial memory","Public service advertisements: emotions and empath guide prosocial behavior","Linguistic Inquiry and Word Count: LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","Disruptive technologies","The Innovator's dilemma: When new technologies cause great firms to fail","When words sweat: Identifying signals for loan default in the text of loan applications","Linguistic Inquiry and Word Count: LIWC2015","The development and psychometric properties of LIWC2015","Diffusion of innovations","A New Product Growth for Model Consumer Durables","All Hits Are Flukes: Institutionalized Decision Making and the Rhetoric of Network Prime-Time Program Development","A Social Psychology of Cultural Dynamics: Examining How Cultures Are Formed, Maintained, and Transformed","Variety Seeking Behavior: An Interdisciplinary Review","An exploration of the brand identity-brand image linkage: A communications perspective","It’s really fascinating work: Differences in evaluative adjectives across academic registers","Can sustainability be luxurious? A mixed-method investigation of implicit and explicit attitudes towards sustainable luxury consumption","Text mining","Can sustainability be luxurious? A mixed-method investigation of implicit and explicit attitudes towards sustainable luxury consumption","Conceptualizing, measuring, and managing customer-based brand equity","Strategic brand management: Building, measuring, and managing brand equity","The development and psychometric properties of LIWC2015","Does Consumer Promiscuity Influence Purchase Intent? The Role of AI, Change Seeking, and Pride","Does Consumer Promiscuity Influence Purchase Intent? The Role of AI, Change Seeking, and Pride","Social Ties and Word-of-Mouth Referral Behavior","How Word-of-Mouth Advertising Works","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Principles of Marketing","The development and psychometric properties of LIWC2015","The economic institutions of capitalism","Subcultures of consumption: An ethnography of the new bikers","Diffusion of innovations","Evaluating structural equation models with unobservable variables and measurement error","Keywords plus-ISI's breakthrough retrieval method. Part 1. Expanding your searching power on Current Contents on Diskette","Keywords plus-ISI's breakthrough retrieval method. Part 1. Expanding your searching power on Current Contents on Diskette","Possessions and the extended self","Distinction: A Social Critique of the Judgement of Taste","A probabilistic choice model for market segmentation and elasticity structure","Negative word-of-mouth by dissatisfied consumers: A pilot study","Getting started with SAS® Text Miner 12.1","Neural and Intelligent Systems Integration","Regression shrinkage and selection via the lasso","Market Segmentation: Conceptual and Methodological Foundations","Ontology Learning from Text: An Overview,” in","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Econometric Analysis","SMOG Grading—A New Readability Formula","The development and psychometric properties of LIWC2015","Estimating Vector Autoregressions with Panel Data","Software Framework for Topic Modelling with Large Corpora","Text Analytics with python","BERT: pre-training of deep bidirectional Transformers for language understanding","WordNet: An Electronic Lexical Database","Market orientation: The construct, research propositions, and managerial implications","Nudge: Improving decisions about health, wealth, and happiness","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","The development and psychometric properties of LIWC2015","Getting started with SAS® Text Miner 12.1","Marketing services: Competing through quality","The relationship between status consumption and materialism: A cross-cultural comparison of Chinese, Mexican, and American student","The Market Maven: A Diffuser of Marketplace Information","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","The Persuasion Knowledge Model: How People Cope with Persuasion Attempts","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","A conceptual model of service quality and its implications for future research","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Automatic text processing","Measuring service quality: a reexamination and extension","SERVPERF versus SERVQUAL: reconciling performance-based and perceptions-minus-expectations measurement of service quality","Content analysis","LDAvis: A Method for Visualizing and Interpreting Topics","Adaptive Selling: Conceptualization, Measurement, and Nomological Validity","The Marketing Aspects of Service Quality","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Refinement and Reassessment of the SERVQUAL Scale","A conceptual model of service quality and its implications for future research","The development and psychometric properties of LIWC2015","SERVQUAL: review, critique, research agenda","Measuring service quality: a reexamination and extension","The Persuasion Knowledge Model: How People Cope with Persuasion Attempts","Logic and Conversation","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Dimensions of Consumer Expertise","Tests of Certain Linear Hypotheses and Their Application to Some Educational Problems","Word of mouse: The role of cognitive personalization in online consumer reviews","Strategic brand management: Building, measuring, and managing brand equity","Role of product-related conversations in the diffusion of a new product","How damaging is negative word of mouth","The intellectual development of management information systems","Social Hierarchy: The Self-Reinforcing Nature of Power and Status","The Secret Life of Pronouns: What Our Words Say About Us","The development and psychometric properties of LIWC2015","The development and psychometric properties of LIWC2015","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Cultures and Organizations: Software of the Mind","BERT: pre-training of deep bidirectional Transformers for language understanding","RoBERTa: A Robustly Optimized BERT Pretraining Approach","Belief, attitude, intention, and behavior: an introduction to theory and research","Statistical bibliography or bibliometrics","The information processing of pictures in print advertisements","Content analysis","Satisfaction: A Behavioral Perspective on Customer","Social media use in the restaurant industry: A work in progress","Modern Optimization with R","Experiential marketing","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","The intellectual development of management information systems","Keywords plus-ISI's breakthrough retrieval method. Part 1. Expanding your searching power on Current Contents on Diskette","The biggest data challenges that you might not even know you have","Market Segmentation: Conceptual and Methodological Foundations","A correlated topic model of science","Scalable recommendation with poisson factorization","A Logit Model of Brand Choice Calibrated on Scanner Data","A model of predictive measurements of advertising effectiveness","The development and psychometric properties of LIWC2015","Evaluating structural equation models with unobservable variables and measurement error","User acceptance of computer technology: a comparison of two theoretical models","Evaluating structural equation models with unobservable variables and measurement error","Experiential marketing","The effect of a market orientation on business profitability","Market orientation: The construct, research propositions, and managerial implications","Critical Service Encounters: The Employee’s Viewpoint","The Secret Life of Pronouns: What Our Words Say About Us","The development and psychometric properties of LIWC2015","The world’s most influential CMOs 2017","The world’s most influential CMOs 2017","The world’s most influential CMOs 2017","Cluster analysis in marketing research: review and suggestions for application","Text mining","Social media e sentiment analysis","Strategic brand management: Building, measuring, and managing brand equity","An exploration of the brand identity-brand image linkage: A communications perspective","The content analysis guidebook","Basic content analysis","Singapore's image as a tourist destination","Content analysis in communication research","An introduction to support vector machines and other kernel-based learning methods","A General Psychoevolutionary Theory of Emotion","Text mining and analysis: Practical methods, examples, and case studies using SAS","BERT: pre-training of deep bidirectional Transformers for language understanding","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","SERVQUAL: review, critique, research agenda","Modern Optimization with R","Investigating Romanian healthcare consumer behaviour in online communities: Qualitative research on negative eWOM","Social Ties and Word-of-Mouth Referral Behavior","Sample Selection Bias as a Specification Error","Conceptualizing, measuring, and managing customer-based brand equity","Principles of Marketing","LDAvis: A Method for Visualizing and Interpreting Topics","A correlated topic model of science","Market orientation: The construct, research propositions, and managerial implications","The commitment-trust theory of relationship marketing","The effect of a market orientation on business profitability","The capabilities of market-driven organizations","Assessing advantage: A framework for diagnosing competitive superiority","Market orientation: Antecedents and consequences","Emotion","Predicting the future with social media","The capabilities of market-driven organizations","Prospect theory: An analysis of decision under risk","Disruptive technologies","The commitment-trust theory of relationship marketing","The development and psychometric properties of LIWC2015","Automatic text processing","Managing Brand Equity","The brandscape: Converting image into equity","Virtual communities of consumption: Networks of consumer-knowledge and companionship","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","The voice of the customer","Conceptualizing, measuring, and managing customer-based brand equity","Strategic brand management: Building, measuring, and managing brand equity","Content analysis","Reliability Measures for Qualitative Data: Theory and Implications","Analysis and Interpretation of Qualitative Data in Consumer Research","Crisp-Dm 1.0","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Marketing as Exchange","Time-Oriented Advertising: A content analysis of United States magazine advertising, 1890-1988","Content analysis in consumer research","Content-Analysis Research: An Examination of Applications with Directives for Improving Research Reliability and Objectivity","Content Analysis of Print Ads from Hong Kong, the People's Republic of China, and Taiwan","Basic content analysis","An analysis of transformations","Consumer Selection of Motion Pictures","Modeling Goes to Hollywood: Predicting Individual Differences in Movie Enjoyment","Evaluating structural equation models with unobservable variables and measurement error","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","The development and psychometric properties of LIWC2015","Controlling the false discovery rate: a practical and powerful approach to multiple testing","Content analysis","The content analysis guidebook","Speech Acts: An Essay in the Philosophy of Language","Content analysis","Communicating Brand Personality: Are the Websites Doing the Talking for the Top South African Business Schools?","Linguistic Inquiry and Word Count: LIWC2015","Evaluating structural equation models with unobservable variables and measurement error","Econometric Analysis","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Introductory econometrics: A modern approach","The development and psychometric properties of LIWC2015","Marketing in new ventures: Theory and empirical evidence","The Secret Life of Pronouns: What Our Words Say About Us","The development and psychometric properties of LIWC2015","Psychographics: A critical review","The forms of capital","Research Design: Qualitative, Quantitative, and Mixed Methods Approaches","Correspondence Analysis in Practice","Full Catastrophe Living (Revised Edition): How to Cope With Stress, Pain and Illness Using Mindfulness Meditation","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The development and psychometric properties of LIWC2015","Store atmosphere: An environmental psychology approach","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","Multivariate Analysis","Sentiment analysis of Twitter data","Content-Analysis Research: An Examination of Applications with Directives for Improving Research Reliability and Objectivity","Content analysis","Basic content analysis","Sentiment analysis of Twitter data","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","They predicted president trump and brexit","Local Consumer Review Survey 2018","Diffusion of innovations","Distributional structure","Online consumer-generated reviews have significant impact on offline purchase behavior","Diffusion of innovations","Twitter sentiment classification using distant supervision","Deep learning","Supervised sequence labelling with recurrent neural networks","Efficient estimation of word representations in vector space","Learning phrase representations using RNN encoder-decoder for statistical machine translation","The Innovator's dilemma: When new technologies cause great firms to fail","Information and consumer behavior","Advertising as information","Hedonic consumption: Emerging concepts, methods and propositions","Diffusion of innovations","Communicating Brand Personality: Are the Websites Doing the Talking for the Top South African Business Schools?","WordStat: Content Analysis Module for SIM- STAT","Linguistic Inquiry and Word Count: LIWC2015","Scalable recommendation with poisson factorization","Social media's mindset: When to use which sentiment extraction tool?","A New Product Growth for Model Consumer Durables","All Hits Are Flukes: Institutionalized Decision Making and the Rhetoric of Network Prime-Time Program Development","How Word-of-Mouth Advertising Works","Dimensions of Consumer Expertise","The Persuasion Knowledge Model: How People Cope with Persuasion Attempts","SMOG Grading—A New Readability Formula","Measuring consumer involvement profiles","SMOG Grading—A New Readability Formula","LDAvis: A Method for Visualizing and Interpreting Topics","Scaling to Very Very Large Corpora for Natural Language Disambiguation","Strategic orientation o business enterprises: the construct, dimensionality and measurement","Basic content analysis","Introductory econometrics: A modern approach","Market orientation: Antecedents and consequences","Market orientation: The construct, research propositions, and managerial implications","The effect of a market orientation on business profitability","The capabilities of market-driven organizations","Local Consumer Review Survey 2018","Use and Impact of Online Travel Reviews","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","Content analysis","Who Is the Celebrity Endorser? Cultural Foundations of the Endorsement Process","The development and psychometric properties of LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","The development and psychometric properties of LIWC2015","Speech Acts: An Essay in the Philosophy of Language","How to Do Things with Words","Distinction: A Social Critique of the Judgement of Taste","The forms of capital","Experiencing Narrative Worlds: On the Psychological Activities of Reading","The capabilities of market-driven organizations","Prospect theory: An analysis of decision under risk","Market orientation: The construct, research propositions, and managerial implications","Supervised sequence labelling with recurrent neural networks","Call for papers: rise of the machines? Customer engagement through automated service interactions","Call for papers: rise of the machines? Customer engagement through automated service interactions","Pipelines, Platforms, and the New Rules of Strategy","A correlated topic model of science","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","The voice of the customer","Introduction to Information Retrieval","The development and psychometric properties of LIWC2015","Managing Brand Equity","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Conceptualizing, measuring, and managing customer-based brand equity","Strategic brand management: Building, measuring, and managing brand equity","Content analysis","An exploration of the brand identity-brand image linkage: A communications perspective","Automatic text processing","Text mining","Conceptualizing, measuring, and managing customer-based brand equity","It’s really fascinating work: Differences in evaluative adjectives across academic registers","Text mining","In the Mind's Eye: Transportation-Imagery Model of Narrative Persuasion","Econometric Analysis","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Content analysis","The development and psychometric properties of LIWC2015","All reviews are not created equal: the disaggregate impact of reviews and reviewers at Amazon.Com","Experiencing Narrative Worlds: On the Psychological Activities of Reading","A correlated topic model of science","Online consumer-generated reviews have significant impact on offline purchase behavior","An Approach to Environmental Psychology","Experiential marketing","Transcendent customer experience and Brand community","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","The development and psychometric properties of LIWC2015","Quantitative analysis of textual data","The service encounter: Diagnosing favorable and unfavorable incidents","The service encounter: diagnosing favorable and unfavorable incidents","Social Ties and Word-of-Mouth Referral Behavior","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","Laddering theory, method, analysis, and interpretation","Product-Class Effects on Brand Commitment and Brand Outcomes: The Role of Brand Trust and Brand Affect","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","The development and psychometric properties of LIWC2015","On consumer beliefs about quality and taste","Distributional structure","Introduction to latent semantic analysis","Word-of-Mouth Communications: A Motivational Analysis","Text mining: the state of the art and the challenges","Neural Networks for Pattern Recognition","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Statistical bibliography or bibliometrics","Market orientation: The construct, research propositions, and managerial implications","A Script-Theoretic Analysis of Industrial Purchasing Behavior","Novelty, Complexity, and Importance as Causal Determinants of Industrial Buyer Behavior","The commitment-trust theory of relationship marketing","Business-to-Business Buying: Challenges and Opportunities","Social media's mindset: When to use which sentiment extraction tool?","Emotions evoked by common words and phrases: Using mechanical turk to create an emotion lexicon","When words sweat: Identifying signals for loan default in the text of loan applications","A new ANEW: evaluation of a word list for sentiment analysis in microblogs","A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","The development and psychometric properties of LIWC2015","Twitter sentiment classification using distant supervision","Gensim–Python framework for vector space modelling","Work and/or fun: Measuring hedonic and utilitarian shopping value","Use and Impact of Online Travel Reviews","Destinations’ Information Competition and Web Reputation","Web2.0: Conceptual foundations and marketinngissues","Introduction to Information Retrieval","Consumer Selection of Motion Pictures","Modeling Goes to Hollywood: Predicting Individual Differences in Movie Enjoyment","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The development and psychometric properties of LIWC2015","Speech Acts: An Essay in the Philosophy of Language","The effects of content characteristics on consumer engagement with branded social media content on Facebook","How to Do Things with Words","A Performative View of Language—Methodological Considerations and Consequences for the Study of Culture","What Does Familiarity Breed? Complexity as a Moderator of Repetition Effects in Advertisement Evaluation","Which hotel attributes matter?","Introduction to Information Retrieval","tidytext: Text Mining and Analysis Using Tidy Data Principles in R","Sentiment analysis of Twitter data","Twitter sentiment classification using distant supervision","The voice of the customer","Distributional structure","The house of quality","Text mining: the state of the art and the challenges","A correlated topic model of science","Crisp-Dm 1.0","Linguistic Inquiry and Word Count: LIWC2015","Sentiment Analysis and Opinion Mining","A new ANEW: evaluation of a word list for sentiment analysis in microblogs","A conceptual model of service quality and its implications for future research","SERVQUAL: a multiple-item scale for measuring consumer perceptions of service quality","Customer satisfaction, market share and profitability: findings from Sweden","SERVQUAL: review, critique, research agenda","Measuring service quality: a reexamination and extension","SERVPERF versus SERVQUAL: reconciling performance-based and perceptions-minus-expectations measurement of service quality","Advertising as information","The commitment-trust theory of relationship marketing","Measuring Emotions in the Consumption Experience","Product-Class Effects on Brand Commitment and Brand Outcomes: The Role of Brand Trust and Brand Affect","Understanding the socialised body: A poststructuralist analysis of consumers’ self conceptions, body images, and self care practices","WordStat: Content Analysis Module for SIM- STAT","Linguistic Inquiry and Word Count: LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","The development and psychometric properties of LIWC2015","Central and peripheral routes to advertising effectiveness: The moderating role of involvement","Subcultures of consumption: An ethnography of the new bikers","On consumer beliefs about quality and taste","Culture and Consumption: A Theoretical Account of the Structure and Movement of the Cultural Meaning of Consumer Goods","Quantitative Text Analysis","Communicating Brand Personality: Are the Websites Doing the Talking for the Top South African Business Schools?","Content analysis","In the Mind's Eye: Transportation-Imagery Model of Narrative Persuasion","Logic and Conversation","Content analysis in consumer research","AParadigmforDevelopingBetterMeasuresofMarketing Constructs,”","Hermeneutics and consumer research","Controlling the false discovery rate: a practical and powerful approach to multiple testing","An analysis of transformations","Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings","Nrc emotion lexicon","Sentiment Analysis and Opinion Mining","Principles of Marketing","Marketing services: Competing through quality","Consumer-based brand equity: Development and validation of a measurement instrument","Consumer perceptions of price, quality, and value: A means-end model and synthesis of evidence","Managing Brand Equity","Managing Brand Equity","Conceptualizing, measuring, and managing customer-based brand equity","Strategic brand management: Building, measuring, and managing brand equity","WordNet: An Electronic Lexical Database","lda: Collapsed Gibbs Sampling Methods for Topic Models","Introduction to Information Retrieval","LDAvis: A Method for Visualizing and Interpreting Topics","User-generated content and travel: A case study on TripAdvisor.com","Product consumption-based affective responses and post-purchase processes","The service encounter: Diagnosing favorable and unfavorable incidents","Which hotel attributes matter?","Text mining: Finding nuggets in mountains of textual data","Online consumer-generated reviews have significant impact on offline purchase behavior","The development and psychometric properties of LIWC2015","Measuring Emotions in the Consumption Experience","Speech Acts: An Essay in the Philosophy of Language","Indirect speech acts","How to Do Things with Words","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Dimensions of Consumer Expertise","Ontology Learning from Text: An Overview,” in","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","A New Product Growth for Model Consumer Durables","Approaches, Tools and Applications for Sentiment Analysis Implementation","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Introduction to Information Retrieval","Introduction to Modern Information Retrieval","Online reviews: Do consumers use them","The Emotions: Facts, Theories, and a New Model","A General Psychoevolutionary Theory of Emotion","Role of product-related conversations in the diffusion of a new product","Affective Norms for English Words (ANEW): Instruction Manual and Affective Ratings","Learning to Classify Text Using Support Vector Machines: Methods, Theory and Algorithms","Biases in dynamic models with fixed effects","Speech Acts: An Essay in the Philosophy of Language","Indirect speech acts","Indirect Speech Acts","How to Do Things with Words","Content analysis","User-generated content and travel: A case study on TripAdvisor.com","A conceptual model of service quality and its implications for future research","Word-of-Mouth Communications: A Motivational Analysis","SERVQUAL: review, critique, research agenda","Measuring service quality: a reexamination and extension","Use and Impact of Online Travel Reviews","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","Culture and Consumption: A Theoretical Account of the Structure and Movement of the Cultural Meaning of Consumer Goods","Consumer Perception of Product Quality and the Country-of-Origin Effect","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Econometric Analysis","Cultures and Organizations: Software of the Mind","Multivariate Analysis","Singapore's image as a tourist destination","Relationship marketing theory: Its roots and direction","Psychographics: A critical review","Effects of Word-of-Mouth and Product-Attribute Information on Persuasion: An Accessibility-Diagnosticity Perspective","Quantitative Text Analysis","Destinations’ Information Competition and Web Reputation","Conceptualizing, measuring, and managing customer-based brand equity","What Does Familiarity Breed? Complexity as a Moderator of Repetition Effects in Advertisement Evaluation","Introduction to Mediation, Moderation, and Conditional Process Analysis—A Regression-based Approach","Prospect theory: An analysis of decision under risk","Linguistic Cues to Deception Assessed by Computer Programs: A Meta-Analysis","Role of product-related conversations in the diffusion of a new product","WordNet: An Electronic Lexical Database","Text mining","The brandscape: Converting image into equity","Customer-oriented approaches to identifying product-markets","Virtual communities of consumption: Networks of consumer-knowledge and companionship","Conceptualizing, measuring, and managing customer-based brand equity","Strategic brand management: Building, measuring, and managing brand equity","Modeling Goes to Hollywood: Predicting Individual Differences in Movie Enjoyment","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Multivariate Analysis","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","A probabilistic choice model for market segmentation and elasticity structure","Diffusion of innovations","Role of product-related conversations in the diffusion of a new product","The service encounter: diagnosing favorable and unfavorable incidents","User acceptance of computer technology: a comparison of two theoretical models","Word-of-Mouth Communications: A Motivational Analysis","Role of product-related conversations in the diffusion of a new product","A New Product Growth for Model Consumer Durables","Possessions and the extended self","How damaging is negative word of mouth","The Market Maven: A Diffuser of Marketplace Information","Content analysis in consumer research","The service encounter: Diagnosing favorable and unfavorable incidents","Ward's clustering algorithm","Negative word-of-mouth by dissatisfied consumers: A pilot study","Mapping Product Constellations: A Social Categorization Approach to Consumption Symbolism","The effect of a market orientation on business profitability","Introductory econometrics: A modern approach","Market orientation: Antecedents and consequences","Market orientation: The construct, research propositions, and managerial implications","Assessing advantage: A framework for diagnosing competitive superiority","Biases in dynamic models with fixed effects","The development and psychometric properties of LIWC2015","Grounding in communication","Are product attribute beliefs the only mediator of advertising effects on brand attitude","Negative word-of-mouth by dissatisfied consumers: A pilot study","Diffusion of innovations","Conditional random fields: Probabilistic models for segmenting and labeling sequence data","Opinion observer: Analyzing and comparing opinions on the web","Introduction to Modern Information Retrieval","Testing competitive market structures","Customer-oriented approaches to identifying product-markets","Text mining: Finding nuggets in mountains of textual data","Measuring interpersonal influence in online conversations","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","WordNet: An Electronic Lexical Database","The dimensions of reputation in electronic markets","Predicting the future with social media","The service encounter: diagnosing favorable and unfavorable incidents","Measuring interpersonal influence in online conversations","Content analysis","Introduction to Modern Information Retrieval","Testing competitive market structures","Commercial Use of Conjoint Analysis: An Update","The dimensions of reputation in electronic markets","The voice of the customer","The house of quality","A probabilistic choice model for market segmentation and elasticity structure","Opinion observer: Analyzing and comparing opinions on the web","Opinion observer: Analyzing and comparing opinions on the web","Store atmosphere: An environmental psychology approach","The experiential aspects of consumption: Consumer fantasies, feelings, and fun","Measuring consumer involvement profiles","Understanding the socialised body: A poststructuralist analysis of consumers’ self conceptions, body images, and self care practices","Speech Acts: An Essay in the Philosophy of Language","Hermeneutics and consumer research","Sensemaking in organizations","The service encounter: diagnosing favorable and unfavorable incidents","Ward's clustering algorithm","Negative word-of-mouth by dissatisfied consumers: A pilot study","Basic content analysis","Content analysis in communication research","AParadigmforDevelopingBetterMeasuresofMarketing Constructs,”","The relationship between status consumption and materialism: A cross-cultural comparison of Chinese, Mexican, and American student","Automatic text processing","Neurolinguistic programming (NLP) and its applications to marketing research","Neuro-linguistic programming: implications for advertising and copy strategy","Neurolinguistic programming (NLP) and its applications to marketing research","Neuro-linguistic programming: implications for advertising and copy strategy","Content analysis in consumer research","Content-Analysis Research: An Examination of Applications with Directives for Improving Research Reliability and Objectivity","Cluster analysis in marketing research: review and suggestions for application","Content Analysis of Print Ads from Hong Kong, the People's Republic of China, and Taiwan","Basic content analysis"],"sourcetitle":["Journal of Consumer Research","Linguistic Inquiry and Word Count: LIWC2015","Proceedings of The Workshop on Computational Approaches to Deception Detection","Industrial Marketing Management","Language","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","The Development and Psychometric Properties of LIWC2015","Journal of Retailing","Text analytics with Python: A practitioner's guide to natural language processing","An approach to environmental psychology","Satisfaction: A behavioral perspective on the consumer","Journal of Marketing","Philos. Rhetor.","Correspondence Analysis in Practice","A Primer on Partial Least Squares Structural Equation Modeling (PLS-SEM)","Research design: Qualitative and quantitative approaches","Diffusion of Innovations","Management Science","Econometrica","Managing Brand Equity","Journal of Consumer Research","Journal of the Academy of Marketing Science","In Perspectives on Socially Shared Cognition","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Neural and Intelligent Systems Integration","Journal of Marketing Research","Ontology Learning from Text: Methods, Evaluation and Applications","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Consumer Research","Journal of Marketing","Text mining: Finding nuggets in mountains of textual data","Journal of Consumer Research","Journal of Marketing","Journal of Retailing","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","Full catastrophe living","Journal of Consumer Research","Journal of the Royal Statistical Society: Series B (Methodological)","Linguistic Inquiry and Word Count: LIWC2015","Journal of Marketing Research","Linguistic Inquiry and Word Count: LIWC2015","Management Science","Journal of Marketing","Content Analysis: An Introduction to Its Methodology","European Journal of Education Studies","DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","International Journal of Computer Applications","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Introductory Econometrics: A Modern Approach","Journal of Political Economy","Journal of Political Economy","Introduction to Modern Information Retrieval","Marketing Science Institute Working Paper Series","Journal of Marketing Research","Sentiment Analysis and Opinion Mining","Introduction to Information Retrieval","Journal of Brand Management","Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer","Practical Handbook of Internet Computing","Managing Brand Equity","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Marketing Science","Journal of Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing Research","Journal of Marketing Research","Management Science","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing Research","A Primer on Partial Least Squares Structural Equation Modeling (PLS-SEM)","MIS Quarterly","Modern Optimization with R","Journal of Marketing","The Content Analysis Guidebook","Schmalenbach Business Review","Journal of the Royal Statistical Society: Series B (Methodological)","Introduction to Information Retrieval","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Transactions of the Association for Computational Linguistics","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","Journal of Interactive Advertising","Journal of Marketing","SSRN Electronic Journal","Journal of Consumer Research","Management Science","J. Consum. Res.","Journal of Consumer Research","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Consumer Research","Journal of Consumer Research","Marketing Science Institute Working Paper Series","Journal of Open Source Software","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Journal of Open Source Software","Journal of Open Source Software","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Statistical Research Memoirs","Journal of Marketing Research","Journal of Open Source Software","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","RoBERTa: A robustly optimized BERT pretraining approach","Journal of Consumer Research","Journal of Marketing Research","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Naval Technical Training Command","Research design: Qualitative and quantitative approaches","Journal of Open Source Software","Journal of Marketing","Emerging Perspectives on Services Marketing","Journal of Retailing","Journal of Consumer Research","Journal of Consumer Research","Journal of Brand Management","Linguistic Inquiry and Word Count: LIWC2015","Journal of Consumer Research","Journal of Consumer Research","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Handbook of Social Psychology","Consumer Psychology Review","The Annals of Applied Statistics","Journal of Direct, Data and Digital Marketing Practice","Marketing Science Institute Working Paper Series","Discourse Processes","Journal of Marketing","Journal of Marketing","Customer Needs and Solutions","The International Encyclopedia of Communication Research Methods","Journal of Marketing","Journal of Marketing","The Annals of Applied Statistics","Handbook of theory and research for the sociology of education","Journal of Marketing","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Diffusion of Innovations","Journal of the Royal Statistical Society: Series B (Methodological)","An Introduction to Support Vector Machines and Other Kernel-based Learning Methods","Social and Personality Psychology Compass","Econometrica","An approach to environmental psychology","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Procedia-Social and Behavioral Sciences","Journal of Consumer Research","Journal of Consumer Research","Proceedings of the Workshop on Languages in Social Media","CNN","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Modern Optimization with R","CS224N project report","The Journal of Open Source Software","Research design: Qualitative and quantitative approaches","Journal of Consumer Research","The Uses of Mass Communications: Current Perspectives on Gratifications Research","Journal of Political Economy","Journal of Political Economy","Journal of Political Economy","Speech Acts: An Essay in the Philosophy of Language","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Forum Qual. Soc. Res.","Proceedings of the ESWC2011 Workshop on ‘making Sense of Microposts’: Big Things Come in Small Packages","Journal of Marketing","Journal of Retailing","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Journal of Marketing","Journal of Interactive Advertising","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Econometrica","Linguistic Inquiry and Word Count: LIWC2015","Journal of Marketing","Journal of Marketing","Journal of Consumer Research","Journal of Consumer Research","Journal of Marketing Research","International Journal of Computer Science and Communication Networks","The Development and Psychometric Properties of LIWC2015","Journal of Marketing Management","An approach to environmental psychology","Journal of Marketing Management","Organizational Behavior and Human Decision Processes","Journal of Marketing","arXiv preprint arXiv","Deep Learning","Market segmentation conceptual and methodological foundations","Introduction to Modern Information Retrieval","Ontology Learning from Text: Methods, Evaluation and Applications","Marketing Science","Harvard Business Review","Organizational Behavior and Human Decision Processes","Consumer Psychology Review","The Development and Psychometric Properties of LIWC2015","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Consumer Research","Journal of Reading","The Development and Psychometric Properties of LIWC2015","Speech Acts: An Essay in the Philosophy of Language","In Perspectives on Socially Shared Cognition","The Development and Psychometric Properties of LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","Journal of Marketing Research","Harvard Business Review","Industrial Marketing Management","MIS Quarterly","Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research","Journal of Marketing","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Journal of Marketing","Journal of Consumer Research","The Annals of Applied Statistics","R Package, Version 1.4.2","Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research","Journal of Consumer Research","Harvard Business Review","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Tell me a Story: A New Look at Real and Artificial Memory","Sensemaking in Organizations","Journal of Marketing","Journal of Consumer Research","Content Analysis: An Introduction to Its Methodology","The economic institutions of capitalism","The Development and Psychometric Properties of LIWC2015","Syntax and Semantics","Content Analysis: An Introduction to Its Methodology","Quantitative Analysis of Textual Data","NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Journal of the Royal Statistical Society. Series B (Methodological)","A review of previous and a framework for future research","Cornell Hotel and Restaurant Administration Quarterly","SSRN Electronic Journal","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","J. Advert. Res.","Marketing Science","The Psychology of Personal Constructs: Vol 1 and 2","Principles of marketing","AI adoption in the enterprise 2020","Proc. NAACL-HLT","Journal of Political Economy","WordStat: Content Analysis Module for SIMSTAT","The Development and Psychometric Properties of LIWC2015","The Development and Psychometric Properties of LIWC2015","Managing Brand Equity","Multivariate Data Analysis","Journal of Marketing Research","Content Analysis: An Introduction to Its Methodology","Journal of Marketing","Syntax and Semantics","Journal of Marketing Research","Managing Brand Equity","The Development and Psychometric Properties of LIWC2015","Journal of Consumer Research","Psychology and Marketing","Harvard Business Review","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Marketing","Journal of Consumer Research","Journal of Consumer Research","Journal of Marketing","Journal of Consumer Research","Proceedings of the ESWC2011 Workshop on ‘making Sense of Microposts’: Big Things Come in Small Packages","Matrix completion methods for causal panel data models","Word","Learning to Classify Text Using Support Vector Machines","Cultures and organizations: Software of the mind","The emotions: Facts, theory and a new model","Linguistic Inquiry and Word Count: LIWC2015","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing Research","The Psychology of Personal Constructs: Vol 1 and 2","J. Advert. Res.","Nudge: Improving decisions about health, wealth, and happiness","International Journal of Computer Science and Communication Networks","Journal of Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","International Journal of Computer Applications","Sentiment Analysis and Opinion Mining","Journal of Documentation","Neural networks for pattern recognition","Journal of Marketing","Management Science and Engineering","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","Proceedings of the PAKDD Workshop on Knowledge Discovery from Advanced Databases","Sentiment Analysis and Opinion Mining","Neural and Intelligent Systems Integration","The Development and Psychometric Properties of LIWC2015","Sentiment Analysis and Opinion Mining","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Deep Learning","Ontology Learning from Text: Methods, Evaluation and Applications","Handbook of e-Tourism","Handbook of e-Tourism","Handbook of e-Tourism","Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research","Journal of Marketing Research","J. Consum. Res.","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","The Development and Psychometric Properties of LIWC2015","European Journal of Education Studies","Scalable Recommendation with Poisson Factorization","Cornell Hotel and Restaurant Administration Quarterly","Linguistic Inquiry and Word Count: LIWC2015","Journal of Marketing","Journal of Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Introduction to Information Retrieval","Language","Correspondence Analysis in Practice","Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics","RoBERTa: A robustly optimized BERT pretraining approach","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Proc. 18th Internat. Conf. Machine Learn","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","NRC Emotion Lexicon","The Journal of Open Source Software","Journal of Open Source Software","Advances in Consumer Research","Journal of Open Source Software","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Journal of Documentation","Introduction to Modern Information Retrieval","Content Analysis: An Introduction to Its Methodology","Journal of Marketing","Cultures and organizations: Software of the mind","Management Science and Engineering","Management Science","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","RoBERTa: A robustly optimized BERT pretraining approach","arXiv","Naval Technical Training Command","Linguistic Inquiry and Word Count: LIWC2015","Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks","arXiv preprint arXiv","Proceedings of the ESWC2011 Workshop on ‘making Sense of Microposts’: Big Things Come in Small Packages","The Development and Psychometric Properties of LIWC2015","The Development and Psychometric Properties of LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Journal of Marketing","Journal of Consumer Research","Word","Academy of Marketing Science Review","Cultures and organizations: Software of the mind","An approach to environmental psychology","The Annals of Applied Statistics","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Introduction to Information Retrieval","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Academy of Marketing Science Review","The International Encyclopedia of Communication Research Methods","Journal of Marketing","IBM","Industrial Marketing Management","Cornell Hospitality Report","Introduction to Modern Information Retrieval","Ritsumeikan Social Sciences Review","Ritsumeikan Social Sciences Review","An approach to environmental psychology","Journal of Marketing","The Content Analysis Guidebook","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing","L'evoluzione dei fenomeni sociali attraverso la rete","Introduction to Information Retrieval","Proc. NAACL-HLT","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The Development and Psychometric Properties of LIWC2015","RoBERTa: A robustly optimized BERT pretraining approach","Academy of Management Annals","The Development and Psychometric Properties of LIWC2015","Synthese","Journal of Consumer Research","Distinction: A Social Critique of the Judgement of Taste","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Marketing","Naval Technical Training Command","The Development and Psychometric Properties of LIWC2015","Text Mining and Analysis: Practical Methods, Examples, and Case Studies using SAS®","DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter","Transactions of the Association for Computational Linguistics","The Innovator’s Dilemma: When New Technologies Cause Great Firms to Fail","Journal of Retailing","Journal of Marketing Management","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Consumer Research","Journal of Marketing","Managing Brand Equity","ACR 2001 Proceedings","Deep Learning","Marketing Sci","The Development and Psychometric Properties of LIWC2015","Journal of Consumer Research","dplyr: A grammar of data manipulation","Proc. NAACL-HLT","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","The Journal of Open Source Software","The Uses of Mass Communications: Current Perspectives on Gratifications Research","Journal of Retailing","Journal of Marketing Research","An approach to environmental psychology","Journal of Marketing","Journal of Marketing","Management Science","Journal of Retailing","The Development and Psychometric Properties of LIWC2015","Journal of Retailing","Journal of Interactive Advertising","Journal of Marketing","Journal of Marketing","Journal of International Marketing","Journal of Political Economy","dplyr: A grammar of data manipulation","Local Consumer Review Survey","The Development and Psychometric Properties of LIWC2015","AI adoption in the enterprise 2020","Matrix completion methods for causal panel data models","Journal of Marketing","RoBERTa: A robustly optimized BERT pretraining approach","Journal of Retailing","J. Retailing","Journal of Marketing","Journal of Marketing","Journal of Marketing Research","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Econometric Analysis","Tell me a Story: A New Look at Real and Artificial Memory","Journal of Marketing","Linguistic Inquiry and Word Count: LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","Harvard Business Review","The Innovator’s Dilemma: When New Technologies Cause Great Firms to Fail","When Words Sweat: Identifying Signals for Loan Default in the Text of Loan Applications","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Diffusion of Innovations","Management Science","American Journal of Sociology","Social and Personality Psychology Compass","Journal of Consumer Research","Journal of Brand Management","Language and Computers","Advances in Consumer Research","Practical Handbook of Internet Computing","Advances in Consumer Research","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","The Development and Psychometric Properties of LIWC2015","Journal of the Association for Consumer Research","Journal of the Association for Consumer Research","Journal of Consumer Research","Harvard Business Review","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Principles of marketing","The Development and Psychometric Properties of LIWC2015","The economic institutions of capitalism","Journal of Consumer Research","Diffusion of Innovations","Journal of Marketing Research","Current Contents","Current Contents","Journal of Consumer Research","Distinction: A Social Critique of the Judgement of Taste","Journal of Marketing Research","Journal of Marketing","Getting Started with SAS® Text Miner","Neural and Intelligent Systems Integration","Journal of the Royal Statistical Society: Series B (Methodological)","Market segmentation conceptual and methodological foundations","Ontology Learning from Text: Methods, Evaluation and Applications","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Econometric Analysis","Journal of Reading","The Development and Psychometric Properties of LIWC2015","Econometrica","Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks","Text analytics with Python: A practitioner's guide to natural language processing","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Language","Journal of Marketing","Nudge: Improving decisions about health, wealth, and happiness","Journal of Marketing","The Development and Psychometric Properties of LIWC2015","Getting Started with SAS® Text Miner","Marketing Services—Competing through Quality","Journal of Marketing Theory and Practice","Journal of Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Consumer Research","Journal of Marketing","Journal of Marketing","Journal of Retailing","Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer","Journal of Marketing","Journal of Marketing","Content Analysis: An Introduction to Its Methodology","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Journal of Marketing Research","Emerging Perspectives on Services Marketing","Journal of Retailing","J. Retailing","Journal of Marketing","The Development and Psychometric Properties of LIWC2015","European Journal of Marketing","Journal of Marketing","Journal of Consumer Research","Syntax and Semantics","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Journal of Consumer Research","Statistical Research Memoirs","Journal of Interactive Advertising","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Journal of Marketing Research","Mark. Bull.","Management Science","Academy of Management Annals","The Secret Life of Pronouns","The Development and Psychometric Properties of LIWC2015","The Development and Psychometric Properties of LIWC2015","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Cultures and organizations: Software of the mind","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","RoBERTa: A robustly optimized BERT pretraining approach","Philos. Rhetor.","Journal of Documentation","Journal of Consumer Research","Content Analysis: An Introduction to Its Methodology","Satisfaction: A behavioral perspective on the consumer","Cornell Hospitality Report","Modern Optimization with R","Journal of Marketing Management","Journal of Consumer Research","Management Science","Current Contents","IBM","Market segmentation conceptual and methodological foundations","The Annals of Applied Statistics","Scalable Recommendation with Poisson Factorization","Marketing Sci","Journal of Marketing","The Development and Psychometric Properties of LIWC2015","Journal of Marketing Research","Management Science","Journal of Marketing Research","Journal of Marketing Management","Journal of Marketing","Journal of Marketing","Journal of Marketing","The Secret Life of Pronouns","The Development and Psychometric Properties of LIWC2015","Forbes","Forbes","Forbes","Journal of Marketing Research","Practical Handbook of Internet Computing","L'evoluzione dei fenomeni sociali attraverso la rete","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Journal of Brand Management","The Content Analysis Guidebook","Basic Content Analysis","International Journal of Tourism Research","Contentanalysis Incommunicationresearch","An Introduction to Support Vector Machines and Other Kernel-based Learning Methods","Theories of Emotion","Text Mining and Analysis: Practical Methods, Examples, and Case Studies using SAS®","Bert: Pre-Training of Deep Bidirectional Transformers for Language Understanding","Journal of Retailing","European Journal of Marketing","Modern Optimization with R","Procedia-Social and Behavioral Sciences","Journal of Consumer Research","Econometrica","Journal of Marketing","Principles of marketing","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","The Annals of Applied Statistics","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing","Handbook of Social Psychology","Predicting the Future with Social Media","Journal of Marketing","Econometrica","Harvard Business Review","Journal of Marketing","The Development and Psychometric Properties of LIWC2015","Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer","Managing Brand Equity","ADMAP","Doctoral Dissertation","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Marketing Science","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Content Analysis: An Introduction to Its Methodology","Journal of Marketing Research","Journal of Consumer Research","CRISP-DM Consortium","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing","Journal of Marketing","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Basic Content Analysis","Journal of the Royal Statistical Society: Series B (Methodological)","The Motion Picture Mega-Industry","Management Science","Journal of Marketing Research","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Journal of the Royal Statistical Society. Series B (Methodological)","Content Analysis: An Introduction to Its Methodology","The Content Analysis Guidebook","Speech Acts: An Essay in the Philosophy of Language","Content Analysis: An Introduction to Its Methodology","Journal of Brand Management","Linguistic Inquiry and Word Count: LIWC2015","Journal of Marketing Research","Econometric Analysis","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Introductory Econometrics: A Modern Approach","The Development and Psychometric Properties of LIWC2015","Schmalenbach Business Review","The Secret Life of Pronouns","The Development and Psychometric Properties of LIWC2015","Journal of Marketing Research","Handbook of theory and research for the sociology of education","Research design: Qualitative and quantitative approaches","Correspondence Analysis in Practice","Full catastrophe living","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The Development and Psychometric Properties of LIWC2015","Journal of Retailing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Consumer Research","Multivariate Data Analysis","Proceedings of the Workshop on Languages in Social Media","Journal of Consumer Research","Content Analysis: An Introduction to Its Methodology","Basic Content Analysis","Proceedings of the Workshop on Languages in Social Media","Journal of Consumer Research","CNN","Local Consumer Review Survey","Diffusion of Innovations","Word","comScore","Diffusion of Innovations","CS224N project report","Deep Learning","Supervised Sequence Lagelling with Recurrent Neural Networks","arXiv preprint arXiv","arXiv","The Innovator’s Dilemma: When New Technologies Cause Great Firms to Fail","Journal of Political Economy","Journal of Political Economy","Journal of Marketing","Diffusion of Innovations","Journal of Brand Management","WordStat: Content Analysis Module for SIMSTAT","Linguistic Inquiry and Word Count: LIWC2015","Scalable Recommendation with Poisson Factorization","Marketing Science Institute Working Paper Series","Management Science","American Journal of Sociology","Harvard Business Review","Journal of Consumer Research","Journal of Consumer Research","Journal of Reading","Journal of Marketing Research","Journal of Reading","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics","Management Science","Basic Content Analysis","Introductory Econometrics: A Modern Approach","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing","Local Consumer Review Survey","Information and Communication Technologies in Tourism","Journal of Consumer Research","Content Analysis: An Introduction to Its Methodology","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Speech Acts: An Essay in the Philosophy of Language","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Distinction: A Social Critique of the Judgement of Taste","Handbook of theory and research for the sociology of education","Experiencing Narrative Worlds: On the Psychological Activities of Reading","Journal of Marketing","Econometrica","Journal of Marketing","Supervised Sequence Lagelling with Recurrent Neural Networks","Journal of Service Research","Journal of Service Research","Harvard Business Review","The Annals of Applied Statistics","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Marketing Science","Introduction to Information Retrieval","The Development and Psychometric Properties of LIWC2015","Managing Brand Equity","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Content Analysis: An Introduction to Its Methodology","Journal of Brand Management","Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer","Practical Handbook of Internet Computing","Journal of Marketing","Language and Computers","Practical Handbook of Internet Computing","Narrative Impact: Social and Cognitive Foundations","Econometric Analysis","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Content Analysis: An Introduction to Its Methodology","The Development and Psychometric Properties of LIWC2015","SSRN Electronic Journal","Experiencing Narrative Worlds: On the Psychological Activities of Reading","The Annals of Applied Statistics","comScore","An approach to environmental psychology","Journal of Marketing Management","Journal of the Academy of Marketing Science","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Quantitative Analysis of Textual Data","Journal of Marketing","Journal of Marketing","Journal of Consumer Research","Journal of Marketing","J. Advert. Res.","Brand Manag.","Journal of Consumer Research","The Development and Psychometric Properties of LIWC2015","Journal of Consumer Research","Word","Discourse Processes","Advances in Consumer Research","Proceedings of the PAKDD Workshop on Knowledge Discovery from Advanced Databases","Neural networks for pattern recognition","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Documentation","Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Marketing","Customer Needs and Solutions","Marketing Science Institute Working Paper Series","Proc. NAACL-HLT","When Words Sweat: Identifying Signals for Loan Default in the Text of Loan Applications","Proceedings of the ESWC2011 Workshop on ‘making Sense of Microposts’: Big Things Come in Small Packages","A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts","The Development and Psychometric Properties of LIWC2015","CS224N project report","NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic","Journal of Consumer Research","Information and Communication Technologies in Tourism","Information Technology & Tourism","Journal of Direct, Data and Digital Marketing Practice","Introduction to Information Retrieval","The Motion Picture Mega-Industry","Management Science","Text Data Management and Analysis: A Practical Introduction to Information Retrieval and Text Mining","The Development and Psychometric Properties of LIWC2015","Speech Acts: An Essay in the Philosophy of Language","Marketing Science Institute Working Paper Series","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Forum Qual. Soc. Res.","Journal of Consumer Research","A review of previous and a framework for future research","Introduction to Information Retrieval","The Journal of Open Source Software","Proceedings of the Workshop on Languages in Social Media","CS224N project report","Marketing Science","Word","Harvard Business Review","Proceedings of the PAKDD Workshop on Knowledge Discovery from Advanced Databases","The Annals of Applied Statistics","CRISP-DM Consortium","Linguistic Inquiry and Word Count: LIWC2015","Sentiment Analysis and Opinion Mining","Proceedings of the ESWC2011 Workshop on ‘making Sense of Microposts’: Big Things Come in Small Packages","Journal of Marketing","Journal of Retailing","Journal of Marketing","European Journal of Marketing","Journal of Marketing","Journal of Marketing","Journal of Political Economy","Journal of Marketing","Journal of Consumer Research","Brand Manag.","Journal of Consumer Research","WordStat: Content Analysis Module for SIMSTAT","Linguistic Inquiry and Word Count: LIWC2015","Linguistic Inquiry and Word Count: LIWC2015","The Development and Psychometric Properties of LIWC2015","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Journal of Consumer Research","Handbook of Multimethod Measurement in Psychology","Journal of Brand Management","Content Analysis: An Introduction to Its Methodology","Narrative Impact: Social and Cognitive Foundations","Syntax and Semantics","Journal of Consumer Research","Journal of Marketing Research","J. Cons. Res.","Journal of the Royal Statistical Society. Series B (Methodological)","Journal of the Royal Statistical Society: Series B (Methodological)","Technical Report. Technical Report C-1","NRC Emotion Lexicon","Sentiment Analysis and Opinion Mining","Principles of marketing","Marketing Services—Competing through Quality","Journal of Marketing Management","Journal of Marketing","Managing Brand Equity","Managing Brand Equity","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Language","R Package, Version 1.4.2","Introduction to Information Retrieval","Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces","Information and Communication Technologies in Tourism","Journal of Marketing Research","Journal of Marketing","A review of previous and a framework for future research","Text mining: Finding nuggets in mountains of textual data","comScore","The Development and Psychometric Properties of LIWC2015","Journal of Consumer Research","Speech Acts: An Essay in the Philosophy of Language","Syntax and Semantics 3: Speech Acts","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Journal of Consumer Research","Ontology Learning from Text: Methods, Evaluation and Applications","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Management Science","International Journal of Computer Applications","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Introduction to Information Retrieval","Introduction to Modern Information Retrieval","ACR 2001 Proceedings","The emotions: Facts, theory and a new model","Theories of Emotion","Journal of Marketing Research","Technical Report. Technical Report C-1","Learning to Classify Text Using Support Vector Machines","Econometrica","Speech Acts: An Essay in the Philosophy of Language","Syntax and Semantics 3: Speech Acts","Synthese","How to do Things with Words: The William James Lectures Delivered at Harvard University in 1955","Content Analysis: An Introduction to Its Methodology","Information and Communication Technologies in Tourism","Journal of Marketing","Advances in Consumer Research","European Journal of Marketing","Journal of Marketing","Information and Communication Technologies in Tourism","Journal of Consumer Research","Journal of Consumer Research","Journal of International Marketing","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Econometric Analysis","Cultures and organizations: Software of the mind","Multivariate Data Analysis","International Journal of Tourism Research","Journal of Marketing Management","Journal of Marketing Research","Journal of Consumer Research","Handbook of Multimethod Measurement in Psychology","Information Technology & Tourism","Journal of Marketing","Journal of Consumer Research","Introduction to Mediation, Moderation, and Conditional Process Analysis: A Regression-Based Approach","Econometrica","Proceedings of The Workshop on Computational Approaches to Deception Detection","Journal of Marketing Research","Language","Practical Handbook of Internet Computing","ADMAP","Journal of Marketing","Doctoral Dissertation","Journal of Marketing","Strategic Brand Management: Building, Measuring, and Managing Brand Equity","Management Science","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Multivariate Data Analysis","Journal of Consumer Research","Journal of Marketing Research","Diffusion of Innovations","Journal of Marketing Research","Journal of Marketing","Management Science","Advances in Consumer Research","Journal of Marketing Research","Management Science","Journal of Consumer Research","Mark. Bull.","Journal of Marketing","Journal of Consumer Research","Journal of Marketing","Encyclopedia of Statistical Sciences","Journal of Marketing","Psychology and Marketing","Journal of Marketing","Introductory Econometrics: A Modern Approach","Journal of Marketing","Journal of Marketing","Journal of Marketing","Econometrica","The Development and Psychometric Properties of LIWC2015","In Perspectives on Socially Shared Cognition","Journal of Marketing Research","Journal of Marketing","Diffusion of Innovations","Proc. 18th Internat. Conf. Machine Learn","Proc. 14th Internat. Conf. World Wide Web","Introduction to Modern Information Retrieval","Marketing Science","Journal of Marketing","Text mining: Finding nuggets in mountains of textual data","Measuring Interpersonal Influence in Online Conversations","The Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data","Language","The Dimensions of Reputation in Electronic Markets","Predicting the Future with Social Media","Journal of Marketing","Measuring Interpersonal Influence in Online Conversations","Content Analysis: An Introduction to Its Methodology","Introduction to Modern Information Retrieval","Marketing Science","Journal of Marketing","The Dimensions of Reputation in Electronic Markets","Marketing Science","Harvard Business Review","Journal of Marketing Research","Proc. 14th Internat. Conf. World Wide Web","Proc. 14th Internat. Conf. World Wide Web","Journal of Retailing","Journal of Consumer Research","Journal of Marketing Research","Journal of Consumer Research","Speech Acts: An Essay in the Philosophy of Language","J. Cons. Res.","Sensemaking in Organizations","Journal of Marketing","Encyclopedia of Statistical Sciences","Journal of Marketing","Basic Content Analysis","Contentanalysis Incommunicationresearch","Journal of Marketing Research","Journal of Marketing Theory and Practice","Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer","Canadian Journal of Marketing Research","Proceedings of the 1990 Conference of the American Academy of Advertising","Canadian Journal of Marketing Research","Proceedings of the 1990 Conference of the American Academy of Advertising","Journal of Consumer Research","Journal of Consumer Research","Journal of Marketing Research","Journal of Consumer Research","Basic Content Analysis"],"year":["NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA","NA"],"author-list.author.ce:indexed-name":["Wells W.","Pennebaker J.W.","Hauch V.","Kauffmann E.","Fellbaum C.","Hayes A.F.","Pennebaker J.W.","Parasuraman A.","Sarkar D.","Mehrabian A.","Oliver R.L.","Cronin J.J.","Fishbein M.","Greenacre M.","Hair J.","Creswell J.W.","Rogers E.M.","Bass F.M.","Holtz-Eakin D.","Aaker D.A.","Belk R.W.","Schouten J.W.","Clark H.H.","Hayes A.F.","Soucek B.","Kamakura W.A.","Buitelaar P.","Feldman R.","Herr P.M.","Zeithaml V.A.","Dorre J.","Belk R.W.","Fornell C.","Parasuraman A.","Zhai C.X.","Kabat-Zinn J.","Novak T.","Tibshirani R.","Pennebaker J.W.","Churchill G.A.","Pennebaker J.W.","Davis F.D.","Fornell C.","Krippendorff K.","Queiros A.","Sanh V.","D'Andrea A.","Devlin J.","Wooldridge J.","Nelson P.","Nelson P.","Salton G.","Kubler R.V.","Laurent G.","Liu B.","Manning C.D.","NANDAN S.","Salton G.","Witten I.H.","Aaker D.A.","Keller K.L.","Keller K.L.","Keller K.L.","Urban G.L.","Day G.S.","Feldman R.","Hauser J.R.","Kamakura W.A.","Venkatraman N.","Jaworski B.J.","Day G.S.","Day G.S.","Fornell C.","Hair J.","Webster J.","Cortez P.","Narver J.C.","Neuendorf K.A.","Gruber M.","Tibshirani R.","Manning C.D.","Novak T.","Pennebaker J.W.","Bojanowski P.","Devlin J.","Pang B.","Xia L.","Zeithaml V.A.","Chen P.-Y.","Edell J.A.","Eliashberg J.","Ford G.T.","Holbrook M.B.","Hayes A.F.","Packard G.","Packard G.","Stephen A.T.","Kearney M.W.","Pennebaker J.W.","Pennebaker J.W.","Barrie C.","Benoit K.","Hayes A.F.","Johnson P.O.","Westbrook R.A.","Benoit K.","Devlin J.","Liu Y.","Edell J.A.","Fornell C.","Hayes A.F.","Kincaid J.P.","Creswell J.W.","Benoit K.","Cronin J.J.","Lewis C.","Parasuraman A.","Belk R.W.","Packard G.","Opoku R.","Pennebaker J.W.","Packard G.","Packard G.","Pennebaker J.W.","Pennebaker J.W.","Keltner D.","Moore S.G.","Blei D.M.","Constantinides E.","Kubler R.V.","Landauer T.K.","McQuiston D.H.","Morgan R.M.","Grewal R.","Breuer J.","Crosby L.A.","Zeithaml V.A.","Blei D.M.","Bourdieu P.","Keller K.L.","Packard G.","Pennebaker J.W.","Rogers E.M.","Tibshirani R.","Cristianini N.","Kashima Y.","Kahneman D.","Mehrabian A.","Petty R.","Richins Marsha L.","Babin B.J.","Gheorghe I.R.","Herr P.M.","Holbrook M.B.","Agarwal A.","McKenzie D.","Devlin J.","Cortez P.","Go A.","Silge J.","Creswell J.W.","Friestad M.","Katz E.","Nelson P.","Nelson P.","Nelson P.","Searle J.R.","Austin J.L.","Barinaga E.","Nielsen F.A.","Parasuraman A.","Parasuraman A.","McAlister L.","Pennebaker J.W.","Parasuraman A.","Krishnamurthy S.","Devlin J.","Heckman J.J.","Pennebaker J.W.","Zeithaml V.A.","Keller K.L.","McCracken G.","Sirgy M.J.","Fornell C.","Vijayarani S.","Pennebaker J.W.","Schmitt B.","Mehrabian A.","Moller K.","Small D.A.","Bagozzi R.P.","Mikolov T.","Goodfellow I.","Wedel M.","Salton G.","Buitelaar P.","Griffin A.","Hauser J.R.","Small D.A.","Moore S.G.","Pennebaker J.W.","Hayes A.F.","Herr P.M.","McLaughlin G.H.","Pennebaker J.W.","Searle J.R.","Clark H.H.","Pennebaker J.W.","Pennebaker J.W.","Spiro R.L.","Mayer D.","Kauffmann E.","Webster J.","Fishbein M.","Hirschman E.C.","Sievert C.","Zeithaml V.A.","Belk R.W.","Blei D.M.","Chang J.","Fishbein M.","Holbrook M.B.","Mayer D.","Pennebaker J.W.","Pennebaker J.W.","Schank R.C.","Weick K.E.","Day G.S.","Kassarjian H.H.","Krippendorff K.","Williamson O.","Pennebaker J.W.","Grice H.P.","Krippendorff K.","Benoit K.","Rehurek R.","Sievert C.","Benjamini Y.","Dolnicar S.","Gundersen M.G.","Chen P.-Y.","Hayes A.F.","Reynolds T.J.","Urban G.L.","Kelly G.A.","Kotler P.","Magoulas R.","Mohammad S.","Nelson P.","Peladeau N.","Pennebaker J.W.","Pennebaker J.W.","Aaker D.A.","Hair J.F.","Hauser J.R.","Krippendorff K.","Crosby L.A.","Grice H.P.","Mitchell A.A.","Aaker D.A.","Pennebaker J.W.","Sirgy M.J.","Solomon M.R.","Van Alstyne M.W.","Hayes A.F.","Keller K.L.","Grant M.","McCracken G.","Bagozzi R.P.","Belk R.W.","Nielsen F.A.","Athey S","Harris Z.S.","Joachims T.","Hofstede G.","Plutchik R.","Pennebaker J.W.","Feldman R.","Hauser J.R.","Kelly G.A.","Reynolds T.J.","Thaler R.H.","Vijayarani S.","Anderson E.W.","Feldman R.","D'Andrea A.","Liu B.","Pritchard A.","Bishop C.M.","Lavidge R.","Chen T.B.","Zhai C.X.","Tan A.","Liu B.","Soucek B.","Pennebaker J.W.","Liu B.","Feldman R.","Goodfellow I.","Buitelaar P.","Fuchs M.","Fuchs M.","Fuchs M.","Fishbein M.","Fornell C.","Ford G.T.","Sievert C.","Pennebaker J.W.","Queiros A.","Gopalan P.","Gundersen M.G.","Pennebaker J.W.","Bitner M.J.","Leigh T.W.","Feldman R.","Manning C.D.","Fellbaum C.","Greenacre M.","Banko M.","Liu Y.","Devlin J.","Lafferty J.","Devlin J.","Mohammad S.M.","Silge J.","Barrie C.","Beckham D.","Kearney M.W.","Devlin J.","Pritchard A.","Salton G.","Krippendorff K.","Morgan R.M.","Hofstede G.","Chen T.B.","Culnan M.","Devlin J.","Liu Y.","Cho K","Kincaid J.P.","Pennebaker J.W.","Rehurek R","Mikolov T.","Nielsen F.A.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Gross B.L.","Spiller S.A.","Harris Z.S.","Wiedmann K.P.","Hofstede G.","Mehrabian A.","Blei D.M.","Austin J.L.","Manning C.D.","Devlin J.","Wiedmann K.P.","Breuer J.","Hirschman E.C.","Schneider C.","Kauffmann E.","Needles A.","Salton G.","Higuchi K.","Higuchi K.","Mehrabian A.","Keller K.L.","Neuendorf K.A.","Feldman R.","Hirschman E.C.","CERON A.","Manning C.D.","Mohammad S.","Zhai C.X.","Pennebaker J.W.","Liu Y.","Magee J.C.","Pennebaker J.W.","Asher N.","Babin B.J.","Bourdieu P.","Hayes A.F.","Hayes A.F.","Feick L.F.","Kincaid J.P.","Pennebaker J.W.","Chakraborty G.","Sanh V.","Bojanowski P.","Christensen C.M.","Parasuraman A.","Vazquez R.","Hayes A.F.","Herr P.M.","Keller K.L.","Aaker D.A.","Chatterjee P.","Goodfellow I.","Guadagni PM","Pennebaker J.W.","Babin B.J.","Wickham H.","Mohammad S.","Sievert C.","Silge J.","Katz E.","Parasuraman A.","Punj G.","Mehrabian A.","Hirschman E.C.","Cronin J.J.","Davis F.D.","Donovan R.J.","Pennebaker J.W.","Parasuraman A.","Krishnamurthy S.","Parasuraman A.","Bitner M.J.","Elliott G.R.","Nelson P.","Wickham H.","BrightLocal","Pennebaker J.W.","Magoulas R.","Athey S","Cronin J.J.","Liu Y.","Parasuraman A.","Parasuraman AA","Wittink D.R.","Keller K.L.","Rust R.T.","Spiggle S.","Wells W.","Alba J.W.","Greene W.H.","Schank R.C.","Bagozzi R.P.","Pennebaker J.W.","Pennebaker J.W.","Bower J.","Christensen C.M.","Netzer O.","Pennebaker J.W.","Pennebaker J.W.","Rogers E.M.","Bass F.M.","Bielby W.","Kashima Y.","McAlister L.","NANDAN S.","SWALES J.M.","Beckham D.","Witten I.H.","Beckham D.","Keller K.L.","Keller K.L.","Pennebaker J.W.","Van Esch Patrick","Van Esch Patrick","Brown J.J.","Dichter E.","Hayes A.F.","Kotler P.","Pennebaker J.W.","Williamson O.","Schouten J.W.","Rogers E.M.","Fornell C.","Garfield E.","Garfield E.","Belk R.W.","Bourdieu P.","Kamakura W.A.","Richins M.L.","SAS","Soucek B.","Tibshirani R.","Wedel M.","Buitelaar P.","Feldman R.","Greene W.H.","McLaughlin G.H.","Pennebaker J.W.","Holtz-Eakin D.","Rehurek R","Sarkar D.","Devlin J.","Fellbaum C.","Kohli A.K.","Thaler R.H.","Zeithaml V.A.","Pennebaker J.W.","SAS","Berry L.","Eastman J.K.","Feick L.F.","Feldman R.","Friestad M.","Zeithaml V.A.","Parasuraman A.","Parasuraman A.","Salton G.","Cronin J.J.","Cronin J.J.","Krippendorff K.","Sievert C.","Spiro R.L.","Lewis C.","Parasuraman A.","Parasuraman AA","Parasuraman A.","Pennebaker J.W.","Buttle F.","Cronin J.J.","Friestad M.","Grice H.P.","Hayes A.F.","Alba J.W.","Johnson P.O.","Xia L.","Keller K.L.","Arndt J.","Charlett D.","Culnan M.","Magee J.C.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Hayes A.F.","Hofstede G.","Devlin J.","Liu Y.","Fishbein M.","Pritchard A.","Edell J.A.","Krippendorff K.","Oliver R.L.","Needles A.","Cortez P.","Schmitt B.","Holbrook M.B.","Culnan M.","Garfield E.","Schneider C.","Wedel M.","Blei D.M.","Gopalan P.","Guadagni PM","Lavidge R.","Pennebaker J.W.","Fornell C.","Davis F.D.","Fornell C.","Schmitt B.","Narver J.C.","Kohli A.K.","Bitner M.J.","Pennebaker J.W.","Pennebaker J.W.","Rooney J.","Rooney J.","Rooney J.","Punj G.","Witten I.H.","CERON A.","Keller K.L.","NANDAN S.","Neuendorf K.A.","Weber R.","Hui T.K.","Berelson B.","Cristianini N.","Plutchik R.","Chakraborty G.","Devlin J.","Parasuraman A.","Buttle F.","Cortez P.","Gheorghe I.R.","Brown J.J.","Heckman J.J.","Keller K.L.","Kotler P.","Sievert C.","Blei D.M.","Kohli A.K.","Morgan R.M.","Narver J.C.","Day G.S.","Day G.S.","Jaworski B.J.","Keltner D.","Asur S.","Day G.S.","Kahneman D.","Bower J.","Morgan R.M.","Pennebaker J.W.","Salton G.","Aaker D.A.","Biel A.L.","De Valck K.","Feldman R.","Griffin A.","Keller K.L.","Keller K.L.","Krippendorff K.","Rust R.T.","Spiggle S.","Chapman P.","Feldman R.","Bagozzi R.P.","Gross B.L.","Kassarjian H.H.","Kolbe R.H.","Tse D.K.","Weber R.","Box G.E.P.","De Silva I.","Eliashberg J.","Fornell C.","Holbrook M.B.","Pennebaker J.W.","Benjamini Y.","Krippendorff K.","Neuendorf K.A.","Searle J.R.","Krippendorff K.","Opoku R.","Pennebaker J.W.","Fornell C.","Greene W.H.","Hayes A.F.","Wooldridge J.","Pennebaker J.W.","Gruber M.","Pennebaker J.W.","Pennebaker J.W.","Wells W.D.","Bourdieu P.","Creswell J.W.","Greenacre M.","Kabat-Zinn J.","Zhai C.X.","Pennebaker J.W.","Donovan R.J.","Feldman R.","Holbrook M.B.","Hair J.F.","Agarwal A.","Kolbe R.H.","Krippendorff K.","Weber R.","Agarwal A.","Herr P.M.","McKenzie D.","BrightLocal","Rogers E.M.","Harris Z.S.","Lipsman A.","Rogers E.M.","Go A.","Goodfellow I.","Graves A.","Mikolov T.","Cho K","Christensen C.M.","Nelson P.","Nelson P.","Hirschman E.C.","Rogers E.M.","Opoku R.","Peladeau N.","Pennebaker J.W.","Gopalan P.","Kubler R.V.","Bass F.M.","Bielby W.","Dichter E.","Alba J.W.","Friestad M.","McLaughlin G.H.","Laurent G.","McLaughlin G.H.","Sievert C.","Banko M.","Venkatraman N.","Weber R.","Wooldridge J.","Jaworski B.J.","Kohli A.K.","Narver J.C.","Day G.S.","BrightLocal","Gretzel U.","Herr P.M.","Krippendorff K.","McCracken G.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Searle J.R.","Austin J.L.","Bourdieu P.","Bourdieu P.","Gerrig R.J.","Day G.S.","Kahneman D.","Kohli A.K.","Graves A.","Hollebeek L.","Hollebeek L.","Van Alstyne M.W.","Blei D.M.","Feldman R.","Griffin A.","Manning C.D.","Pennebaker J.W.","Aaker D.A.","Feldman R.","Keller K.L.","Keller K.L.","Krippendorff K.","NANDAN S.","Salton G.","Witten I.H.","Keller K.L.","SWALES J.M.","Witten I.H.","Green M.C.","Greene W.H.","Hayes A.F.","Krippendorff K.","Pennebaker J.W.","Chen P.-Y.","Gerrig R.J.","Blei D.M.","Lipsman A.","Mehrabian A.","Schmitt B.","Schouten J.W.","Holbrook M.B.","Pennebaker J.W.","Benoit K.","Bitner M.J.","Bitner M.J.","Brown J.J.","Zeithaml V.A.","Reynolds T.J.","Chaudhuri A.","Holbrook M.B.","Pennebaker J.W.","Spiller S.A.","Harris Z.S.","Landauer T.K.","Sundaram D.S.","Tan A.","Bishop C.M.","Feldman R.","Pritchard A.","Kohli A.K.","Leigh T.W.","McQuiston D.H.","Morgan R.M.","Grewal R.","Kubler R.V.","Mohammad S.","Netzer O.","Nielsen F.A.","Pang B.","Pennebaker J.W.","Go A.","Rehurek R.","Babin B.J.","Gretzel U.","Inversini A.","Constantinides E.","Manning C.D.","De Silva I.","Eliashberg J.","Zhai C.X.","Pennebaker J.W.","Searle J.R.","Stephen A.T.","Austin J.L.","Barinaga E.","Cox D.S.","Dolnicar S.","Manning C.D.","Silge J.","Agarwal A.","Go A.","Griffin A.","Harris Z.S.","Hauser J.R.","Tan A.","Blei D.M.","Chapman P.","Pennebaker J.W.","Liu B.","Nielsen F.A.","Parasuraman A.","Parasuraman A.","Anderson E.W.","Buttle F.","Cronin J.J.","Cronin J.J.","Nelson P.","Morgan R.M.","Richins Marsha L.","Chaudhuri A.","Thompson C.","Peladeau N.","Pennebaker J.W.","Pennebaker J.W.","Pennebaker J.W.","Petty R.","Schouten J.W.","Spiller S.A.","Grant M.","Mehl M.R.","Opoku R.","Krippendorff K.","Green M.C.","Grice H.P.","Kassarjian H.H.","Churchill G.A.","Arnold S.J.","Benjamini Y.","Box G.E.P.","Bradley M.M.","Mohammad S.M.","Liu B.","Kotler P.","Berry L.","Vazquez R.","Zeithaml V.A.","Aaker D.A.","Aaker D.A.","Keller K.L.","Keller K.L.","Fellbaum C.","Chang J.","Manning C.D.","Sievert C.","O'Connor P.","Westbrook R.A.","Bitner M.J.","Dolnicar S.","Dorre J.","Lipsman A.","Pennebaker J.W.","Richins Marsha L.","Searle J.R.","Searle J.","Austin J.L.","Feldman R.","Alba J.W.","Buitelaar P.","Feldman R.","Bass F.M.","D'Andrea A.","Feldman R.","Manning C.D.","Salton G.","Chatterjee P.","Plutchik R.","Plutchik R.","Arndt J.","Bradley M.M.","Joachims T.","Nickell S.","Searle J.R.","Searle J.","Asher N.","Austin J.L.","Krippendorff K.","O'Connor P.","Parasuraman A.","Sundaram D.S.","Buttle F.","Cronin J.J.","Gretzel U.","Herr P.M.","Grant M.","Elliott G.R.","Feldman R.","Greene W.H.","Hofstede G.","Hair J.F.","Hui T.K.","Moller K.","Wells W.D.","Herr P.M.","Mehl M.R.","Inversini A.","Keller K.L.","Cox D.S.","Hayes A.F.","Kahneman D.","Hauch V.","Arndt J.","Fellbaum C.","Witten I.H.","Biel A.L.","Day G.S.","De Valck K.","Keller K.L.","Keller K.L.","Eliashberg J.","Feldman R.","Hair J.F.","Holbrook M.B.","Kamakura W.A.","Rogers E.M.","Arndt J.","Bitner M.J.","Davis F.D.","Sundaram D.S.","Arndt J.","Bass F.M.","Belk R.W.","Charlett D.","Feick L.F.","Kassarjian H.H.","Bitner M.J.","Mojena R.","Richins M.L.","Solomon M.R.","Narver J.C.","Wooldridge J.","Jaworski B.J.","Kohli A.K.","Day G.S.","Nickell S.","Pennebaker J.W.","Clark H.H.","Mitchell A.A.","Richins M.L.","Rogers E.M.","Lafferty J.","Liu B.","Salton G.","Urban G.L.","Day G.S.","Dorre J.","Dwyer P.","Feldman R.","Fellbaum C.","Ghose A.","Asur S.","Bitner M.J.","Dwyer P.","Krippendorff K.","Salton G.","Urban G.L.","Wittink D.R.","Ghose A.","Griffin A.","Hauser J.R.","Kamakura W.A.","Liu B.","Liu B.","Donovan R.J.","Holbrook M.B.","Laurent G.","Thompson C.","Searle J.R.","Arnold S.J.","Weick K.E.","Bitner M.J.","Mojena R.","Richins M.L.","Weber R.","Berelson B.","Churchill G.A.","Eastman J.K.","Salton G.","Chakrapani C.","Orr B.H.","Chakrapani C.","Orr B.H.","Kassarjian H.H.","Kolbe R.H.","Punj G.","Tse D.K.","Weber R."]},"columns":[{"id":"scopus_id","name":"scopus_id","type":"character","minWidth":100,"maxWidth":200},{"id":"citing_art","name":"citing_art","type":"character","minWidth":100,"maxWidth":200},{"id":"title","name":"title","type":"character","minWidth":250,"maxWidth":200},{"id":"sourcetitle","name":"sourcetitle","type":"character","minWidth":100,"maxWidth":200},{"id":"year","name":"year","type":"character","minWidth":100,"maxWidth":200},{"id":"author-list.author.ce:indexed-name","name":"author-list.author.ce:indexed-name","type":"character","minWidth":100,"maxWidth":200}],"groupBy":["scopus_id"],"dataKey":"4de2df45c6c51f20c98d4eb727bd6932"},"children":[]},"class":"reactR_markup"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</section>
</section>
</section>
<section id="construct-the-dataframes" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="construct-the-dataframes"><span class="header-section-number">6</span> Construct the dataframes</h2>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_citations_df(df, start_year, end_year):</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filtrer les données en fonction de la colonne 'year'</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    df_filtered <span class="op">=</span> df[df[<span class="st">'year'</span>].between(start_year, end_year)]</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extraire les colonnes nécessaires pour le réseau de citations</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    citations_df <span class="op">=</span> df_filtered[[<span class="st">'citing_art'</span>, <span class="st">'scopus_id'</span>, <span class="st">'sourcetitle'</span>, <span class="st">'title'</span>, <span class="st">'citedby-count'</span>, <span class="st">'author-list.author.ce:indexed-name'</span>, <span class="st">'year'</span>]]</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> citations_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<!-- -->


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-plique:hal-03903518v1" class="csl-entry" role="listitem">
Plique, Guillaume. 2022. <span>“<span class="nocase">ipysigma</span>.”</span> <a href="https://doi.org/10.5281/zenodo.7446059">https://doi.org/10.5281/zenodo.7446059</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb40" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Systematic literature review"</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> references.bib</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner:</span><span class="co"> true</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "A focus on authors, articles, references with networks"</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Olivier Caron</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="co">    email: olivier.caron@dauphine.psl.eu</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations: </span></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co">      name: "Paris Dauphine - PSL"</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co">      city: Paris</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co">      state: France</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Christophe Benavent</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co">    email: christophe.benavent@dauphine.psl.eu</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliations: </span></span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="co">      name: "Paris Dauphine - PSL"</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co">      city: Paris</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="co">      state: France</span></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a><span class="an">date :</span><span class="co"> "last-modified"</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a><span class="an">toc:</span><span class="co"> true</span></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="an">number-sections:</span><span class="co"> true</span></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="an">number-depth:</span><span class="co"> 10</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a><span class="co">    theme:</span></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a><span class="co">      light: yeti</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a><span class="co">      #dark: darkly</span></span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a><span class="co">    code-summary: "Display code"</span></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true #enables to display/hide all blocks of code</span></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a><span class="co">    code-copy: true #enables to copy code</span></span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a><span class="co">    grid:</span></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a><span class="co">      body-width: 1000px</span></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a><span class="co">      margin-width: 100px</span></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-location: left</span></span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a><span class="an">execute:</span></span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a><span class="co">  echo: true</span></span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a><span class="co">  warning: false</span></span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a><span class="co">  message: false</span></span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> visual</span></span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a><span class="an">fig-align:</span><span class="co"> "center"</span></span>
<span id="cb40-43"><a href="#cb40-43" aria-hidden="true" tabindex="-1"></a><span class="an">highlight-style:</span><span class="co"> ayu</span></span>
<span id="cb40-44"><a href="#cb40-44" aria-hidden="true" tabindex="-1"></a><span class="an">css:</span><span class="co"> styles.css</span></span>
<span id="cb40-45"><a href="#cb40-45" aria-hidden="true" tabindex="-1"></a><span class="an">reference-location:</span><span class="co"> margin</span></span>
<span id="cb40-46"><a href="#cb40-46" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb40-47"><a href="#cb40-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-48"><a href="#cb40-48" aria-hidden="true" tabindex="-1"></a><span class="fu">## Purpose</span></span>
<span id="cb40-49"><a href="#cb40-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-52"><a href="#cb40-52" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-53"><a href="#cb40-53" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: introduction</span></span>
<span id="cb40-54"><a href="#cb40-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-55"><a href="#cb40-55" aria-hidden="true" tabindex="-1"></a>cowsay<span class="sc">::</span><span class="fu">say</span>(<span class="st">"After researching the articles and references by making graphs to</span></span>
<span id="cb40-56"><a href="#cb40-56" aria-hidden="true" tabindex="-1"></a><span class="st">better visualize the structure of the research. We want to focus</span></span>
<span id="cb40-57"><a href="#cb40-57" aria-hidden="true" tabindex="-1"></a><span class="st">here on the authors, trying to understand how communities evolve over time."</span>)</span>
<span id="cb40-58"><a href="#cb40-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-59"><a href="#cb40-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-60"><a href="#cb40-60" aria-hidden="true" tabindex="-1"></a><span class="fu">## Libraries and preparing data</span></span>
<span id="cb40-61"><a href="#cb40-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-64"><a href="#cb40-64" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-65"><a href="#cb40-65" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-libraries-python</span></span>
<span id="cb40-66"><a href="#cb40-66" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb40-67"><a href="#cb40-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-68"><a href="#cb40-68" aria-hidden="true" tabindex="-1"></a><span class="co">#Libraries</span></span>
<span id="cb40-69"><a href="#cb40-69" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb40-70"><a href="#cb40-70" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb40-71"><a href="#cb40-71" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb40-72"><a href="#cb40-72" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb40-73"><a href="#cb40-73" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb40-74"><a href="#cb40-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-75"><a href="#cb40-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-76"><a href="#cb40-76" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ipysigma <span class="im">import</span> Sigma</span>
<span id="cb40-77"><a href="#cb40-77" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> combinations</span>
<span id="cb40-78"><a href="#cb40-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-79"><a href="#cb40-79" aria-hidden="true" tabindex="-1"></a><span class="co">#Data</span></span>
<span id="cb40-80"><a href="#cb40-80" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">"data_final.csv"</span>)</span>
<span id="cb40-81"><a href="#cb40-81" aria-hidden="true" tabindex="-1"></a>list_articles <span class="op">=</span> pd.read_csv(<span class="st">"nlp_full_data_final_18-08-2023.csv"</span>, sep<span class="op">=</span><span class="st">';'</span>, decimal<span class="op">=</span><span class="st">','</span>)</span>
<span id="cb40-82"><a href="#cb40-82" aria-hidden="true" tabindex="-1"></a>list_articles <span class="op">=</span> list_articles[list_articles[<span class="st">'marketing'</span>] <span class="op">==</span> <span class="dv">1</span>] <span class="co">#only marketing articles</span></span>
<span id="cb40-83"><a href="#cb40-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-84"><a href="#cb40-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge the "topic" and "topic_name" columns from the "data" dataframe into "list_articles"</span></span>
<span id="cb40-85"><a href="#cb40-85" aria-hidden="true" tabindex="-1"></a>list_articles <span class="op">=</span> list_articles.merge(data[[<span class="st">'entry_number'</span>, <span class="st">'topic'</span>, <span class="st">'topic_name'</span>]], on<span class="op">=</span><span class="st">'entry_number'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb40-86"><a href="#cb40-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-87"><a href="#cb40-87" aria-hidden="true" tabindex="-1"></a>list_references <span class="op">=</span> pd.read_csv(<span class="st">"nlp_references_final_18-08-2023.csv"</span>, sep<span class="op">=</span><span class="st">';'</span>, decimal<span class="op">=</span><span class="st">','</span>)</span>
<span id="cb40-88"><a href="#cb40-88" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-89"><a href="#cb40-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-90"><a href="#cb40-90" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary of the authors data</span></span>
<span id="cb40-91"><a href="#cb40-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-94"><a href="#cb40-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-95"><a href="#cb40-95" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: summary-authors-data</span></span>
<span id="cb40-96"><a href="#cb40-96" aria-hidden="true" tabindex="-1"></a><span class="co">#| column: screen-inset-right</span></span>
<span id="cb40-97"><a href="#cb40-97" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: fenced</span></span>
<span id="cb40-98"><a href="#cb40-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-99"><a href="#cb40-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-100"><a href="#cb40-100" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb40-101"><a href="#cb40-101" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reactable)</span>
<span id="cb40-102"><a href="#cb40-102" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb40-103"><a href="#cb40-103" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(skimr)</span>
<span id="cb40-104"><a href="#cb40-104" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plotly)</span>
<span id="cb40-105"><a href="#cb40-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-106"><a href="#cb40-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-107"><a href="#cb40-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-108"><a href="#cb40-108" aria-hidden="true" tabindex="-1"></a>list_articles <span class="ot">&lt;-</span> <span class="fu">read_csv2</span>(<span class="st">"nlp_full_data_final_18-08-2023.csv"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-109"><a href="#cb40-109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">marketing =</span> <span class="fu">as.logical</span>(marketing)) <span class="sc">%&gt;%</span></span>
<span id="cb40-110"><a href="#cb40-110" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">authid =</span> <span class="fu">as.character</span>(authid)) <span class="sc">%&gt;%</span></span>
<span id="cb40-111"><a href="#cb40-111" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">afid =</span> <span class="fu">as.character</span>(afid)) <span class="sc">%&gt;%</span></span>
<span id="cb40-112"><a href="#cb40-112" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">entry_number =</span> <span class="fu">as.character</span>(entry_number)) <span class="sc">%&gt;%</span></span>
<span id="cb40-113"><a href="#cb40-113" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">source_id =</span> <span class="fu">as.character</span>(source_id)) <span class="sc">%&gt;%</span></span>
<span id="cb40-114"><a href="#cb40-114" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">article_number =</span> <span class="fu">as.character</span>(article_number)) <span class="sc">%&gt;%</span></span>
<span id="cb40-115"><a href="#cb40-115" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">openaccess =</span> <span class="fu">as.logical</span>(openaccess))</span>
<span id="cb40-116"><a href="#cb40-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-117"><a href="#cb40-117" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(list_articles) <span class="co">#%&gt;%</span></span>
<span id="cb40-118"><a href="#cb40-118" aria-hidden="true" tabindex="-1"></a>  <span class="co">#filter(!skim_type %in% c("logical"))</span></span>
<span id="cb40-119"><a href="#cb40-119" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-120"><a href="#cb40-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-121"><a href="#cb40-121" aria-hidden="true" tabindex="-1"></a><span class="fu">### Check name of authors</span></span>
<span id="cb40-122"><a href="#cb40-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-123"><a href="#cb40-123" aria-hidden="true" tabindex="-1"></a>We need to check if there are more than one unique <span class="in">`authorname`</span> per <span class="in">`authid`</span>. If so, we need to change the different names of author to the same name in order to have the exact same node per author later in the network.</span>
<span id="cb40-124"><a href="#cb40-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-127"><a href="#cb40-127" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-128"><a href="#cb40-128" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: load-libraries-r</span></span>
<span id="cb40-129"><a href="#cb40-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-130"><a href="#cb40-130" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span></span>
<span id="cb40-131"><a href="#cb40-131" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb40-132"><a href="#cb40-132" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(authid, authname, entry_number) <span class="sc">%&gt;%</span></span>
<span id="cb40-133"><a href="#cb40-133" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n =</span> <span class="fu">n</span>())</span>
<span id="cb40-134"><a href="#cb40-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-135"><a href="#cb40-135" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> test <span class="sc">%&gt;%</span></span>
<span id="cb40-136"><a href="#cb40-136" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb40-137"><a href="#cb40-137" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">n_distinct</span>(authname) <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-138"><a href="#cb40-138" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(authid, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>)</span>
<span id="cb40-139"><a href="#cb40-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-140"><a href="#cb40-140" aria-hidden="true" tabindex="-1"></a>result <span class="sc">%&gt;%</span> <span class="fu">reactable</span>()</span>
<span id="cb40-141"><a href="#cb40-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-142"><a href="#cb40-142" aria-hidden="true" tabindex="-1"></a>number_duplicates <span class="ot">&lt;-</span> <span class="fu">nrow</span>(result)</span>
<span id="cb40-143"><a href="#cb40-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-144"><a href="#cb40-144" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"There are "</span>, number_duplicates, <span class="st">" authors registered with different names."</span>)</span>
<span id="cb40-145"><a href="#cb40-145" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-146"><a href="#cb40-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-147"><a href="#cb40-147" aria-hidden="true" tabindex="-1"></a><span class="fu">### Correct the duplicate names</span></span>
<span id="cb40-148"><a href="#cb40-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-149"><a href="#cb40-149" aria-hidden="true" tabindex="-1"></a>Let's correct that by using one property of the distinct function: the <span class="in">`.keep_all = TRUE`</span> parameter. It keeps the first occurrence of each group, which is the first row encountered for each unique combination of <span class="in">`authid`</span> and <span class="in">`authname`</span>. It will be faster than manually changing the name of each author.</span>
<span id="cb40-150"><a href="#cb40-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-153"><a href="#cb40-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-154"><a href="#cb40-154" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: change-data-authors</span></span>
<span id="cb40-155"><a href="#cb40-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-156"><a href="#cb40-156" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge list_articles with result on the authid column</span></span>
<span id="cb40-157"><a href="#cb40-157" aria-hidden="true" tabindex="-1"></a>merged_df <span class="ot">&lt;-</span> <span class="fu">left_join</span>(list_articles, result, <span class="at">by =</span> <span class="st">"authid"</span>)</span>
<span id="cb40-158"><a href="#cb40-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-159"><a href="#cb40-159" aria-hidden="true" tabindex="-1"></a><span class="co"># Replace authname values in list_articles with those from result</span></span>
<span id="cb40-160"><a href="#cb40-160" aria-hidden="true" tabindex="-1"></a>list_articles<span class="sc">$</span>authname <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(<span class="sc">!</span><span class="fu">is.na</span>(merged_df<span class="sc">$</span>authname.y), merged_df<span class="sc">$</span>authname.y, list_articles<span class="sc">$</span>authname)</span>
<span id="cb40-161"><a href="#cb40-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-162"><a href="#cb40-162" aria-hidden="true" tabindex="-1"></a><span class="co"># Keep only marketing articles and filter "Erratum" type of publications (=correction)</span></span>
<span id="cb40-163"><a href="#cb40-163" aria-hidden="true" tabindex="-1"></a>list_articles <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span> </span>
<span id="cb40-164"><a href="#cb40-164" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(marketing <span class="sc">==</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-165"><a href="#cb40-165" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(subtypeDescription <span class="sc">!=</span> <span class="st">"Erratum"</span>)</span>
<span id="cb40-166"><a href="#cb40-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-167"><a href="#cb40-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-168"><a href="#cb40-168" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"There are"</span>, <span class="fu">n_distinct</span>(list_articles<span class="sc">$</span>entry_number), <span class="st">"articles and"</span>, <span class="fu">n_distinct</span>(list_articles<span class="sc">$</span>authname), <span class="st">"authors overall in the data."</span>)</span>
<span id="cb40-169"><a href="#cb40-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-170"><a href="#cb40-170" aria-hidden="true" tabindex="-1"></a><span class="co"># Write the updated dataframe to a CSV file </span></span>
<span id="cb40-171"><a href="#cb40-171" aria-hidden="true" tabindex="-1"></a><span class="fu">write_csv2</span>(list_articles, <span class="st">"nlp_full_data_final_unique_author_names.csv"</span>)</span>
<span id="cb40-172"><a href="#cb40-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-173"><a href="#cb40-173" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-174"><a href="#cb40-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-175"><a href="#cb40-175" aria-hidden="true" tabindex="-1"></a>It is now done. We can check again if there are more than one unique <span class="in">`authorname`</span> per <span class="in">`authid`</span>.</span>
<span id="cb40-176"><a href="#cb40-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-177"><a href="#cb40-177" aria-hidden="true" tabindex="-1"></a><span class="fu">### Verification of duplicate names</span></span>
<span id="cb40-178"><a href="#cb40-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-181"><a href="#cb40-181" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-182"><a href="#cb40-182" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: check-unique-name-authors</span></span>
<span id="cb40-183"><a href="#cb40-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-184"><a href="#cb40-184" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> list_articles <span class="sc">%&gt;%</span></span>
<span id="cb40-185"><a href="#cb40-185" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb40-186"><a href="#cb40-186" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(authid, authname, entry_number) <span class="sc">%&gt;%</span></span>
<span id="cb40-187"><a href="#cb40-187" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">n =</span> <span class="fu">n</span>())</span>
<span id="cb40-188"><a href="#cb40-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-189"><a href="#cb40-189" aria-hidden="true" tabindex="-1"></a>result <span class="ot">&lt;-</span> test <span class="sc">%&gt;%</span></span>
<span id="cb40-190"><a href="#cb40-190" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(authid) <span class="sc">%&gt;%</span></span>
<span id="cb40-191"><a href="#cb40-191" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">n_distinct</span>(authname) <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-192"><a href="#cb40-192" aria-hidden="true" tabindex="-1"></a>  <span class="fu">distinct</span>(authid, <span class="at">.keep_all =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-193"><a href="#cb40-193" aria-hidden="true" tabindex="-1"></a>  <span class="fu">relocate</span>(entry_number)</span>
<span id="cb40-194"><a href="#cb40-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-195"><a href="#cb40-195" aria-hidden="true" tabindex="-1"></a>result <span class="sc">%&gt;%</span> <span class="fu">reactable</span>()</span>
<span id="cb40-196"><a href="#cb40-196" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-197"><a href="#cb40-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-198"><a href="#cb40-198" aria-hidden="true" tabindex="-1"></a>It's alright, we can now continue on constructing the data frames for the networks.</span>
<span id="cb40-199"><a href="#cb40-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-200"><a href="#cb40-200" aria-hidden="true" tabindex="-1"></a><span class="fu">## Construct the dataframes for the networks</span></span>
<span id="cb40-201"><a href="#cb40-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-202"><a href="#cb40-202" aria-hidden="true" tabindex="-1"></a><span class="fu">### Create the dataframes of collaboration between authors (one per period)</span></span>
<span id="cb40-203"><a href="#cb40-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-206"><a href="#cb40-206" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-207"><a href="#cb40-207" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-authors</span></span>
<span id="cb40-208"><a href="#cb40-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-209"><a href="#cb40-209" aria-hidden="true" tabindex="-1"></a>list_articles <span class="op">=</span>  pd.read_csv(<span class="st">"nlp_full_data_final_unique_author_names.csv"</span>, sep<span class="op">=</span><span class="st">';'</span>, decimal<span class="op">=</span><span class="st">','</span>)</span>
<span id="cb40-210"><a href="#cb40-210" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the year ranges</span></span>
<span id="cb40-211"><a href="#cb40-211" aria-hidden="true" tabindex="-1"></a>year_ranges <span class="op">=</span> [(<span class="va">None</span>, <span class="dv">2013</span>), (<span class="dv">2013</span>, <span class="dv">2017</span>), (<span class="dv">2018</span>, <span class="dv">2021</span>), (<span class="dv">2022</span>, <span class="dv">2023</span>)]</span>
<span id="cb40-212"><a href="#cb40-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-213"><a href="#cb40-213" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize a list to store the results for each year period</span></span>
<span id="cb40-214"><a href="#cb40-214" aria-hidden="true" tabindex="-1"></a>result_dfs <span class="op">=</span> []</span>
<span id="cb40-215"><a href="#cb40-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-216"><a href="#cb40-216" aria-hidden="true" tabindex="-1"></a><span class="co"># Iterate through the year ranges</span></span>
<span id="cb40-217"><a href="#cb40-217" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> start_year, end_year <span class="kw">in</span> year_ranges:</span>
<span id="cb40-218"><a href="#cb40-218" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> start_year <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb40-219"><a href="#cb40-219" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filter articles before 2013</span></span>
<span id="cb40-220"><a href="#cb40-220" aria-hidden="true" tabindex="-1"></a>        filtered_articles <span class="op">=</span> list_articles[list_articles[<span class="st">'year'</span>] <span class="op">&lt;</span> end_year]</span>
<span id="cb40-221"><a href="#cb40-221" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb40-222"><a href="#cb40-222" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Filter articles within the specified year range</span></span>
<span id="cb40-223"><a href="#cb40-223" aria-hidden="true" tabindex="-1"></a>        filtered_articles <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> start_year) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> end_year)]</span>
<span id="cb40-224"><a href="#cb40-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-225"><a href="#cb40-225" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a list to store author pairs and their details for the current year period</span></span>
<span id="cb40-226"><a href="#cb40-226" aria-hidden="true" tabindex="-1"></a>    author_pairs <span class="op">=</span> []</span>
<span id="cb40-227"><a href="#cb40-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-228"><a href="#cb40-228" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Group the filtered dataframe by article number and collect unique author IDs for each article</span></span>
<span id="cb40-229"><a href="#cb40-229" aria-hidden="true" tabindex="-1"></a>    grouped <span class="op">=</span> filtered_articles.groupby(<span class="st">'entry_number'</span>)[[<span class="st">'authid'</span>, <span class="st">'authname'</span>]].agg(<span class="bu">list</span>).reset_index()</span>
<span id="cb40-230"><a href="#cb40-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-231"><a href="#cb40-231" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through the grouped dataframe and find author pairs for each article</span></span>
<span id="cb40-232"><a href="#cb40-232" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> _, row <span class="kw">in</span> grouped.iterrows():</span>
<span id="cb40-233"><a href="#cb40-233" aria-hidden="true" tabindex="-1"></a>        entry_number <span class="op">=</span> row[<span class="st">'entry_number'</span>]</span>
<span id="cb40-234"><a href="#cb40-234" aria-hidden="true" tabindex="-1"></a>        authors <span class="op">=</span> row[<span class="st">'authid'</span>]</span>
<span id="cb40-235"><a href="#cb40-235" aria-hidden="true" tabindex="-1"></a>        authnames <span class="op">=</span> row[<span class="st">'authname'</span>]</span>
<span id="cb40-236"><a href="#cb40-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-237"><a href="#cb40-237" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(authors) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb40-238"><a href="#cb40-238" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Handle single authors by creating a self-relation</span></span>
<span id="cb40-239"><a href="#cb40-239" aria-hidden="true" tabindex="-1"></a>            author_pairs.append((entry_number, authors[<span class="dv">0</span>], authors[<span class="dv">0</span>], authnames[<span class="dv">0</span>], authnames[<span class="dv">0</span>]))</span>
<span id="cb40-240"><a href="#cb40-240" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="bu">len</span>(authors) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb40-241"><a href="#cb40-241" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Create pairs of authors who have co-authored the article</span></span>
<span id="cb40-242"><a href="#cb40-242" aria-hidden="true" tabindex="-1"></a>            author_combinations <span class="op">=</span> <span class="bu">list</span>(combinations(<span class="bu">range</span>(<span class="bu">len</span>(authors)), <span class="dv">2</span>))</span>
<span id="cb40-243"><a href="#cb40-243" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, j <span class="kw">in</span> author_combinations:</span>
<span id="cb40-244"><a href="#cb40-244" aria-hidden="true" tabindex="-1"></a>                author_pairs.append((entry_number, authors[i], authors[j], authnames[i], authnames[j]))</span>
<span id="cb40-245"><a href="#cb40-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-246"><a href="#cb40-246" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the DataFrame with the additional 'entry_number' column for the current year period</span></span>
<span id="cb40-247"><a href="#cb40-247" aria-hidden="true" tabindex="-1"></a>    result_df <span class="op">=</span> pd.DataFrame(author_pairs, columns<span class="op">=</span>[<span class="st">'entry_number'</span>, <span class="st">'authid1'</span>, <span class="st">'authid2'</span>, <span class="st">'authname1'</span>, <span class="st">'authname2'</span>])</span>
<span id="cb40-248"><a href="#cb40-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-249"><a href="#cb40-249" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Append the result DataFrame to the list of results</span></span>
<span id="cb40-250"><a href="#cb40-250" aria-hidden="true" tabindex="-1"></a>    result_dfs.append(result_df)</span>
<span id="cb40-251"><a href="#cb40-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-252"><a href="#cb40-252" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, result_dfs contains DataFrames for each year period</span></span>
<span id="cb40-253"><a href="#cb40-253" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[0] corresponds to articles before 2013</span></span>
<span id="cb40-254"><a href="#cb40-254" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[1] corresponds to articles from 2013 to 2017</span></span>
<span id="cb40-255"><a href="#cb40-255" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[2] corresponds to articles from 2018 to 2021</span></span>
<span id="cb40-256"><a href="#cb40-256" aria-hidden="true" tabindex="-1"></a><span class="co"># result_dfs[3] corresponds to articles from 2022 to 2023</span></span>
<span id="cb40-257"><a href="#cb40-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-258"><a href="#cb40-258" aria-hidden="true" tabindex="-1"></a>authors_before_2013 <span class="op">=</span> result_dfs[<span class="dv">0</span>]</span>
<span id="cb40-259"><a href="#cb40-259" aria-hidden="true" tabindex="-1"></a>authors_2013_2017 <span class="op">=</span> result_dfs[<span class="dv">1</span>]</span>
<span id="cb40-260"><a href="#cb40-260" aria-hidden="true" tabindex="-1"></a>authors_2018_2021 <span class="op">=</span> result_dfs[<span class="dv">2</span>]</span>
<span id="cb40-261"><a href="#cb40-261" aria-hidden="true" tabindex="-1"></a>authors_2022_2023 <span class="op">=</span> result_dfs[<span class="dv">3</span>]</span>
<span id="cb40-262"><a href="#cb40-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-263"><a href="#cb40-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-264"><a href="#cb40-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-265"><a href="#cb40-265" aria-hidden="true" tabindex="-1"></a><span class="fu">### Sort cases with a-\&gt;b and b-\&gt;a and create weighted edges</span></span>
<span id="cb40-266"><a href="#cb40-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-269"><a href="#cb40-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-270"><a href="#cb40-270" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: function-calculate-edge-weights</span></span>
<span id="cb40-271"><a href="#cb40-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-272"><a href="#cb40-272" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort the cases with a-&gt;b and b-&gt;a and sum them up =&gt; it creates weighted edges</span></span>
<span id="cb40-273"><a href="#cb40-273" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_collaboration_df(df):</span>
<span id="cb40-274"><a href="#cb40-274" aria-hidden="true" tabindex="-1"></a>    collaboration_df <span class="op">=</span> df[[<span class="st">"authname1"</span>,<span class="st">"authname2"</span>]]</span>
<span id="cb40-275"><a href="#cb40-275" aria-hidden="true" tabindex="-1"></a>    collaboration_df <span class="op">=</span> pd.DataFrame(np.sort(collaboration_df.values, axis<span class="op">=</span><span class="dv">1</span>), columns<span class="op">=</span>collaboration_df.columns)</span>
<span id="cb40-276"><a href="#cb40-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-277"><a href="#cb40-277" aria-hidden="true" tabindex="-1"></a>    collaboration_df[<span class="st">'value'</span>] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb40-278"><a href="#cb40-278" aria-hidden="true" tabindex="-1"></a>    collaboration_df <span class="op">=</span> collaboration_df.groupby([<span class="st">"authname1"</span>,<span class="st">"authname2"</span>], sort<span class="op">=</span><span class="va">False</span>, as_index<span class="op">=</span><span class="va">False</span>).<span class="bu">sum</span>()</span>
<span id="cb40-279"><a href="#cb40-279" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> collaboration_df</span>
<span id="cb40-280"><a href="#cb40-280" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb40-281"><a href="#cb40-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-282"><a href="#cb40-282" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function to DataFrames</span></span>
<span id="cb40-283"><a href="#cb40-283" aria-hidden="true" tabindex="-1"></a>network_data_2022_2023 <span class="op">=</span> get_collaboration_df(authors_2022_2023)</span>
<span id="cb40-284"><a href="#cb40-284" aria-hidden="true" tabindex="-1"></a>network_data_2022_2023.to_csv(<span class="st">"networks/csv/network_data_2022_2023.csv"</span>)</span>
<span id="cb40-285"><a href="#cb40-285" aria-hidden="true" tabindex="-1"></a>network_data_2018_2021 <span class="op">=</span> get_collaboration_df(authors_2018_2021)</span>
<span id="cb40-286"><a href="#cb40-286" aria-hidden="true" tabindex="-1"></a>network_data_2018_2021.to_csv(<span class="st">"networks/csv/network_data_2018_2021.csv"</span>)</span>
<span id="cb40-287"><a href="#cb40-287" aria-hidden="true" tabindex="-1"></a>network_data_2013_2017 <span class="op">=</span> get_collaboration_df(authors_2013_2017)</span>
<span id="cb40-288"><a href="#cb40-288" aria-hidden="true" tabindex="-1"></a>network_data_2013_2017.to_csv(<span class="st">"networks/csv/network_data_2013_2017.csv"</span>)</span>
<span id="cb40-289"><a href="#cb40-289" aria-hidden="true" tabindex="-1"></a>network_data_before_2013 <span class="op">=</span> get_collaboration_df(authors_before_2013)</span>
<span id="cb40-290"><a href="#cb40-290" aria-hidden="true" tabindex="-1"></a>network_data_before_2013.to_csv(<span class="st">"networks/csv/network_data_before_2013.csv"</span>)</span>
<span id="cb40-291"><a href="#cb40-291" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-292"><a href="#cb40-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-293"><a href="#cb40-293" aria-hidden="true" tabindex="-1"></a><span class="fu">### Get information about authors</span></span>
<span id="cb40-294"><a href="#cb40-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-297"><a href="#cb40-297" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-298"><a href="#cb40-298" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: get_author_info_by_period</span></span>
<span id="cb40-299"><a href="#cb40-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-300"><a href="#cb40-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-301"><a href="#cb40-301" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sort_dict(<span class="bu">dict</span>):</span>
<span id="cb40-302"><a href="#cb40-302" aria-hidden="true" tabindex="-1"></a>    sorted_dict <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> <span class="bu">sorted</span>(<span class="bu">dict</span>.items(), key<span class="op">=</span><span class="kw">lambda</span> item: item[<span class="dv">0</span>])}</span>
<span id="cb40-303"><a href="#cb40-303" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sorted_dict</span>
<span id="cb40-304"><a href="#cb40-304" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb40-305"><a href="#cb40-305" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_author_info_by_period(list_articles, period):</span>
<span id="cb40-306"><a href="#cb40-306" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter the DataFrame based on the specified period</span></span>
<span id="cb40-307"><a href="#cb40-307" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> period <span class="op">==</span> <span class="st">"before-2013"</span>:</span>
<span id="cb40-308"><a href="#cb40-308" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[list_articles[<span class="st">'year'</span>] <span class="op">&lt;</span> <span class="dv">2013</span>]</span>
<span id="cb40-309"><a href="#cb40-309" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> period <span class="op">==</span> <span class="st">"2013-2017"</span>:</span>
<span id="cb40-310"><a href="#cb40-310" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> <span class="dv">2013</span>) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> <span class="dv">2017</span>)]</span>
<span id="cb40-311"><a href="#cb40-311" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> period <span class="op">==</span> <span class="st">"2018-2021"</span>:</span>
<span id="cb40-312"><a href="#cb40-312" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> <span class="dv">2018</span>) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> <span class="dv">2021</span>)]</span>
<span id="cb40-313"><a href="#cb40-313" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> period <span class="op">==</span> <span class="st">"2022-2023"</span>:</span>
<span id="cb40-314"><a href="#cb40-314" aria-hidden="true" tabindex="-1"></a>        filtered_df <span class="op">=</span> list_articles[(list_articles[<span class="st">'year'</span>] <span class="op">&gt;=</span> <span class="dv">2022</span>) <span class="op">&amp;</span> (list_articles[<span class="st">'year'</span>] <span class="op">&lt;=</span> <span class="dv">2023</span>)]</span>
<span id="cb40-315"><a href="#cb40-315" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb40-316"><a href="#cb40-316" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Invalid period parameter. Please choose one of: 'before-2013', '2013-2017', '2018-2021', '2022-2023"</span>)</span>
<span id="cb40-317"><a href="#cb40-317" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-318"><a href="#cb40-318" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dictionary to store affiliations and countries for each author</span></span>
<span id="cb40-319"><a href="#cb40-319" aria-hidden="true" tabindex="-1"></a>    info_author <span class="op">=</span> {<span class="st">'affiliation'</span>: {}, <span class="st">'country'</span>: {}, <span class="st">'article'</span>: {}, <span class="st">'journal'</span>: {}}</span>
<span id="cb40-320"><a href="#cb40-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-321"><a href="#cb40-321" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Iterate through the filtered DataFrame to collect affiliations and countries for each author</span></span>
<span id="cb40-322"><a href="#cb40-322" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> index, row <span class="kw">in</span> filtered_df.iterrows():</span>
<span id="cb40-323"><a href="#cb40-323" aria-hidden="true" tabindex="-1"></a>        author_name <span class="op">=</span> row[<span class="st">'authname'</span>]</span>
<span id="cb40-324"><a href="#cb40-324" aria-hidden="true" tabindex="-1"></a>        affiliation <span class="op">=</span> row[<span class="st">'affilname'</span>]</span>
<span id="cb40-325"><a href="#cb40-325" aria-hidden="true" tabindex="-1"></a>        country <span class="op">=</span> row[<span class="st">'affiliation_country'</span>]</span>
<span id="cb40-326"><a href="#cb40-326" aria-hidden="true" tabindex="-1"></a>        article <span class="op">=</span> row[<span class="st">'dc:title'</span>]</span>
<span id="cb40-327"><a href="#cb40-327" aria-hidden="true" tabindex="-1"></a>        journal <span class="op">=</span> row[<span class="st">'prism:publicationName'</span>]</span>
<span id="cb40-328"><a href="#cb40-328" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-329"><a href="#cb40-329" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the affiliation is not NaN (i.e., a valid affiliation)</span></span>
<span id="cb40-330"><a href="#cb40-330" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(affiliation, <span class="bu">str</span>) <span class="kw">and</span> affiliation.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb40-331"><a href="#cb40-331" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if the author already has an affiliation, and if the new one is not already included, then add it with "&amp;"</span></span>
<span id="cb40-332"><a href="#cb40-332" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'affiliation'</span>]:</span>
<span id="cb40-333"><a href="#cb40-333" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> affiliation <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'affiliation'</span>][author_name]:</span>
<span id="cb40-334"><a href="#cb40-334" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'affiliation'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> affiliation</span>
<span id="cb40-335"><a href="#cb40-335" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb40-336"><a href="#cb40-336" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'affiliation'</span>][author_name] <span class="op">=</span> affiliation</span>
<span id="cb40-337"><a href="#cb40-337" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-338"><a href="#cb40-338" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the country is not NaN (i.e., a valid country)</span></span>
<span id="cb40-339"><a href="#cb40-339" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(country, <span class="bu">str</span>) <span class="kw">and</span> country.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb40-340"><a href="#cb40-340" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if the author already has a country, and if the new one is not already included, then add it with "&amp;"</span></span>
<span id="cb40-341"><a href="#cb40-341" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'country'</span>]:</span>
<span id="cb40-342"><a href="#cb40-342" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> country <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'country'</span>][author_name]:</span>
<span id="cb40-343"><a href="#cb40-343" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'country'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> country</span>
<span id="cb40-344"><a href="#cb40-344" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb40-345"><a href="#cb40-345" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'country'</span>][author_name] <span class="op">=</span> country</span>
<span id="cb40-346"><a href="#cb40-346" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb40-347"><a href="#cb40-347" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the article title is not NaN (i.e., a valid article title)</span></span>
<span id="cb40-348"><a href="#cb40-348" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(article, <span class="bu">str</span>) <span class="kw">and</span> article.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb40-349"><a href="#cb40-349" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if an author has multiple articles, if so add the new article with "&amp;"</span></span>
<span id="cb40-350"><a href="#cb40-350" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'article'</span>]:</span>
<span id="cb40-351"><a href="#cb40-351" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> article <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'article'</span>][author_name]:</span>
<span id="cb40-352"><a href="#cb40-352" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'article'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> article</span>
<span id="cb40-353"><a href="#cb40-353" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb40-354"><a href="#cb40-354" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'article'</span>][author_name] <span class="op">=</span> article</span>
<span id="cb40-355"><a href="#cb40-355" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb40-356"><a href="#cb40-356" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if the journal name (or conference name) is not NaN (i.e., a valid journal)</span></span>
<span id="cb40-357"><a href="#cb40-357" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(journal, <span class="bu">str</span>) <span class="kw">and</span> journal.strip() <span class="op">!=</span> <span class="st">""</span>:</span>
<span id="cb40-358"><a href="#cb40-358" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if the author has published in multiple journals, if so add the new journal with "&amp;"</span></span>
<span id="cb40-359"><a href="#cb40-359" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> author_name <span class="kw">in</span> info_author[<span class="st">'journal'</span>]:</span>
<span id="cb40-360"><a href="#cb40-360" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> journal <span class="kw">not</span> <span class="kw">in</span> info_author[<span class="st">'journal'</span>][author_name]:</span>
<span id="cb40-361"><a href="#cb40-361" aria-hidden="true" tabindex="-1"></a>                    info_author[<span class="st">'journal'</span>][author_name] <span class="op">+=</span> <span class="st">" | "</span> <span class="op">+</span> journal</span>
<span id="cb40-362"><a href="#cb40-362" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb40-363"><a href="#cb40-363" aria-hidden="true" tabindex="-1"></a>                info_author[<span class="st">'journal'</span>][author_name] <span class="op">=</span> journal</span>
<span id="cb40-364"><a href="#cb40-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-365"><a href="#cb40-365" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a dictionary that associates each author with their ln(total number of citations+1)+1</span></span>
<span id="cb40-366"><a href="#cb40-366" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We do +1 twice because if the result is 0, then the log is undefined.</span></span>
<span id="cb40-367"><a href="#cb40-367" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We add another +1 to avoid having 0 values in the network.</span></span>
<span id="cb40-368"><a href="#cb40-368" aria-hidden="true" tabindex="-1"></a>    citedby_dict <span class="op">=</span> filtered_df.groupby(<span class="st">'authname'</span>)[<span class="st">'citedby_count'</span>].<span class="bu">sum</span>() .to_dict()</span>
<span id="cb40-369"><a href="#cb40-369" aria-hidden="true" tabindex="-1"></a>    <span class="co">#citedby_dict = filtered_df.groupby('authname')['citedby_count'].sum().apply(lambda x: np.log(x + 1) + 1).to_dict()</span></span>
<span id="cb40-370"><a href="#cb40-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-371"><a href="#cb40-371" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add the 'citedby_count' dictionary to the 'info_author' dictionary under the key 'citations'</span></span>
<span id="cb40-372"><a href="#cb40-372" aria-hidden="true" tabindex="-1"></a>    info_author[<span class="st">'citations'</span>] <span class="op">=</span> citedby_dict</span>
<span id="cb40-373"><a href="#cb40-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-374"><a href="#cb40-374" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the info_author dictionary containing both affiliation, country, and citations information</span></span>
<span id="cb40-375"><a href="#cb40-375" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> info_author</span>
<span id="cb40-376"><a href="#cb40-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-377"><a href="#cb40-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-378"><a href="#cb40-378" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb40-379"><a href="#cb40-379" aria-hidden="true" tabindex="-1"></a><span class="co"># How to use:</span></span>
<span id="cb40-380"><a href="#cb40-380" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the period of interest: ("before-2013", "2013-2017", "2018-2021", or "2022-2023")</span></span>
<span id="cb40-381"><a href="#cb40-381" aria-hidden="true" tabindex="-1"></a><span class="co"># The function returns a dictionary with four keys: 'affiliation', 'country', 'article', 'journal', and 'citations'</span></span>
<span id="cb40-382"><a href="#cb40-382" aria-hidden="true" tabindex="-1"></a><span class="co"># The dictionaries are then used as attributes for the nodes in the network (see below)</span></span>
<span id="cb40-383"><a href="#cb40-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-384"><a href="#cb40-384" aria-hidden="true" tabindex="-1"></a>affilauthor_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb40-385"><a href="#cb40-385" aria-hidden="true" tabindex="-1"></a>affilauthor_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb40-386"><a href="#cb40-386" aria-hidden="true" tabindex="-1"></a>affilauthor_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb40-387"><a href="#cb40-387" aria-hidden="true" tabindex="-1"></a>affilauthor_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'affiliation'</span>])</span>
<span id="cb40-388"><a href="#cb40-388" aria-hidden="true" tabindex="-1"></a>countryauthor_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'country'</span>])</span>
<span id="cb40-389"><a href="#cb40-389" aria-hidden="true" tabindex="-1"></a>countryauthor_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'country'</span>])</span>
<span id="cb40-390"><a href="#cb40-390" aria-hidden="true" tabindex="-1"></a>countryauthor_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'country'</span>])</span>
<span id="cb40-391"><a href="#cb40-391" aria-hidden="true" tabindex="-1"></a>countryauthor_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'country'</span>])</span>
<span id="cb40-392"><a href="#cb40-392" aria-hidden="true" tabindex="-1"></a>citations_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb40-393"><a href="#cb40-393" aria-hidden="true" tabindex="-1"></a>citations_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb40-394"><a href="#cb40-394" aria-hidden="true" tabindex="-1"></a>citations_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb40-395"><a href="#cb40-395" aria-hidden="true" tabindex="-1"></a>citations_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'citations'</span>])</span>
<span id="cb40-396"><a href="#cb40-396" aria-hidden="true" tabindex="-1"></a>article_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'article'</span>])</span>
<span id="cb40-397"><a href="#cb40-397" aria-hidden="true" tabindex="-1"></a>article_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'article'</span>])</span>
<span id="cb40-398"><a href="#cb40-398" aria-hidden="true" tabindex="-1"></a>article_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'article'</span>])</span>
<span id="cb40-399"><a href="#cb40-399" aria-hidden="true" tabindex="-1"></a>article_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'article'</span>])</span>
<span id="cb40-400"><a href="#cb40-400" aria-hidden="true" tabindex="-1"></a>journal_before_2013 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"before-2013"</span>)[<span class="st">'journal'</span>])</span>
<span id="cb40-401"><a href="#cb40-401" aria-hidden="true" tabindex="-1"></a>journal_2013_2017 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2013-2017"</span>)[<span class="st">'journal'</span>])</span>
<span id="cb40-402"><a href="#cb40-402" aria-hidden="true" tabindex="-1"></a>journal_2018_2021 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2018-2021"</span>)[<span class="st">'journal'</span>])</span>
<span id="cb40-403"><a href="#cb40-403" aria-hidden="true" tabindex="-1"></a>journal_2022_2023 <span class="op">=</span> sort_dict(get_author_info_by_period(list_articles, <span class="st">"2022-2023"</span>)[<span class="st">'journal'</span>])</span>
<span id="cb40-404"><a href="#cb40-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-405"><a href="#cb40-405" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-406"><a href="#cb40-406" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-407"><a href="#cb40-407" aria-hidden="true" tabindex="-1"></a><span class="fu">## Co-authorship networks</span></span>
<span id="cb40-408"><a href="#cb40-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-411"><a href="#cb40-411" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-412"><a href="#cb40-412" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-creation</span></span>
<span id="cb40-413"><a href="#cb40-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-414"><a href="#cb40-414" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.from_pandas_edgelist(network_data_2022_2023, <span class="st">'authname1'</span>, <span class="st">'authname2'</span>, edge_attr<span class="op">=</span><span class="st">'value'</span>, create_using<span class="op">=</span>nx.Graph())</span>
<span id="cb40-415"><a href="#cb40-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-416"><a href="#cb40-416" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-417"><a href="#cb40-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-418"><a href="#cb40-418" aria-hidden="true" tabindex="-1"></a><span class="fu">### Network basic visualization</span></span>
<span id="cb40-419"><a href="#cb40-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-420"><a href="#cb40-420" aria-hidden="true" tabindex="-1"></a>This is a basic visualization done with the NetworkX library and matplotlib.</span>
<span id="cb40-421"><a href="#cb40-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-424"><a href="#cb40-424" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-425"><a href="#cb40-425" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization</span></span>
<span id="cb40-426"><a href="#cb40-426" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: fenced</span></span>
<span id="cb40-427"><a href="#cb40-427" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Visualization of the co-authorship network for the 2022-2023 period, created using NetworkX and matplotlib.</span></span>
<span id="cb40-428"><a href="#cb40-428" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb40-429"><a href="#cb40-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-430"><a href="#cb40-430" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>,<span class="dv">20</span>))</span>
<span id="cb40-431"><a href="#cb40-431" aria-hidden="true" tabindex="-1"></a>pos <span class="op">=</span> nx.kamada_kawai_layout(G)</span>
<span id="cb40-432"><a href="#cb40-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-433"><a href="#cb40-433" aria-hidden="true" tabindex="-1"></a>nx.draw(G, with_labels<span class="op">=</span><span class="va">True</span>, node_color<span class="op">=</span><span class="st">'skyblue'</span>, edge_cmap<span class="op">=</span>plt.cm.Blues, pos<span class="op">=</span>pos)</span>
<span id="cb40-434"><a href="#cb40-434" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-435"><a href="#cb40-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-436"><a href="#cb40-436" aria-hidden="true" tabindex="-1"></a>::: callout-caution</span>
<span id="cb40-437"><a href="#cb40-437" aria-hidden="true" tabindex="-1"></a>This is not interactive and the result is not enlightening at all. We then decide to use <span class="in">`Pyvis`</span> to create an interactive visualization.</span>
<span id="cb40-438"><a href="#cb40-438" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-439"><a href="#cb40-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-440"><a href="#cb40-440" aria-hidden="true" tabindex="-1"></a><span class="fu">### Network visualization with Pyvis</span></span>
<span id="cb40-441"><a href="#cb40-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-442"><a href="#cb40-442" aria-hidden="true" tabindex="-1"></a>::: callout-tip</span>
<span id="cb40-443"><a href="#cb40-443" aria-hidden="true" tabindex="-1"></a>Pyvis enables us to create interactive visualizations and modify the network layout in real time with the <span class="in">`net.show_buttons(filter_=['physics'])`</span> command. This button then generates options to include in our code by using the <span class="in">`net.set_options()`</span> function. <span class="co">[</span><span class="ot">More information here</span><span class="co">](https://pyvis.readthedocs.io/en/latest/tutorial.html#using-the-configuration-ui-to-dynamically-tweak-network-settings "button physics Pyvis")</span>.</span>
<span id="cb40-444"><a href="#cb40-444" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-445"><a href="#cb40-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-448"><a href="#cb40-448" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-449"><a href="#cb40-449" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-pyvis</span></span>
<span id="cb40-450"><a href="#cb40-450" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb40-451"><a href="#cb40-451" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: fenced</span></span>
<span id="cb40-452"><a href="#cb40-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-453"><a href="#cb40-453" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pyvis.network <span class="im">import</span> Network</span>
<span id="cb40-454"><a href="#cb40-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-455"><a href="#cb40-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-456"><a href="#cb40-456" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> Network(notebook<span class="op">=</span><span class="va">True</span>, cdn_resources<span class="op">=</span><span class="st">'remote'</span>, width<span class="op">=</span><span class="dv">1500</span>, height<span class="op">=</span><span class="dv">900</span>, bgcolor<span class="op">=</span><span class="st">"white"</span>, font_color<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb40-457"><a href="#cb40-457" aria-hidden="true" tabindex="-1"></a><span class="co">#net.show_buttons(filter_=['physics'])</span></span>
<span id="cb40-458"><a href="#cb40-458" aria-hidden="true" tabindex="-1"></a>net.set_options(<span class="st">"""</span></span>
<span id="cb40-459"><a href="#cb40-459" aria-hidden="true" tabindex="-1"></a><span class="st">const options = {</span></span>
<span id="cb40-460"><a href="#cb40-460" aria-hidden="true" tabindex="-1"></a><span class="st">  "physics": {</span></span>
<span id="cb40-461"><a href="#cb40-461" aria-hidden="true" tabindex="-1"></a><span class="st">    "forceAtlas2Based": {</span></span>
<span id="cb40-462"><a href="#cb40-462" aria-hidden="true" tabindex="-1"></a><span class="st">      "gravitationalConstant": -13,</span></span>
<span id="cb40-463"><a href="#cb40-463" aria-hidden="true" tabindex="-1"></a><span class="st">      "centralGravity": 0.015,</span></span>
<span id="cb40-464"><a href="#cb40-464" aria-hidden="true" tabindex="-1"></a><span class="st">      "springLength": 70</span></span>
<span id="cb40-465"><a href="#cb40-465" aria-hidden="true" tabindex="-1"></a><span class="st">    },</span></span>
<span id="cb40-466"><a href="#cb40-466" aria-hidden="true" tabindex="-1"></a><span class="st">    "minVelocity": 0.75,</span></span>
<span id="cb40-467"><a href="#cb40-467" aria-hidden="true" tabindex="-1"></a><span class="st">    "solver": "forceAtlas2Based"</span></span>
<span id="cb40-468"><a href="#cb40-468" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb40-469"><a href="#cb40-469" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb40-470"><a href="#cb40-470" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb40-471"><a href="#cb40-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-472"><a href="#cb40-472" aria-hidden="true" tabindex="-1"></a>node_degree <span class="op">=</span> <span class="bu">dict</span>(G.degree)</span>
<span id="cb40-473"><a href="#cb40-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-474"><a href="#cb40-474" aria-hidden="true" tabindex="-1"></a><span class="co">## Some values for nodes</span></span>
<span id="cb40-475"><a href="#cb40-475" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiply node sizes by two</span></span>
<span id="cb40-476"><a href="#cb40-476" aria-hidden="true" tabindex="-1"></a>node_degree_doubled <span class="op">=</span> {node: <span class="dv">2</span> <span class="op">*</span> degree <span class="cf">for</span> node, degree <span class="kw">in</span> node_degree.items()}</span>
<span id="cb40-477"><a href="#cb40-477" aria-hidden="true" tabindex="-1"></a>node_degree_centrality <span class="op">=</span> nx.degree_centrality(G)</span>
<span id="cb40-478"><a href="#cb40-478" aria-hidden="true" tabindex="-1"></a>node_degree_betweenness <span class="op">=</span> nx.betweenness_centrality(G)</span>
<span id="cb40-479"><a href="#cb40-479" aria-hidden="true" tabindex="-1"></a>node_degree_closeness <span class="op">=</span> nx.closeness_centrality(G)</span>
<span id="cb40-480"><a href="#cb40-480" aria-hidden="true" tabindex="-1"></a>node_degree_constraint <span class="op">=</span> nx.constraint(G)</span>
<span id="cb40-481"><a href="#cb40-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-482"><a href="#cb40-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-483"><a href="#cb40-483" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the node attributes with the doubled sizes</span></span>
<span id="cb40-484"><a href="#cb40-484" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_doubled, <span class="st">'size'</span>)</span>
<span id="cb40-485"><a href="#cb40-485" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_centrality, <span class="st">'centrality'</span>)</span>
<span id="cb40-486"><a href="#cb40-486" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_betweenness, <span class="st">'betweenness'</span>)</span>
<span id="cb40-487"><a href="#cb40-487" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_closeness, <span class="st">'closeness'</span>)</span>
<span id="cb40-488"><a href="#cb40-488" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, node_degree_constraint, <span class="st">'constraint'</span>)</span>
<span id="cb40-489"><a href="#cb40-489" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, affilauthor_2022_2023, <span class="st">'affiliation'</span>)</span>
<span id="cb40-490"><a href="#cb40-490" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, countryauthor_2022_2023, <span class="st">'country'</span>)</span>
<span id="cb40-491"><a href="#cb40-491" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, citations_2022_2023, <span class="st">'citations'</span>)</span>
<span id="cb40-492"><a href="#cb40-492" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, article_2022_2023, <span class="st">'title'</span>)</span>
<span id="cb40-493"><a href="#cb40-493" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, journal_2022_2023, <span class="st">'journal'</span>)</span>
<span id="cb40-494"><a href="#cb40-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-495"><a href="#cb40-495" aria-hidden="true" tabindex="-1"></a><span class="co">#listnodes = net.nodes</span></span>
<span id="cb40-496"><a href="#cb40-496" aria-hidden="true" tabindex="-1"></a><span class="co">#net.nodes.__getitem__(1)</span></span>
<span id="cb40-497"><a href="#cb40-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-498"><a href="#cb40-498" aria-hidden="true" tabindex="-1"></a><span class="co">#listnodes = net.nodes</span></span>
<span id="cb40-499"><a href="#cb40-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-500"><a href="#cb40-500" aria-hidden="true" tabindex="-1"></a>net.from_nx(G)</span>
<span id="cb40-501"><a href="#cb40-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-502"><a href="#cb40-502" aria-hidden="true" tabindex="-1"></a>net.show(<span class="st">"networks/authors/network_2022_2023_pyvis.html"</span>)</span>
<span id="cb40-503"><a href="#cb40-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-504"><a href="#cb40-504" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-505"><a href="#cb40-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-506"><a href="#cb40-506" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb40-507"><a href="#cb40-507" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;iframe width="1500" height="900" src="networks/authors/network_2022_2023_pyvis.html" title="Quarto Documentation" frameborder=0 class="column-page"&gt;&lt;/iframe&gt;</span></span>
<span id="cb40-508"><a href="#cb40-508" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-509"><a href="#cb40-509" aria-hidden="true" tabindex="-1"></a><span class="fu">### Detect communities with Louvain's algorithm</span></span>
<span id="cb40-510"><a href="#cb40-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-513"><a href="#cb40-513" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-514"><a href="#cb40-514" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: community-detection-louvain</span></span>
<span id="cb40-515"><a href="#cb40-515" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb40-516"><a href="#cb40-516" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: fenced</span></span>
<span id="cb40-517"><a href="#cb40-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-518"><a href="#cb40-518" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> community <span class="im">as</span> community_louvain</span>
<span id="cb40-519"><a href="#cb40-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-520"><a href="#cb40-520" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the best partition</span></span>
<span id="cb40-521"><a href="#cb40-521" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G)</span>
<span id="cb40-522"><a href="#cb40-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-523"><a href="#cb40-523" aria-hidden="true" tabindex="-1"></a><span class="co">#dftest = pd.DataFrame(list(communities.items()), columns=['authname', 'community'])</span></span>
<span id="cb40-524"><a href="#cb40-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-525"><a href="#cb40-525" aria-hidden="true" tabindex="-1"></a>nx.set_node_attributes(G, communities, <span class="st">'group'</span>)</span>
<span id="cb40-526"><a href="#cb40-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-527"><a href="#cb40-527" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-528"><a href="#cb40-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-531"><a href="#cb40-531" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-532"><a href="#cb40-532" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-pyvis-louvain</span></span>
<span id="cb40-533"><a href="#cb40-533" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb40-534"><a href="#cb40-534" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: fenced</span></span>
<span id="cb40-535"><a href="#cb40-535" aria-hidden="true" tabindex="-1"></a>com_net <span class="op">=</span> Network(notebook<span class="op">=</span><span class="va">True</span>, cdn_resources<span class="op">=</span><span class="st">'remote'</span>, width<span class="op">=</span><span class="dv">1500</span>, height<span class="op">=</span><span class="dv">900</span>, bgcolor<span class="op">=</span><span class="st">"white"</span>, font_color<span class="op">=</span><span class="st">"black"</span>)</span>
<span id="cb40-536"><a href="#cb40-536" aria-hidden="true" tabindex="-1"></a>com_net.set_options(<span class="st">"""</span></span>
<span id="cb40-537"><a href="#cb40-537" aria-hidden="true" tabindex="-1"></a><span class="st">const options = {</span></span>
<span id="cb40-538"><a href="#cb40-538" aria-hidden="true" tabindex="-1"></a><span class="st">  "physics": {</span></span>
<span id="cb40-539"><a href="#cb40-539" aria-hidden="true" tabindex="-1"></a><span class="st">    "forceAtlas2Based": {</span></span>
<span id="cb40-540"><a href="#cb40-540" aria-hidden="true" tabindex="-1"></a><span class="st">      "gravitationalConstant": -13,</span></span>
<span id="cb40-541"><a href="#cb40-541" aria-hidden="true" tabindex="-1"></a><span class="st">      "centralGravity": 0.015,</span></span>
<span id="cb40-542"><a href="#cb40-542" aria-hidden="true" tabindex="-1"></a><span class="st">      "springLength": 50</span></span>
<span id="cb40-543"><a href="#cb40-543" aria-hidden="true" tabindex="-1"></a><span class="st">    },</span></span>
<span id="cb40-544"><a href="#cb40-544" aria-hidden="true" tabindex="-1"></a><span class="st">    "minVelocity": 0.75,</span></span>
<span id="cb40-545"><a href="#cb40-545" aria-hidden="true" tabindex="-1"></a><span class="st">    "solver": "forceAtlas2Based"</span></span>
<span id="cb40-546"><a href="#cb40-546" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb40-547"><a href="#cb40-547" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb40-548"><a href="#cb40-548" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span>)</span>
<span id="cb40-549"><a href="#cb40-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-550"><a href="#cb40-550" aria-hidden="true" tabindex="-1"></a>com_net.from_nx(G)</span>
<span id="cb40-551"><a href="#cb40-551" aria-hidden="true" tabindex="-1"></a>com_net.show(<span class="st">"networks/authors/network_2022_2023_louvain_pyvis.html"</span>)</span>
<span id="cb40-552"><a href="#cb40-552" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-553"><a href="#cb40-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-554"><a href="#cb40-554" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb40-555"><a href="#cb40-555" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;iframe width="1500" height="900" src="networks/authors/network_2022_2023_louvain_pyvis.html" title="network_2022_2023_louvain" frameborder=0 class="column-page"&gt;&lt;/iframe&gt;</span></span>
<span id="cb40-556"><a href="#cb40-556" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-557"><a href="#cb40-557" aria-hidden="true" tabindex="-1"></a><span class="fu">### Network visualization with ipysigma [@plique:hal-03903518v1]</span></span>
<span id="cb40-558"><a href="#cb40-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-559"><a href="#cb40-559" aria-hidden="true" tabindex="-1"></a><span class="fu">#### A function to graph them all</span></span>
<span id="cb40-560"><a href="#cb40-560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-561"><a href="#cb40-561" aria-hidden="true" tabindex="-1"></a>::: column-margin</span>
<span id="cb40-562"><a href="#cb40-562" aria-hidden="true" tabindex="-1"></a><span class="al">![](images/graph_ring.png)</span>{fig-align="center" width="289"}</span>
<span id="cb40-563"><a href="#cb40-563" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb40-564"><a href="#cb40-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-567"><a href="#cb40-567" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-568"><a href="#cb40-568" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: function-ipysigma-network</span></span>
<span id="cb40-569"><a href="#cb40-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-570"><a href="#cb40-570" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sigma_graph(dataframe, year_period):</span>
<span id="cb40-571"><a href="#cb40-571" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a graph from the given dataframe</span></span>
<span id="cb40-572"><a href="#cb40-572" aria-hidden="true" tabindex="-1"></a>    G <span class="op">=</span> nx.from_pandas_edgelist(dataframe, <span class="st">'authname1'</span>, <span class="st">'authname2'</span>, edge_attr<span class="op">=</span><span class="st">'value'</span>, create_using<span class="op">=</span>nx.Graph())</span>
<span id="cb40-573"><a href="#cb40-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-574"><a href="#cb40-574" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set edge colors for visualization</span></span>
<span id="cb40-575"><a href="#cb40-575" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> u, v <span class="kw">in</span> G.edges:</span>
<span id="cb40-576"><a href="#cb40-576" aria-hidden="true" tabindex="-1"></a>        G[u][v][<span class="st">"color"</span>] <span class="op">=</span> <span class="st">"#7D7C7C"</span></span>
<span id="cb40-577"><a href="#cb40-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-578"><a href="#cb40-578" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the degree of each node</span></span>
<span id="cb40-579"><a href="#cb40-579" aria-hidden="true" tabindex="-1"></a>    node_degree <span class="op">=</span> <span class="bu">dict</span>(G.degree)</span>
<span id="cb40-580"><a href="#cb40-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-581"><a href="#cb40-581" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Compute multiple centrality metrics for nodes</span></span>
<span id="cb40-582"><a href="#cb40-582" aria-hidden="true" tabindex="-1"></a>    node_degree_centrality <span class="op">=</span> nx.degree_centrality(G)</span>
<span id="cb40-583"><a href="#cb40-583" aria-hidden="true" tabindex="-1"></a>    node_degree_betweenness <span class="op">=</span> nx.betweenness_centrality(G)</span>
<span id="cb40-584"><a href="#cb40-584" aria-hidden="true" tabindex="-1"></a>    node_degree_closeness <span class="op">=</span> nx.closeness_centrality(G)</span>
<span id="cb40-585"><a href="#cb40-585" aria-hidden="true" tabindex="-1"></a>    node_degree_eigenvector <span class="op">=</span> nx.closeness_centrality(G)</span>
<span id="cb40-586"><a href="#cb40-586" aria-hidden="true" tabindex="-1"></a>    node_degree_constraint_weighted <span class="op">=</span> nx.constraint(G, weight<span class="op">=</span><span class="st">"value"</span>)</span>
<span id="cb40-587"><a href="#cb40-587" aria-hidden="true" tabindex="-1"></a>    node_degree_constraint_unweighted <span class="op">=</span> nx.constraint(G)</span>
<span id="cb40-588"><a href="#cb40-588" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-589"><a href="#cb40-589" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set node attributes for various metrics</span></span>
<span id="cb40-590"><a href="#cb40-590" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_centrality, <span class="st">'centrality'</span>)</span>
<span id="cb40-591"><a href="#cb40-591" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_betweenness, <span class="st">'betweenness'</span>)</span>
<span id="cb40-592"><a href="#cb40-592" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_closeness, <span class="st">'closeness'</span>)</span>
<span id="cb40-593"><a href="#cb40-593" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_eigenvector, <span class="st">'eigenvector centrality'</span>)</span>
<span id="cb40-594"><a href="#cb40-594" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_weighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint weighted'</span>)</span>
<span id="cb40-595"><a href="#cb40-595" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_unweighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint unweighted'</span>)</span>
<span id="cb40-596"><a href="#cb40-596" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-597"><a href="#cb40-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-598"><a href="#cb40-598" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Mapping of variables based on the provided 'year_period'</span></span>
<span id="cb40-599"><a href="#cb40-599" aria-hidden="true" tabindex="-1"></a>    affilauthor_mapping <span class="op">=</span> {</span>
<span id="cb40-600"><a href="#cb40-600" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: affilauthor_before_2013,</span>
<span id="cb40-601"><a href="#cb40-601" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: affilauthor_2013_2017,</span>
<span id="cb40-602"><a href="#cb40-602" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: affilauthor_2018_2021,</span>
<span id="cb40-603"><a href="#cb40-603" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: affilauthor_2022_2023</span>
<span id="cb40-604"><a href="#cb40-604" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb40-605"><a href="#cb40-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-606"><a href="#cb40-606" aria-hidden="true" tabindex="-1"></a>    countryauthor_mapping <span class="op">=</span> {</span>
<span id="cb40-607"><a href="#cb40-607" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: countryauthor_before_2013,</span>
<span id="cb40-608"><a href="#cb40-608" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: countryauthor_2013_2017,</span>
<span id="cb40-609"><a href="#cb40-609" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: countryauthor_2018_2021,</span>
<span id="cb40-610"><a href="#cb40-610" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: countryauthor_2022_2023</span>
<span id="cb40-611"><a href="#cb40-611" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb40-612"><a href="#cb40-612" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-613"><a href="#cb40-613" aria-hidden="true" tabindex="-1"></a>    citations_mapping <span class="op">=</span> {</span>
<span id="cb40-614"><a href="#cb40-614" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: citations_before_2013,</span>
<span id="cb40-615"><a href="#cb40-615" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: citations_2013_2017,</span>
<span id="cb40-616"><a href="#cb40-616" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: citations_2018_2021,</span>
<span id="cb40-617"><a href="#cb40-617" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: citations_2022_2023</span>
<span id="cb40-618"><a href="#cb40-618" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb40-619"><a href="#cb40-619" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-620"><a href="#cb40-620" aria-hidden="true" tabindex="-1"></a>    article_mapping <span class="op">=</span> {</span>
<span id="cb40-621"><a href="#cb40-621" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: article_before_2013,</span>
<span id="cb40-622"><a href="#cb40-622" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: article_2013_2017,</span>
<span id="cb40-623"><a href="#cb40-623" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: article_2018_2021,</span>
<span id="cb40-624"><a href="#cb40-624" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: article_2022_2023</span>
<span id="cb40-625"><a href="#cb40-625" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb40-626"><a href="#cb40-626" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-627"><a href="#cb40-627" aria-hidden="true" tabindex="-1"></a>    journal_mapping <span class="op">=</span> {</span>
<span id="cb40-628"><a href="#cb40-628" aria-hidden="true" tabindex="-1"></a>        <span class="st">"before-2013"</span>: journal_before_2013,</span>
<span id="cb40-629"><a href="#cb40-629" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2013-2017"</span>: journal_2013_2017,</span>
<span id="cb40-630"><a href="#cb40-630" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2018-2021"</span>: journal_2018_2021,</span>
<span id="cb40-631"><a href="#cb40-631" aria-hidden="true" tabindex="-1"></a>        <span class="st">"2022-2023"</span>: journal_2022_2023</span>
<span id="cb40-632"><a href="#cb40-632" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb40-633"><a href="#cb40-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-634"><a href="#cb40-634" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set node attributes based on the selected 'year_period'</span></span>
<span id="cb40-635"><a href="#cb40-635" aria-hidden="true" tabindex="-1"></a>    <span class="co"># They appear in the graph in the same order they are added</span></span>
<span id="cb40-636"><a href="#cb40-636" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, affilauthor_mapping[year_period], <span class="st">'affiliation'</span>)</span>
<span id="cb40-637"><a href="#cb40-637" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, countryauthor_mapping[year_period], <span class="st">'country'</span>)</span>
<span id="cb40-638"><a href="#cb40-638" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, article_mapping[year_period], <span class="st">'articles'</span>)</span>
<span id="cb40-639"><a href="#cb40-639" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, journal_mapping[year_period], <span class="st">'journals'</span>)</span>
<span id="cb40-640"><a href="#cb40-640" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, citations_mapping[year_period], <span class="st">'citations'</span>)</span>
<span id="cb40-641"><a href="#cb40-641" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_weighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint weighted'</span>)</span>
<span id="cb40-642"><a href="#cb40-642" aria-hidden="true" tabindex="-1"></a>    nx.set_node_attributes(G, node_degree_constraint_unweighted, <span class="st">'burt</span><span class="ch">\'</span><span class="st">s constraint unweighted'</span>)</span>
<span id="cb40-643"><a href="#cb40-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-644"><a href="#cb40-644" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Construct the sigma graph and customize visualization</span></span>
<span id="cb40-645"><a href="#cb40-645" aria-hidden="true" tabindex="-1"></a>    Sigma.write_html(G,</span>
<span id="cb40-646"><a href="#cb40-646" aria-hidden="true" tabindex="-1"></a>        node_metrics<span class="op">=</span>{<span class="st">"community"</span>: {<span class="st">"name"</span>: <span class="st">"louvain"</span>, <span class="st">"resolution"</span>: <span class="dv">1</span>}},  <span class="co"># Specify node metrics. increase resolution to have more communities</span></span>
<span id="cb40-647"><a href="#cb40-647" aria-hidden="true" tabindex="-1"></a>        edge_size<span class="op">=</span><span class="st">"value"</span>,  <span class="co"># Set edge size</span></span>
<span id="cb40-648"><a href="#cb40-648" aria-hidden="true" tabindex="-1"></a>        node_color<span class="op">=</span><span class="st">"community"</span>,  <span class="co"># Set node colors</span></span>
<span id="cb40-649"><a href="#cb40-649" aria-hidden="true" tabindex="-1"></a>        path<span class="op">=</span><span class="ss">f"networks/authors/</span><span class="sc">{</span>year_period<span class="sc">}</span><span class="ss">_sigma.html"</span>,  <span class="co"># Specify the output file path</span></span>
<span id="cb40-650"><a href="#cb40-650" aria-hidden="true" tabindex="-1"></a>        fullscreen<span class="op">=</span><span class="va">True</span>,  <span class="co"># Display in fullscreen mode</span></span>
<span id="cb40-651"><a href="#cb40-651" aria-hidden="true" tabindex="-1"></a>        start_layout<span class="op">=</span><span class="dv">3</span>,  <span class="co"># Start the layout algorithm automatically and lasts 3 seconds</span></span>
<span id="cb40-652"><a href="#cb40-652" aria-hidden="true" tabindex="-1"></a>        max_categorical_colors<span class="op">=</span><span class="dv">10</span>,  <span class="co"># Max categorical colors for communities</span></span>
<span id="cb40-653"><a href="#cb40-653" aria-hidden="true" tabindex="-1"></a>        label_density<span class="op">=</span><span class="dv">2</span>,  <span class="co"># Increase this to have more labels appear, it is also possible to display all labels</span></span>
<span id="cb40-654"><a href="#cb40-654" aria-hidden="true" tabindex="-1"></a>        node_size_range<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">20</span>),  <span class="co"># Set node size range</span></span>
<span id="cb40-655"><a href="#cb40-655" aria-hidden="true" tabindex="-1"></a>        default_edge_type<span class="op">=</span><span class="st">"curve"</span>,  <span class="co"># Set default edge type</span></span>
<span id="cb40-656"><a href="#cb40-656" aria-hidden="true" tabindex="-1"></a>        label_font<span class="op">=</span><span class="st">"Helvetica Neue"</span>,  <span class="co"># Set label font</span></span>
<span id="cb40-657"><a href="#cb40-657" aria-hidden="true" tabindex="-1"></a>        node_label_size<span class="op">=</span><span class="st">"citations"</span>,  <span class="co"># Set node label size</span></span>
<span id="cb40-658"><a href="#cb40-658" aria-hidden="true" tabindex="-1"></a>        <span class="co">#node_border_color="black",  # Set node border color</span></span>
<span id="cb40-659"><a href="#cb40-659" aria-hidden="true" tabindex="-1"></a>        <span class="co">#edge_color="source",  # Set edge color from 'source' attribute</span></span>
<span id="cb40-660"><a href="#cb40-660" aria-hidden="true" tabindex="-1"></a>        node_border_color_from<span class="op">=</span><span class="st">'node'</span>,  <span class="co"># Set node border color from 'node' attribute</span></span>
<span id="cb40-661"><a href="#cb40-661" aria-hidden="true" tabindex="-1"></a>        node_size<span class="op">=</span><span class="st">"citations"</span>,  <span class="co"># Set node size based on 'citations' attribute</span></span>
<span id="cb40-662"><a href="#cb40-662" aria-hidden="true" tabindex="-1"></a>        node_label_size_range<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">25</span>)</span>
<span id="cb40-663"><a href="#cb40-663" aria-hidden="true" tabindex="-1"></a>        <span class="co"># node_label_color="community"  # Set node label color based on 'community' attribute</span></span>
<span id="cb40-664"><a href="#cb40-664" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb40-665"><a href="#cb40-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-666"><a href="#cb40-666" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> G</span>
<span id="cb40-667"><a href="#cb40-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-668"><a href="#cb40-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-669"><a href="#cb40-669" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-670"><a href="#cb40-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-671"><a href="#cb40-671" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Co-authorship network for the 2022-2023 period</span></span>
<span id="cb40-672"><a href="#cb40-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-675"><a href="#cb40-675" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-676"><a href="#cb40-676" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-ipysigma-2022-2023</span></span>
<span id="cb40-677"><a href="#cb40-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-678"><a href="#cb40-678" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb40-679"><a href="#cb40-679" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> community <span class="im">as</span> community_louvain</span>
<span id="cb40-680"><a href="#cb40-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-681"><a href="#cb40-681" aria-hidden="true" tabindex="-1"></a><span class="co"># Fix the seed for reproducibility</span></span>
<span id="cb40-682"><a href="#cb40-682" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">42</span>)</span>
<span id="cb40-683"><a href="#cb40-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-684"><a href="#cb40-684" aria-hidden="true" tabindex="-1"></a>G_2022_2023 <span class="op">=</span> sigma_graph(network_data_2022_2023, <span class="st">'2022-2023'</span>)</span>
<span id="cb40-685"><a href="#cb40-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-686"><a href="#cb40-686" aria-hidden="true" tabindex="-1"></a><span class="co">#detect how many commmunities there are in the graph</span></span>
<span id="cb40-687"><a href="#cb40-687" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_2022_2023)</span>
<span id="cb40-688"><a href="#cb40-688" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the 2022-2023 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span>
<span id="cb40-689"><a href="#cb40-689" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The density of the graph is {}".format(round(nx.density(G_2022_2023), 6)))</span></span>
<span id="cb40-690"><a href="#cb40-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-691"><a href="#cb40-691" aria-hidden="true" tabindex="-1"></a>test_value <span class="op">=</span> nx.constraint(G_2022_2023, nodes<span class="op">=</span><span class="va">None</span>, weight<span class="op">=</span><span class="st">"value"</span>)</span>
<span id="cb40-692"><a href="#cb40-692" aria-hidden="true" tabindex="-1"></a>test_novalue <span class="op">=</span> nx.constraint(G_2022_2023, nodes<span class="op">=</span><span class="va">None</span>, weight<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb40-693"><a href="#cb40-693" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-694"><a href="#cb40-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-695"><a href="#cb40-695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-696"><a href="#cb40-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-697"><a href="#cb40-697" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb40-698"><a href="#cb40-698" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;iframe width="1500" height="900" src="networks/authors/2022-2023_sigma.html" title="Sigma graph" frameborder=0 class="column-page"&gt;&lt;/iframe&gt;</span></span>
<span id="cb40-699"><a href="#cb40-699" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-700"><a href="#cb40-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-701"><a href="#cb40-701" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Co-authorship network for the 2018-2021 period</span></span>
<span id="cb40-702"><a href="#cb40-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-705"><a href="#cb40-705" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-706"><a href="#cb40-706" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-ipysigma-2018-2021</span></span>
<span id="cb40-707"><a href="#cb40-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-708"><a href="#cb40-708" aria-hidden="true" tabindex="-1"></a>G_2018_2021 <span class="op">=</span> sigma_graph(network_data_2018_2021, <span class="st">'2018-2021'</span>)</span>
<span id="cb40-709"><a href="#cb40-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-710"><a href="#cb40-710" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The density of the graph is {}".format(nx.density(G_2018_2021))</span></span>
<span id="cb40-711"><a href="#cb40-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-712"><a href="#cb40-712" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_2018_2021)</span>
<span id="cb40-713"><a href="#cb40-713" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the 2018-2021 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span>
<span id="cb40-714"><a href="#cb40-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-715"><a href="#cb40-715" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-716"><a href="#cb40-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-717"><a href="#cb40-717" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb40-718"><a href="#cb40-718" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;iframe width="1500" height="900" src="networks/authors/2018-2021_sigma.html" title="Sigma graph" frameborder=0 class="column-page"&gt;&lt;/iframe&gt;</span></span>
<span id="cb40-719"><a href="#cb40-719" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-720"><a href="#cb40-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-721"><a href="#cb40-721" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Co-authorship network for the 2013-2017 period</span></span>
<span id="cb40-722"><a href="#cb40-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-725"><a href="#cb40-725" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-726"><a href="#cb40-726" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-ipysigma-2013-2017</span></span>
<span id="cb40-727"><a href="#cb40-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-728"><a href="#cb40-728" aria-hidden="true" tabindex="-1"></a>G_2013_2017 <span class="op">=</span> sigma_graph(network_data_2013_2017, <span class="st">'2013-2017'</span>)</span>
<span id="cb40-729"><a href="#cb40-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-730"><a href="#cb40-730" aria-hidden="true" tabindex="-1"></a><span class="co">#print("The density of the graph is {}".format(nx.density(G_2013_2017))</span></span>
<span id="cb40-731"><a href="#cb40-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-732"><a href="#cb40-732" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_2013_2017)</span>
<span id="cb40-733"><a href="#cb40-733" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the 2013-2017 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span>
<span id="cb40-734"><a href="#cb40-734" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-735"><a href="#cb40-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-736"><a href="#cb40-736" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb40-737"><a href="#cb40-737" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;iframe width="1500" height="900" src="networks/authors/2013-2017_sigma.html" title="Sigma graph" frameborder=0 class="column-page"&gt;&lt;/iframe&gt;</span></span>
<span id="cb40-738"><a href="#cb40-738" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-739"><a href="#cb40-739" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Co-authorship network before 2013</span></span>
<span id="cb40-740"><a href="#cb40-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-743"><a href="#cb40-743" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-744"><a href="#cb40-744" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: network-visualization-ipysigma-before-2013</span></span>
<span id="cb40-745"><a href="#cb40-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-746"><a href="#cb40-746" aria-hidden="true" tabindex="-1"></a>G_before_2013 <span class="op">=</span> sigma_graph(network_data_before_2013, <span class="st">'before-2013'</span>)</span>
<span id="cb40-747"><a href="#cb40-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-748"><a href="#cb40-748" aria-hidden="true" tabindex="-1"></a>communities <span class="op">=</span> community_louvain.best_partition(G_before_2013)</span>
<span id="cb40-749"><a href="#cb40-749" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"There are </span><span class="sc">{}</span><span class="st"> communities in the before-2013 network"</span>.<span class="bu">format</span>(<span class="bu">len</span>(<span class="bu">set</span>(communities.values()))))</span>
<span id="cb40-750"><a href="#cb40-750" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-751"><a href="#cb40-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-752"><a href="#cb40-752" aria-hidden="true" tabindex="-1"></a><span class="in">```{=html}</span></span>
<span id="cb40-753"><a href="#cb40-753" aria-hidden="true" tabindex="-1"></a><span class="in">&lt;iframe width="1500" height="900" src="networks/authors/before-2013_sigma.html" title="Sigma graph" frameborder=0 class="column-page"&gt;&lt;/iframe&gt;</span></span>
<span id="cb40-754"><a href="#cb40-754" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-755"><a href="#cb40-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-756"><a href="#cb40-756" aria-hidden="true" tabindex="-1"></a><span class="fu">### An interesting metric: the graph density</span></span>
<span id="cb40-757"><a href="#cb40-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-758"><a href="#cb40-758" aria-hidden="true" tabindex="-1"></a>The graph density is the ratio of the number of edges to the maximum number of possible edges. It is a measure of the proportion of edges present in a graph. A graph with a high density has a large number of edges compared to the number of nodes. A graph with a low density has a small number of edges compared to the number of nodes.</span>
<span id="cb40-759"><a href="#cb40-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-760"><a href="#cb40-760" aria-hidden="true" tabindex="-1"></a>A more formal definition is given <span class="co">[</span><span class="ot">here</span><span class="co">](https://networkx.org/documentation/stable/reference/generated/networkx.classes.function.density.html)</span> by the following formulas:</span>
<span id="cb40-761"><a href="#cb40-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-762"><a href="#cb40-762" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For undirected graphs:</span>
<span id="cb40-763"><a href="#cb40-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-764"><a href="#cb40-764" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb40-765"><a href="#cb40-765" aria-hidden="true" tabindex="-1"></a>\begin{equation}d=\frac{2 m}{n(n-1)}\end{equation}</span>
<span id="cb40-766"><a href="#cb40-766" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb40-767"><a href="#cb40-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-768"><a href="#cb40-768" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>For directed graphs:</span>
<span id="cb40-769"><a href="#cb40-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-770"><a href="#cb40-770" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb40-771"><a href="#cb40-771" aria-hidden="true" tabindex="-1"></a>\begin{equation}d=\frac{2 m}{n(n-1)}\end{equation}</span>
<span id="cb40-772"><a href="#cb40-772" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb40-773"><a href="#cb40-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-774"><a href="#cb40-774" aria-hidden="true" tabindex="-1"></a>where $n$ is the number of nodes and $m$ is the number of edges in the graph.</span>
<span id="cb40-775"><a href="#cb40-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-776"><a href="#cb40-776" aria-hidden="true" tabindex="-1"></a>From an interpretation standpoint, we can appreciate the density in the graphs bellow as follows:</span>
<span id="cb40-777"><a href="#cb40-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-778"><a href="#cb40-778" aria-hidden="true" tabindex="-1"></a>+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span id="cb40-779"><a href="#cb40-779" aria-hidden="true" tabindex="-1"></a>| $d$                  | **Interpretation**                                                                                                                                         |</span>
<span id="cb40-780"><a href="#cb40-780" aria-hidden="true" tabindex="-1"></a>+:====================:+:===========================================================================================================================================================+</span>
<span id="cb40-781"><a href="#cb40-781" aria-hidden="true" tabindex="-1"></a>| Close to $0$         | -   The collaborative relationships among authors are sparse:                                                                                              |</span>
<span id="cb40-782"><a href="#cb40-782" aria-hidden="true" tabindex="-1"></a>|                      |                                                                                                                                                            |</span>
<span id="cb40-783"><a href="#cb40-783" aria-hidden="true" tabindex="-1"></a>|                      | -   Authors have limited connections with each other outside of their community.                                                                           |</span>
<span id="cb40-784"><a href="#cb40-784" aria-hidden="true" tabindex="-1"></a>|                      |                                                                                                                                                            |</span>
<span id="cb40-785"><a href="#cb40-785" aria-hidden="true" tabindex="-1"></a>|                      | -   Scientific papers are primarily the work of individual authors or small isolated groups.                                                               |</span>
<span id="cb40-786"><a href="#cb40-786" aria-hidden="true" tabindex="-1"></a>+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span id="cb40-787"><a href="#cb40-787" aria-hidden="true" tabindex="-1"></a>| Close to $1$         | -   Authors frequently collaborate with one another, leading to a web of interconnected scientific collaborations.                                         |</span>
<span id="cb40-788"><a href="#cb40-788" aria-hidden="true" tabindex="-1"></a>|                      |                                                                                                                                                            |</span>
<span id="cb40-789"><a href="#cb40-789" aria-hidden="true" tabindex="-1"></a>|                      | -   Scientific papers often involve contributions from multiple authors, reflecting a high level of teamwork and interdisciplinary research.               |</span>
<span id="cb40-790"><a href="#cb40-790" aria-hidden="true" tabindex="-1"></a>|                      |                                                                                                                                                            |</span>
<span id="cb40-791"><a href="#cb40-791" aria-hidden="true" tabindex="-1"></a>|                      | -   Collaborations are a significant aspect of the research process in this marketing field, and authors actively seek out opportunities to work together. |</span>
<span id="cb40-792"><a href="#cb40-792" aria-hidden="true" tabindex="-1"></a>|                      |                                                                                                                                                            |</span>
<span id="cb40-793"><a href="#cb40-793" aria-hidden="true" tabindex="-1"></a>|                      | -   The network of collaborations is well-established and robust, facilitating the exchange of ideas and the advancement of scientific knowledge.          |</span>
<span id="cb40-794"><a href="#cb40-794" aria-hidden="true" tabindex="-1"></a>+----------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------+</span>
<span id="cb40-795"><a href="#cb40-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-796"><a href="#cb40-796" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Evolution of the graphs' density</span></span>
<span id="cb40-797"><a href="#cb40-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-800"><a href="#cb40-800" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-801"><a href="#cb40-801" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: evolution-graphs-density</span></span>
<span id="cb40-802"><a href="#cb40-802" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb40-803"><a href="#cb40-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-804"><a href="#cb40-804" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a dataframe with the density of each graph</span></span>
<span id="cb40-805"><a href="#cb40-805" aria-hidden="true" tabindex="-1"></a>density_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb40-806"><a href="#cb40-806" aria-hidden="true" tabindex="-1"></a>    <span class="st">'period'</span>: [<span class="st">'before-2013'</span>, <span class="st">'2013-2017'</span>, <span class="st">'2018-2021'</span>, <span class="st">'2022-2023'</span>],</span>
<span id="cb40-807"><a href="#cb40-807" aria-hidden="true" tabindex="-1"></a>    <span class="st">'density'</span>: [nx.density(G_before_2013), nx.density(G_2013_2017), nx.density(G_2018_2021), nx.density(G_2022_2023)]</span>
<span id="cb40-808"><a href="#cb40-808" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb40-809"><a href="#cb40-809" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-810"><a href="#cb40-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-811"><a href="#cb40-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-814"><a href="#cb40-814" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-815"><a href="#cb40-815" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: evolution-graphs-density-r</span></span>
<span id="cb40-816"><a href="#cb40-816" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb40-817"><a href="#cb40-817" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(Hmisc)</span>
<span id="cb40-818"><a href="#cb40-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-819"><a href="#cb40-819" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the 'density_df' dataframe from Python using reticulate</span></span>
<span id="cb40-820"><a href="#cb40-820" aria-hidden="true" tabindex="-1"></a>testtransfer <span class="ot">&lt;-</span> py<span class="sc">$</span>density_df</span>
<span id="cb40-821"><a href="#cb40-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-822"><a href="#cb40-822" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the order of categories for the 'period' column</span></span>
<span id="cb40-823"><a href="#cb40-823" aria-hidden="true" tabindex="-1"></a>testtransfer<span class="sc">$</span>period <span class="ot">&lt;-</span> <span class="fu">factor</span>(testtransfer<span class="sc">$</span>period, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">'before-2013'</span>, <span class="st">'2013-2017'</span>, <span class="st">'2018-2021'</span>, <span class="st">'2022-2023'</span>))</span>
<span id="cb40-824"><a href="#cb40-824" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-825"><a href="#cb40-825" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the 'gt()' function to display the dataframe</span></span>
<span id="cb40-826"><a href="#cb40-826" aria-hidden="true" tabindex="-1"></a>testtransfer <span class="sc">%&gt;%</span></span>
<span id="cb40-827"><a href="#cb40-827" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename_all</span>(Hmisc<span class="sc">::</span>capitalize) <span class="sc">%&gt;%</span></span>
<span id="cb40-828"><a href="#cb40-828" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gt</span>() <span class="sc">%&gt;%</span></span>
<span id="cb40-829"><a href="#cb40-829" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tab_style</span>(</span>
<span id="cb40-830"><a href="#cb40-830" aria-hidden="true" tabindex="-1"></a>    <span class="at">style =</span> <span class="fu">cell_text</span>(<span class="at">weight =</span> <span class="st">"bold"</span>, <span class="at">align =</span> <span class="st">"center"</span>),</span>
<span id="cb40-831"><a href="#cb40-831" aria-hidden="true" tabindex="-1"></a>    <span class="at">locations =</span> <span class="fu">cells_column_labels</span>()</span>
<span id="cb40-832"><a href="#cb40-832" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb40-833"><a href="#cb40-833" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-834"><a href="#cb40-834" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb40-835"><a href="#cb40-835" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the Plotly graph</span></span>
<span id="cb40-836"><a href="#cb40-836" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> <span class="fu">plot_ly</span>(testtransfer, <span class="at">x =</span> <span class="sc">~</span>period, <span class="at">y =</span> <span class="sc">~</span>density, <span class="at">type =</span> <span class="st">'scatter'</span>, <span class="at">mode =</span> <span class="st">'lines+markers'</span>, </span>
<span id="cb40-837"><a href="#cb40-837" aria-hidden="true" tabindex="-1"></a>               <span class="at">text =</span> <span class="sc">~</span><span class="fu">paste</span>(<span class="st">"Period="</span>, period, <span class="st">"&lt;br&gt;Density="</span>, density), <span class="at">hoverinfo =</span> <span class="st">"text"</span>)</span>
<span id="cb40-838"><a href="#cb40-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-839"><a href="#cb40-839" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the graph</span></span>
<span id="cb40-840"><a href="#cb40-840" aria-hidden="true" tabindex="-1"></a>fig <span class="ot">&lt;-</span> fig <span class="sc">%&gt;%</span> <span class="fu">layout</span>(<span class="at">template =</span> <span class="st">"plotly_white"</span>)</span>
<span id="cb40-841"><a href="#cb40-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-842"><a href="#cb40-842" aria-hidden="true" tabindex="-1"></a>fig</span>
<span id="cb40-843"><a href="#cb40-843" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-844"><a href="#cb40-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-845"><a href="#cb40-845" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-846"><a href="#cb40-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-847"><a href="#cb40-847" aria-hidden="true" tabindex="-1"></a><span class="fu">## Citations networks</span></span>
<span id="cb40-848"><a href="#cb40-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-849"><a href="#cb40-849" aria-hidden="true" tabindex="-1"></a>Let's now dive into the exploration of citation networks. We'll be employing the same approach that we used for analyzing co-authorship networks across different time periods.</span>
<span id="cb40-850"><a href="#cb40-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-851"><a href="#cb40-851" aria-hidden="true" tabindex="-1"></a>In this new investigation, our primary aim remains the acquisition of valuable insights into the ever-evolving landscape of research in marketing using NLP methods.</span>
<span id="cb40-852"><a href="#cb40-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-853"><a href="#cb40-853" aria-hidden="true" tabindex="-1"></a>This research is motivated by the convergence of two critical factors:</span>
<span id="cb40-854"><a href="#cb40-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-855"><a href="#cb40-855" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>The advent of novel tools and techniques that facilitate the analysis of large data volumes ;</span>
<span id="cb40-856"><a href="#cb40-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-857"><a href="#cb40-857" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The proliferation and the availability of open and private data from various sectors.</span>
<span id="cb40-858"><a href="#cb40-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-859"><a href="#cb40-859" aria-hidden="true" tabindex="-1"></a>While our prior work focused on uncovering emerging research topics, our current emphasis shifts towards comprehending which papers have garnered the most attention. We seek to determine whether it is predominantly computer science papers that have inspired marketing scholars with new perspectives into data analysis or if marketing papers have also played a role in advocating the development of new theories.</span>
<span id="cb40-860"><a href="#cb40-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-861"><a href="#cb40-861" aria-hidden="true" tabindex="-1"></a><span class="fu">### Data preparation and summary</span></span>
<span id="cb40-862"><a href="#cb40-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-863"><a href="#cb40-863" aria-hidden="true" tabindex="-1"></a>We'll start by loading the data of references and preparing it for the analysis.</span>
<span id="cb40-864"><a href="#cb40-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-867"><a href="#cb40-867" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-868"><a href="#cb40-868" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: citations-data-preparation</span></span>
<span id="cb40-869"><a href="#cb40-869" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-870"><a href="#cb40-870" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data of references</span></span>
<span id="cb40-871"><a href="#cb40-871" aria-hidden="true" tabindex="-1"></a>list_references <span class="ot">&lt;-</span> <span class="fu">read_csv2</span>(<span class="st">'nlp_references_final_18-08-2023.csv'</span>)</span>
<span id="cb40-872"><a href="#cb40-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-873"><a href="#cb40-873" aria-hidden="true" tabindex="-1"></a>list_references <span class="ot">&lt;-</span> list_references <span class="sc">%&gt;%</span></span>
<span id="cb40-874"><a href="#cb40-874" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">32</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-875"><a href="#cb40-875" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">citing_art =</span> <span class="fu">str_sub</span>(citing_art, <span class="dv">11</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb40-876"><a href="#cb40-876" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">scopus_id =</span> <span class="st">`</span><span class="at">scopus-id</span><span class="st">`</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb40-877"><a href="#cb40-877" aria-hidden="true" tabindex="-1"></a>  <span class="fu">relocate</span>(scopus_id, <span class="at">.after =</span> citing_art) <span class="sc">%&gt;%</span></span>
<span id="cb40-878"><a href="#cb40-878" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">year =</span> <span class="fu">as.character</span>(<span class="fu">str_sub</span>(<span class="st">`</span><span class="at">prism:coverDate</span><span class="st">`</span>, <span class="dv">1</span>, <span class="dv">4</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb40-879"><a href="#cb40-879" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="st">`</span><span class="at">prism:coverDate</span><span class="st">`</span>)</span>
<span id="cb40-880"><a href="#cb40-880" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-881"><a href="#cb40-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-882"><a href="#cb40-882" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(list_references)</span>
<span id="cb40-883"><a href="#cb40-883" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-884"><a href="#cb40-884" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Detect inconsistencies</span></span>
<span id="cb40-885"><a href="#cb40-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-886"><a href="#cb40-886" aria-hidden="true" tabindex="-1"></a>There are some problems with the data that we need to address before proceeding with the analysis.</span>
<span id="cb40-887"><a href="#cb40-887" aria-hidden="true" tabindex="-1"></a>Some <span class="in">`scopus_id`</span> identifiers (the id of the reference that appears in our marketing NLP corpus articles) have multiple different values of title (even only minor differences), sourcetitle, etc. although they should be equal. We want to plot the networks with information about the nodes. One unique node should have one unique value for each variable.</span>
<span id="cb40-888"><a href="#cb40-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-891"><a href="#cb40-891" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-892"><a href="#cb40-892" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: citations-detect-inconsistencies</span></span>
<span id="cb40-893"><a href="#cb40-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-894"><a href="#cb40-894" aria-hidden="true" tabindex="-1"></a>list_references <span class="op">=</span> r.list_references</span>
<span id="cb40-895"><a href="#cb40-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-896"><a href="#cb40-896" aria-hidden="true" tabindex="-1"></a><span class="co"># Group by 'scopus_id' and count the unique number of 'title' for each 'scopus_id'</span></span>
<span id="cb40-897"><a href="#cb40-897" aria-hidden="true" tabindex="-1"></a>title_counts <span class="op">=</span> list_references.groupby(<span class="st">'scopus_id'</span>)[<span class="st">'title'</span>].nunique()</span>
<span id="cb40-898"><a href="#cb40-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-899"><a href="#cb40-899" aria-hidden="true" tabindex="-1"></a><span class="co"># Find the 'scopus_id' that have more than one associated title</span></span>
<span id="cb40-900"><a href="#cb40-900" aria-hidden="true" tabindex="-1"></a>inconsistent_scopus_id <span class="op">=</span> title_counts[title_counts <span class="op">&gt;</span> <span class="dv">1</span>].index.tolist()</span>
<span id="cb40-901"><a href="#cb40-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-902"><a href="#cb40-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-903"><a href="#cb40-903" aria-hidden="true" tabindex="-1"></a>year_counts <span class="op">=</span> list_references.groupby(<span class="st">'scopus_id'</span>)[<span class="st">'year'</span>].nunique()</span>
<span id="cb40-904"><a href="#cb40-904" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-905"><a href="#cb40-905" aria-hidden="true" tabindex="-1"></a>inconsistent_scopus_id_year <span class="op">=</span> year_counts[title_counts <span class="op">&gt;</span> <span class="dv">1</span>].index.tolist()</span>
<span id="cb40-906"><a href="#cb40-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-907"><a href="#cb40-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-908"><a href="#cb40-908" aria-hidden="true" tabindex="-1"></a>inconsistent_scopus_id_year</span>
<span id="cb40-909"><a href="#cb40-909" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-910"><a href="#cb40-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-911"><a href="#cb40-911" aria-hidden="true" tabindex="-1"></a><span class="fu">#### List of all inconsistencies</span></span>
<span id="cb40-912"><a href="#cb40-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-913"><a href="#cb40-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-916"><a href="#cb40-916" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-917"><a href="#cb40-917" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: citations-show-inconsistencies</span></span>
<span id="cb40-918"><a href="#cb40-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-919"><a href="#cb40-919" aria-hidden="true" tabindex="-1"></a>list_inconsistencies <span class="ot">&lt;-</span> list_references <span class="sc">%&gt;%</span></span>
<span id="cb40-920"><a href="#cb40-920" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(scopus_id <span class="sc">%in%</span> py<span class="sc">$</span>inconsistent_scopus_id) <span class="sc">%&gt;%</span> <span class="co">#we take the inconsistent scopus_id from python by using reticulate</span></span>
<span id="cb40-921"><a href="#cb40-921" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(scopus_id, citing_art, title, sourcetitle, year, <span class="st">`</span><span class="at">author-list.author.ce:indexed-name</span><span class="st">`</span>)</span>
<span id="cb40-922"><a href="#cb40-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-923"><a href="#cb40-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-924"><a href="#cb40-924" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(</span>
<span id="cb40-925"><a href="#cb40-925" aria-hidden="true" tabindex="-1"></a>  list_inconsistencies,</span>
<span id="cb40-926"><a href="#cb40-926" aria-hidden="true" tabindex="-1"></a>  <span class="at">striped =</span> <span class="cn">TRUE</span>,</span>
<span id="cb40-927"><a href="#cb40-927" aria-hidden="true" tabindex="-1"></a>  <span class="at">groupBy =</span> <span class="st">"scopus_id"</span>,</span>
<span id="cb40-928"><a href="#cb40-928" aria-hidden="true" tabindex="-1"></a>  <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">100</span>, <span class="at">maxWidth =</span> <span class="dv">200</span>),  <span class="co"># Adjust these values as needed</span></span>
<span id="cb40-929"><a href="#cb40-929" aria-hidden="true" tabindex="-1"></a>  <span class="at">columns =</span> <span class="fu">list</span>(</span>
<span id="cb40-930"><a href="#cb40-930" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">250</span>)  <span class="co"># Adjust this value based on the length of your titles</span></span>
<span id="cb40-931"><a href="#cb40-931" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb40-932"><a href="#cb40-932" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-933"><a href="#cb40-933" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-934"><a href="#cb40-934" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-935"><a href="#cb40-935" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-936"><a href="#cb40-936" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Correct inconsistencies</span></span>
<span id="cb40-937"><a href="#cb40-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-938"><a href="#cb40-938" aria-hidden="true" tabindex="-1"></a>We correct inconsistencies in the data.</span>
<span id="cb40-939"><a href="#cb40-939" aria-hidden="true" tabindex="-1"></a>Some <span class="in">`scopus_id`</span> identifiers have multiple different values of title, sourcetitle, authorname, etc. (even only minor differences). </span>
<span id="cb40-940"><a href="#cb40-940" aria-hidden="true" tabindex="-1"></a>For data consistency and future plot of networks, we need to have only one unique value for each variable of <span class="in">`scopus_id`</span>.</span>
<span id="cb40-941"><a href="#cb40-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-944"><a href="#cb40-944" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-945"><a href="#cb40-945" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: citations-correct-inconsistencies</span></span>
<span id="cb40-946"><a href="#cb40-946" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-947"><a href="#cb40-947" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> standardize_values(df, groupby_column, value_column):</span>
<span id="cb40-948"><a href="#cb40-948" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb40-949"><a href="#cb40-949" aria-hidden="true" tabindex="-1"></a><span class="co">    Standardize the values of the specified column based on the most frequent non-empty value and fewest characters </span></span>
<span id="cb40-950"><a href="#cb40-950" aria-hidden="true" tabindex="-1"></a><span class="co">    within each group.</span></span>
<span id="cb40-951"><a href="#cb40-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-952"><a href="#cb40-952" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb40-953"><a href="#cb40-953" aria-hidden="true" tabindex="-1"></a><span class="co">    - df: DataFrame</span></span>
<span id="cb40-954"><a href="#cb40-954" aria-hidden="true" tabindex="-1"></a><span class="co">    - groupby_column: The column by which we group data.</span></span>
<span id="cb40-955"><a href="#cb40-955" aria-hidden="true" tabindex="-1"></a><span class="co">    - value_column: The column whose values we want to standardize based on the rules.</span></span>
<span id="cb40-956"><a href="#cb40-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-957"><a href="#cb40-957" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb40-958"><a href="#cb40-958" aria-hidden="true" tabindex="-1"></a><span class="co">    - DataFrame with standardized values.</span></span>
<span id="cb40-959"><a href="#cb40-959" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb40-960"><a href="#cb40-960" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-961"><a href="#cb40-961" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> custom_mode(series):</span>
<span id="cb40-962"><a href="#cb40-962" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Remove NA values and other representations of NA</span></span>
<span id="cb40-963"><a href="#cb40-963" aria-hidden="true" tabindex="-1"></a>        series <span class="op">=</span> series.dropna()</span>
<span id="cb40-964"><a href="#cb40-964" aria-hidden="true" tabindex="-1"></a>        series <span class="op">=</span> series[<span class="op">~</span>series.isin([<span class="st">''</span>, <span class="st">'NA'</span>])]</span>
<span id="cb40-965"><a href="#cb40-965" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb40-966"><a href="#cb40-966" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If all values were NA or empty</span></span>
<span id="cb40-967"><a href="#cb40-967" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> series.empty:</span>
<span id="cb40-968"><a href="#cb40-968" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> np.nan  <span class="co"># Using numpy's nan for consistency</span></span>
<span id="cb40-969"><a href="#cb40-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-970"><a href="#cb40-970" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get value counts</span></span>
<span id="cb40-971"><a href="#cb40-971" aria-hidden="true" tabindex="-1"></a>        counts <span class="op">=</span> series.value_counts()</span>
<span id="cb40-972"><a href="#cb40-972" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-973"><a href="#cb40-973" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there's a single most common value, return it</span></span>
<span id="cb40-974"><a href="#cb40-974" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(counts) <span class="op">==</span> <span class="dv">1</span> <span class="kw">or</span> counts.iloc[<span class="dv">0</span>] <span class="op">!=</span> counts.iloc[<span class="dv">1</span>]:</span>
<span id="cb40-975"><a href="#cb40-975" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> counts.idxmax()</span>
<span id="cb40-976"><a href="#cb40-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-977"><a href="#cb40-977" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If multiple values have the same max count, apply further rules</span></span>
<span id="cb40-978"><a href="#cb40-978" aria-hidden="true" tabindex="-1"></a>        top_values <span class="op">=</span> counts[counts <span class="op">==</span> counts.iloc[<span class="dv">0</span>]].index.tolist()</span>
<span id="cb40-979"><a href="#cb40-979" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-980"><a href="#cb40-980" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sort by fewest characters</span></span>
<span id="cb40-981"><a href="#cb40-981" aria-hidden="true" tabindex="-1"></a>        sorted_by_chars <span class="op">=</span> <span class="bu">sorted</span>(top_values, key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">len</span>(x))</span>
<span id="cb40-982"><a href="#cb40-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-983"><a href="#cb40-983" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If there's a single value with the fewest characters, return it</span></span>
<span id="cb40-984"><a href="#cb40-984" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(sorted_by_chars) <span class="op">==</span> <span class="dv">1</span> <span class="kw">or</span> <span class="bu">len</span>(sorted_by_chars[<span class="dv">0</span>]) <span class="op">!=</span> <span class="bu">len</span>(sorted_by_chars[<span class="dv">1</span>]):</span>
<span id="cb40-985"><a href="#cb40-985" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> sorted_by_chars[<span class="dv">0</span>]</span>
<span id="cb40-986"><a href="#cb40-986" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-987"><a href="#cb40-987" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If the column is not the author's name, apply the uppercase letter rule.</span></span>
<span id="cb40-988"><a href="#cb40-988" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> value_column <span class="op">!=</span> <span class="st">"author_name"</span>:  <span class="co"># adjust "author_name" to the correct column name if necessary</span></span>
<span id="cb40-989"><a href="#cb40-989" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">sorted</span>(sorted_by_chars, key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> c <span class="kw">in</span> x <span class="cf">if</span> c.isupper()), reverse<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb40-990"><a href="#cb40-990" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb40-991"><a href="#cb40-991" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> sorted_by_chars[<span class="dv">0</span>]</span>
<span id="cb40-992"><a href="#cb40-992" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-993"><a href="#cb40-993" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Find the most common value for each group based on the custom mode</span></span>
<span id="cb40-994"><a href="#cb40-994" aria-hidden="true" tabindex="-1"></a>    most_common_value <span class="op">=</span> df.groupby(groupby_column)[value_column].<span class="bu">apply</span>(custom_mode).to_dict()</span>
<span id="cb40-995"><a href="#cb40-995" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-996"><a href="#cb40-996" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Map the most common values to the dataframe based on the group</span></span>
<span id="cb40-997"><a href="#cb40-997" aria-hidden="true" tabindex="-1"></a>    df[value_column] <span class="op">=</span> df[groupby_column].<span class="bu">map</span>(most_common_value)</span>
<span id="cb40-998"><a href="#cb40-998" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-999"><a href="#cb40-999" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> df</span>
<span id="cb40-1000"><a href="#cb40-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1001"><a href="#cb40-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1002"><a href="#cb40-1002" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage example:</span></span>
<span id="cb40-1003"><a href="#cb40-1003" aria-hidden="true" tabindex="-1"></a>list_references_standardized <span class="op">=</span> standardize_values(list_references, <span class="st">'scopus_id'</span>, <span class="st">'title'</span>)</span>
<span id="cb40-1004"><a href="#cb40-1004" aria-hidden="true" tabindex="-1"></a>list_references_standardized <span class="op">=</span> standardize_values(list_references_standardized, <span class="st">'scopus_id'</span>, <span class="st">'sourcetitle'</span>)</span>
<span id="cb40-1005"><a href="#cb40-1005" aria-hidden="true" tabindex="-1"></a>list_references_standardized <span class="op">=</span> standardize_values(list_references_standardized, <span class="st">'scopus_id'</span>, <span class="st">'author-list.author.ce:indexed-name'</span>)</span>
<span id="cb40-1006"><a href="#cb40-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1007"><a href="#cb40-1007" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1008"><a href="#cb40-1008" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-1009"><a href="#cb40-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1010"><a href="#cb40-1010" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Check inconsistencies</span></span>
<span id="cb40-1011"><a href="#cb40-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1012"><a href="#cb40-1012" aria-hidden="true" tabindex="-1"></a>We check that the inconsistencies have been corrected.</span>
<span id="cb40-1013"><a href="#cb40-1013" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1016"><a href="#cb40-1016" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb40-1017"><a href="#cb40-1017" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: citations-check-inconsistencies</span></span>
<span id="cb40-1018"><a href="#cb40-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1019"><a href="#cb40-1019" aria-hidden="true" tabindex="-1"></a>check_inconsistencies <span class="ot">&lt;-</span> py<span class="sc">$</span>list_references_standardized <span class="sc">%&gt;%</span></span>
<span id="cb40-1020"><a href="#cb40-1020" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(scopus_id <span class="sc">%in%</span> py<span class="sc">$</span>inconsistent_scopus_id) <span class="sc">%&gt;%</span> <span class="co">#we take the inconsistent scopus_id from python by using reticulate</span></span>
<span id="cb40-1021"><a href="#cb40-1021" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(scopus_id, citing_art, title, sourcetitle, year, <span class="st">`</span><span class="at">author-list.author.ce:indexed-name</span><span class="st">`</span>)</span>
<span id="cb40-1022"><a href="#cb40-1022" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1023"><a href="#cb40-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1024"><a href="#cb40-1024" aria-hidden="true" tabindex="-1"></a><span class="fu">reactable</span>(</span>
<span id="cb40-1025"><a href="#cb40-1025" aria-hidden="true" tabindex="-1"></a>  check_inconsistencies,</span>
<span id="cb40-1026"><a href="#cb40-1026" aria-hidden="true" tabindex="-1"></a>  <span class="at">groupBy =</span> <span class="st">"scopus_id"</span>,</span>
<span id="cb40-1027"><a href="#cb40-1027" aria-hidden="true" tabindex="-1"></a>  <span class="at">defaultColDef =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">100</span>, <span class="at">maxWidth =</span> <span class="dv">200</span>),  <span class="co"># Adjust these values as needed</span></span>
<span id="cb40-1028"><a href="#cb40-1028" aria-hidden="true" tabindex="-1"></a>  <span class="at">columns =</span> <span class="fu">list</span>(</span>
<span id="cb40-1029"><a href="#cb40-1029" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="fu">colDef</span>(<span class="at">minWidth =</span> <span class="dv">250</span>)  <span class="co"># Adjust this value based on the length of your titles</span></span>
<span id="cb40-1030"><a href="#cb40-1030" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb40-1031"><a href="#cb40-1031" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-1032"><a href="#cb40-1032" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1033"><a href="#cb40-1033" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb40-1034"><a href="#cb40-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1035"><a href="#cb40-1035" aria-hidden="true" tabindex="-1"></a><span class="fu">## Construct the dataframes</span></span>
<span id="cb40-1036"><a href="#cb40-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1039"><a href="#cb40-1039" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb40-1040"><a href="#cb40-1040" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: citations-construct-dataframes</span></span>
<span id="cb40-1041"><a href="#cb40-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1042"><a href="#cb40-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1043"><a href="#cb40-1043" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_citations_df(df, start_year, end_year):</span>
<span id="cb40-1044"><a href="#cb40-1044" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filtrer les données en fonction de la colonne 'year'</span></span>
<span id="cb40-1045"><a href="#cb40-1045" aria-hidden="true" tabindex="-1"></a>    df_filtered <span class="op">=</span> df[df[<span class="st">'year'</span>].between(start_year, end_year)]</span>
<span id="cb40-1046"><a href="#cb40-1046" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-1047"><a href="#cb40-1047" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extraire les colonnes nécessaires pour le réseau de citations</span></span>
<span id="cb40-1048"><a href="#cb40-1048" aria-hidden="true" tabindex="-1"></a>    citations_df <span class="op">=</span> df_filtered[[<span class="st">'citing_art'</span>, <span class="st">'scopus_id'</span>, <span class="st">'sourcetitle'</span>, <span class="st">'title'</span>, <span class="st">'citedby-count'</span>, <span class="st">'author-list.author.ce:indexed-name'</span>, <span class="st">'year'</span>]]</span>
<span id="cb40-1049"><a href="#cb40-1049" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-1050"><a href="#cb40-1050" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> citations_df</span>
<span id="cb40-1051"><a href="#cb40-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-1052"><a href="#cb40-1052" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>