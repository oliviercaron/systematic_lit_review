{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "56f012f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import re\n",
    "from ipysigma import Sigma, SigmaGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "35fab3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_references = pd.read_csv(\"list_ref_test_to_delete.csv\", sep=';', decimal=',')\n",
    "data = pd.read_csv(\"data_final.csv\")\n",
    "data.rename(columns={'citedby-count': 'citedby_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2b51f9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict(dict):\n",
    "    sorted_dict = {k: v for k, v in sorted(dict.items(), key=lambda item: item[0])}\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ed6136db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_citations_df(df, start_year=None, end_year=None):\n",
    "    \"\"\"\n",
    "    Filter and extract necessary columns for citation network from a DataFrame based on a range of years.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data\n",
    "    - start_year: Optional, the starting year for filtering\n",
    "    - end_year: Optional, the ending year for filtering\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with filtered data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace 'NA' with numpy.nan and reassign the DataFrame\n",
    "    df = df.replace({'year': 'NA'}, np.nan)\n",
    "    \n",
    "    # Drop rows where 'year' is NaN\n",
    "    df = df.dropna(subset=['year'])\n",
    "    \n",
    "    # Convert the 'year' column to integer using .astype\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    \n",
    "    # Filter the data based on the 'year' column only if start_year and end_year are provided\n",
    "    if start_year is not None and end_year is not None:\n",
    "        df = df[df['year'].between(start_year, end_year)]\n",
    "    \n",
    "    # Extract necessary columns for the citation network\n",
    "    citations_df = df[['citing_art', 'scopus_id', 'sourcetitle', 'title', 'citedby_count', 'citations_per_year' , 'author', 'year']]\n",
    "    \n",
    "    return citations_df\n",
    "\n",
    "# Using the function to get a->b standardized data for the citations networks below\n",
    "citations_df_2022_2023 = get_citations_df(list_references_standardized, 2022, 2023)\n",
    "citations_df_2018_2021 = get_citations_df(list_references_standardized, 2018, 2021)\n",
    "citations_df_2013_2017 = get_citations_df(list_references_standardized, 2013, 2017)\n",
    "citations_df_before_2013 = get_citations_df(list_references_standardized, 0, 2012)\n",
    "citations_df_overall = get_citations_df(list_references_standardized)  #No filter on years: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7528e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_values(df, groupby_column, value_column):\n",
    "    \"\"\"\n",
    "    Standardize the values of the specified column based on the most frequent non-empty value and fewest characters \n",
    "    within each group.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - groupby_column: The column by which we group data.\n",
    "    - value_column: The column whose values we want to standardize based on the rules.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with standardized values.\n",
    "    \"\"\"\n",
    "    \n",
    "    def custom_mode(series):\n",
    "        # Remove NA values and other representations of NA\n",
    "        series = series.dropna()\n",
    "        series = series[~series.isin(['', 'NA'])]\n",
    "        \n",
    "        # If all values were NA or empty\n",
    "        if series.empty:\n",
    "            return np.nan  # Using numpy's nan for consistency\n",
    "\n",
    "        # Get value counts\n",
    "        counts = series.value_counts()\n",
    "\n",
    "        # If there's a single most common value, return it\n",
    "        if len(counts) == 1 or counts.iloc[0] != counts.iloc[1]:\n",
    "            return counts.idxmax()\n",
    "\n",
    "        # If multiple values have the same max count, apply further rules\n",
    "        top_values = counts[counts == counts.iloc[0]].index.tolist()\n",
    "\n",
    "        # Sort by fewest characters\n",
    "        sorted_by_chars = sorted(top_values, key=lambda x: len(x))\n",
    "\n",
    "        # If there's a single value with the fewest characters, return it\n",
    "        if len(sorted_by_chars) == 1 or len(sorted_by_chars[0]) != len(sorted_by_chars[1]):\n",
    "            return sorted_by_chars[0]\n",
    "\n",
    "        # If the column is not the author's name, apply the uppercase letter rule.\n",
    "        if value_column != \"author_name\":  # adjust \"author_name\" to the correct column name if necessary\n",
    "            return sorted(sorted_by_chars, key=lambda x: sum(1 for c in x if c.isupper()), reverse=True)[0]\n",
    "        else:\n",
    "            return sorted_by_chars[0]\n",
    "\n",
    "    # Find the most common value for each group based on the custom mode\n",
    "    most_common_value = df.groupby(groupby_column)[value_column].apply(custom_mode).to_dict()\n",
    "\n",
    "    # Map the most common values to the dataframe based on the group\n",
    "    df[value_column] = df[groupby_column].map(most_common_value)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "list_references_standardized = standardize_values(list_references, 'scopus_id', 'title')\n",
    "list_references_standardized = standardize_values(list_references_standardized, 'scopus_id', 'sourcetitle')\n",
    "list_references_standardized = standardize_values(list_references_standardized, 'scopus_id', 'author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4bce5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_citations_df(df, start_year=None, end_year=None):\n",
    "    \"\"\"\n",
    "    Filter and extract necessary columns for citation network from a DataFrame based on a range of years.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data\n",
    "    - start_year: Optional, the starting year for filtering\n",
    "    - end_year: Optional, the ending year for filtering\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with filtered data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Replace 'NA' with numpy.nan and reassign the DataFrame\n",
    "    df = df.replace({'year': 'NA'}, np.nan)\n",
    "    \n",
    "    # Drop rows where 'year' is NaN\n",
    "    df = df.dropna(subset=['year'])\n",
    "    \n",
    "    # Convert the 'year' column to integer using .astype\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    \n",
    "    # Filter the data based on the 'year' column only if start_year and end_year are provided\n",
    "    if start_year is not None and end_year is not None:\n",
    "        df = df[df['year'].between(start_year, end_year)]\n",
    "    \n",
    "    # Extract necessary columns for the citation network\n",
    "    citations_df = df[['citing_art', 'scopus_id', 'sourcetitle', 'title', 'citedby_count', 'citations_per_year' , 'author', 'year']]\n",
    "    \n",
    "    return citations_df\n",
    "\n",
    "# Using the function to get a->b standardized data for the citations networks below\n",
    "citations_df_2022_2023 = get_citations_df(list_references_standardized, 2022, 2023)\n",
    "citations_df_2018_2021 = get_citations_df(list_references_standardized, 2018, 2021)\n",
    "citations_df_2013_2017 = get_citations_df(list_references_standardized, 2013, 2017)\n",
    "citations_df_before_2013 = get_citations_df(list_references_standardized, 0, 2012)\n",
    "citations_df_overall = get_citations_df(list_references_standardized)  #No filter on years: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71ba97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_references_dict(df, key, column):\n",
    "    \"\"\"\n",
    "    Create a dictionary with keys from the specified key_column and values from the specified value_column.\n",
    "\n",
    "    :param df: Input DataFrame.\n",
    "    :param key_column: Column name to be used as keys in the resulting dictionary.\n",
    "    :param value_column: Column name to be used as values in the resulting dictionary.\n",
    "    :return: Dictionary with keys from key_column and values from value_column.\n",
    "    \"\"\"\n",
    "    if key not in df.columns or column not in df.columns:\n",
    "        raise ValueError(\"The required columns are not present in the DataFrame.\")\n",
    "    return sort_dict(df.set_index(key)[column].to_dict())\n",
    "  \n",
    "\n",
    "# We also need to get the info of the citing articles, otherwise we won't get any info when we click \n",
    "# on the nodes and we will have the number of the node as node label instead of the author name\n",
    "# Create the 'citing_art' column by stripping the first 10 characters from 'dc_identifier'\n",
    "data['citing_art'] = data['dc_identifier'].str[10:]\n",
    "\n",
    "# Getting the current year\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# English Comment: Function to calculate citations per year, handles NaN values, division by zero, and the current year.\n",
    "def calculate_citations_per_year(row):\n",
    "    if pd.isna(row['year']):\n",
    "        return np.nan\n",
    "    elif (current_year - row['year']) == 0:\n",
    "        return 0  # Handle division by zero by returning 0\n",
    "    else:\n",
    "        return round(row['citedby_count'] / (current_year - row['year']), 2)\n",
    "\n",
    "# Creating the new column 'citations_per_year'\n",
    "data['citations_per_year'] = data.apply(calculate_citations_per_year, axis=1)\n",
    "\n",
    "# List of columns to use in the networks later as attributes. We can add more columns if we want to.\n",
    "columns_to_extract = ['title', 'sourcetitle', 'citedby_count', 'author', 'year', 'citations_per_year']\n",
    "\n",
    "# Dictionary of dataframes with their respective names\n",
    "dfs = {\n",
    "    \"2022_2023\": citations_df_2022_2023,\n",
    "    \"2018_2021\": citations_df_2018_2021,\n",
    "    \"2013_2017\": citations_df_2013_2017,\n",
    "    \"before_2013\": citations_df_before_2013,\n",
    "    \"overall\": citations_df_overall\n",
    "}\n",
    "\n",
    "\n",
    "# Map old column names to new column names\n",
    "column_mapping = {\n",
    "    'title': 'dc_title',\n",
    "    'sourcetitle': 'prism_publicationName',\n",
    "    'author': 'dc_creator',\n",
    "    'year': 'year',\n",
    "    'citations': 'citedby_count',\n",
    "    'citations_per_year': 'citations_per_year'\n",
    "}\n",
    "\n",
    "# Reverse mapping for merging\n",
    "reverse_column_mapping = {v: k for k, v in column_mapping.items()}\n",
    "\n",
    "# Rename columns in data DataFrame for merging\n",
    "data.rename(columns=reverse_column_mapping, inplace=True)\n",
    "\n",
    "\n",
    "# Initialize the output dictionary\n",
    "dict_references = {}\n",
    "\n",
    "# Retrieve the information for each period and each column\n",
    "for period, df in dfs.items():\n",
    "    dict_references[period] = {}\n",
    "    for column in columns_to_extract:\n",
    "        # This check is important in case all columns are not present across all dataframes\n",
    "        if column in df.columns:\n",
    "            dict_references[period][column] = get_info_references_dict(df, 'scopus_id', column)\n",
    "\n",
    "    # Get the citing_art dictionary from 'data' DataFrame\n",
    "    for column in columns_to_extract:\n",
    "        if column in data.columns:\n",
    "            citing_art_dict = get_info_references_dict(data, 'citing_art', column)\n",
    "            \n",
    "            # Add to dict_references only if key is not already present \n",
    "            # It means that the article in our data has been cited by others and is then already present in the references dataframe\n",
    "            for key, value in citing_art_dict.items():\n",
    "                if key not in dict_references[period].get(column, {}):\n",
    "                    dict_references[period].setdefault(column, {})[key] = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fb80c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma_graph_references(dataframe, period_label):\n",
    "        \n",
    "    # Create a graph from the given dataframe\n",
    "    G = nx.from_pandas_edgelist(dataframe, 'citing_art', 'scopus_id', create_using=nx.DiGraph())\n",
    "    \n",
    "    # Fetch attributes for the given period from the global dict_references\n",
    "    attributes_dict = dict_references.get(period_label, {})\n",
    "\n",
    "    # Set the attributes from dict_references to the nodes of the graph\n",
    "    for attribute, attribute_dict in attributes_dict.items():\n",
    "        nx.set_node_attributes(G, attribute_dict, name=attribute)\n",
    "\n",
    "    # Set edge colors for visualization\n",
    "    for u, v in G.edges:\n",
    "        G[u][v][\"color\"] = \"#7D7C7C\"\n",
    "\n",
    "    # Calculate the degree of each node\n",
    "    node_degree = dict(G.degree)\n",
    "\n",
    "    # Compute multiple centrality metrics for nodes\n",
    "    node_degree_centrality = nx.degree_centrality(G)\n",
    "    node_degree_betweenness = nx.betweenness_centrality(G)\n",
    "    node_degree_closeness = nx.closeness_centrality(G)\n",
    "    node_degree_eigenvector = nx.closeness_centrality(G)\n",
    "    #node_degree_constraint_weighted = nx.constraint(G, weight=\"value\")\n",
    "    node_degree_constraint_unweighted = nx.constraint(G)\n",
    "    \n",
    "    # Set node attributes for various metrics\n",
    "    nx.set_node_attributes(G, node_degree_centrality, 'centrality')\n",
    "    nx.set_node_attributes(G, node_degree_betweenness, 'betweenness')\n",
    "    nx.set_node_attributes(G, node_degree_closeness, 'closeness')\n",
    "    nx.set_node_attributes(G, node_degree_eigenvector, 'eigenvector centrality')\n",
    "    #nx.set_node_attributes(G, node_degree_constraint_weighted, 'burt\\'s constraint weighted')\n",
    "    nx.set_node_attributes(G, node_degree_constraint_unweighted, 'burt constraint unweighted')\n",
    "    \n",
    "    # Set node attributes based on the selected 'year_period'\n",
    "    \n",
    "\n",
    "    # Construct the sigma graph and customize visualization\n",
    "    Sigma.write_html(G,\n",
    "                 default_edge_type      = \"arrow\",                                                # Set default edge type\n",
    "                 fullscreen             = True,                                                   # Display in fullscreen mode\n",
    "                 label_density          = 2,                                                      # Increase this to have more labels appear\n",
    "                 label_font             = \"Helvetica Neue\",                                       # Set label font\n",
    "                 max_categorical_colors = 30,                                                     # Max categorical colors for communities\n",
    "                 node_border_color_from = 'node',                                                 # Set node border color from 'node' attribute\n",
    "                 node_color             = \"community\",                                            # Set node colors\n",
    "                 node_label             = \"author\",                                               # Set node label from 'author' attribute\n",
    "                 node_label_size        = G.in_degree,                                            # Set node label size\n",
    "                 node_label_size_range  = (12, 36),                                               # Set node label size range\n",
    "                 node_metrics           = {\"community\": {\"name\": \"louvain\", \"resolution\": 1}},    # Specify node metrics\n",
    "                 node_size              = G.in_degree,                                            # Set node size based on the in_degree attribute\n",
    "                 node_size_range        = (3, 30),                                                # Set node size range\n",
    "                 path                   = f\"networks/references/{period_label}_sigma.html\",       # Specify the output file path\n",
    "                 start_layout           = 10                                                       # Start the layout algorithm automatically and lasts 5 seconds\n",
    "                 #node_border_color     = \"black\",                                                # Set node border color\n",
    "                 #edge_color            = \"source\",                                               # Set edge color from 'source' attribute\n",
    "                 )\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3aa4f1dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type builtin_function_or_method is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m G_2022_2023_references \u001b[38;5;241m=\u001b[39m sigma_graph_references(citations_df_2022_2023, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2022_2023\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[92], line 40\u001b[0m, in \u001b[0;36msigma_graph_references\u001b[1;34m(dataframe, period_label)\u001b[0m\n\u001b[0;32m     34\u001b[0m nx\u001b[38;5;241m.\u001b[39mset_node_attributes(G, node_degree_constraint_unweighted, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mburt constraint unweighted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Set node attributes based on the selected 'year_period'\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Construct the sigma graph and customize visualization\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m Sigma\u001b[38;5;241m.\u001b[39mwrite_html(G,\n\u001b[0;32m     41\u001b[0m              default_edge_type      \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m,                                                \u001b[38;5;66;03m# Set default edge type\u001b[39;00m\n\u001b[0;32m     42\u001b[0m              fullscreen             \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,                                                   \u001b[38;5;66;03m# Display in fullscreen mode\u001b[39;00m\n\u001b[0;32m     43\u001b[0m              label_density          \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,                                                      \u001b[38;5;66;03m# Increase this to have more labels appear\u001b[39;00m\n\u001b[0;32m     44\u001b[0m              label_font             \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHelvetica Neue\u001b[39m\u001b[38;5;124m\"\u001b[39m,                                       \u001b[38;5;66;03m# Set label font\u001b[39;00m\n\u001b[0;32m     45\u001b[0m              max_categorical_colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m,                                                     \u001b[38;5;66;03m# Max categorical colors for communities\u001b[39;00m\n\u001b[0;32m     46\u001b[0m              node_border_color_from \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m'\u001b[39m,                                                 \u001b[38;5;66;03m# Set node border color from 'node' attribute\u001b[39;00m\n\u001b[0;32m     47\u001b[0m              node_color             \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunity\u001b[39m\u001b[38;5;124m\"\u001b[39m,                                            \u001b[38;5;66;03m# Set node colors\u001b[39;00m\n\u001b[0;32m     48\u001b[0m              node_label             \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m,                                               \u001b[38;5;66;03m# Set node label from 'author' attribute\u001b[39;00m\n\u001b[0;32m     49\u001b[0m              node_label_size        \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39min_degree,                                            \u001b[38;5;66;03m# Set node label size\u001b[39;00m\n\u001b[0;32m     50\u001b[0m              node_label_size_range  \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m36\u001b[39m),                                               \u001b[38;5;66;03m# Set node label size range\u001b[39;00m\n\u001b[0;32m     51\u001b[0m              node_metrics           \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunity\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlouvain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresolution\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}},    \u001b[38;5;66;03m# Specify node metrics\u001b[39;00m\n\u001b[0;32m     52\u001b[0m              node_size              \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39min_degree,                                            \u001b[38;5;66;03m# Set node size based on the in_degree attribute\u001b[39;00m\n\u001b[0;32m     53\u001b[0m              node_size_range        \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m30\u001b[39m),                                                \u001b[38;5;66;03m# Set node size range\u001b[39;00m\n\u001b[0;32m     54\u001b[0m              path                   \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworks/references/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiod_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_sigma.html\u001b[39m\u001b[38;5;124m\"\u001b[39m,       \u001b[38;5;66;03m# Specify the output file path\u001b[39;00m\n\u001b[0;32m     55\u001b[0m              start_layout           \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m                                                       \u001b[38;5;66;03m# Start the layout algorithm automatically and lasts 5 seconds\u001b[39;00m\n\u001b[0;32m     56\u001b[0m              \u001b[38;5;66;03m#node_border_color     = \"black\",                                                # Set node border color\u001b[39;00m\n\u001b[0;32m     57\u001b[0m              \u001b[38;5;66;03m#edge_color            = \"source\",                                               # Set edge color from 'source' attribute\u001b[39;00m\n\u001b[0;32m     58\u001b[0m              )\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m G\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipysigma\\sigma.py:1143\u001b[0m, in \u001b[0;36mSigma.write_html\u001b[1;34m(cls, graph, path, fullscreen, **kwargs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_height\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalc(100vh - 16px)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(graph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mto_html(path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipysigma\\sigma.py:1133\u001b[0m, in \u001b[0;36mSigma.to_html\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1130\u001b[0m current_snapshot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msnapshot\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msnapshot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m embed_minimal_html(path, views\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m])\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msnapshot \u001b[38;5;241m=\u001b[39m current_snapshot\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipywidgets\\embed.py:302\u001b[0m, in \u001b[0;36membed_minimal_html\u001b[1;34m(fp, views, title, template, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;129m@doc_subst\u001b[39m(_doc_snippets)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_minimal_html\u001b[39m(fp, views, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIPyWidget export\u001b[39m\u001b[38;5;124m'\u001b[39m, template\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a minimal HTML file with widget views embedded.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124;03m    {embed_kwargs}\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     snippet \u001b[38;5;241m=\u001b[39m embed_snippet(views, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    304\u001b[0m     values \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: title,\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnippet\u001b[39m\u001b[38;5;124m'\u001b[39m: snippet,\n\u001b[0;32m    307\u001b[0m     }\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m template \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipywidgets\\embed.py:279\u001b[0m, in \u001b[0;36membed_snippet\u001b[1;34m(views, drop_defaults, state, indent, embed_url, requirejs, cors)\u001b[0m\n\u001b[0;32m    274\u001b[0m load \u001b[38;5;241m=\u001b[39m load_requirejs_template \u001b[38;5;28;01mif\u001b[39;00m requirejs \u001b[38;5;28;01melse\u001b[39;00m load_template\n\u001b[0;32m    276\u001b[0m use_cors \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m crossorigin=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manonymous\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cors \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    277\u001b[0m values \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m: load\u001b[38;5;241m.\u001b[39mformat(embed_url\u001b[38;5;241m=\u001b[39membed_url, use_cors\u001b[38;5;241m=\u001b[39muse_cors),\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson_data\u001b[39m\u001b[38;5;124m'\u001b[39m: escape_script(json\u001b[38;5;241m.\u001b[39mdumps(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanager_state\u001b[39m\u001b[38;5;124m'\u001b[39m], indent\u001b[38;5;241m=\u001b[39mindent)),\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidget_views\u001b[39m\u001b[38;5;124m'\u001b[39m: widget_views,\n\u001b[0;32m    281\u001b[0m }\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m snippet_template\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalues)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    235\u001b[0m     skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    236\u001b[0m     check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    237\u001b[0m     separators\u001b[38;5;241m=\u001b[39mseparators, default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys,\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39mencode(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\encoder.py:202\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m--> 202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: _make_iterencode.<locals>._iterencode_dict at line 406 (2 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m _default(o)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type builtin_function_or_method is not JSON serializable"
     ]
    }
   ],
   "source": [
    "G_2022_2023_references = sigma_graph_references(citations_df_2022_2023, \"2022_2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "830f312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43846c91027406587cff7688557c7ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Sigma(nx.DiGraph with 526 nodes and 469 edges), Sigma(nx.DiGraph with 526 nodes …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SigmaGrid(G_2022_2023_references,\n",
    "    views=[{'node_size': G_2022_2023_references.in_degree}, {'node_size': \"centrality\"}],\n",
    "    #path=\"networks/references/2022_2023_sigma_grid.html\"\n",
    "    default_edge_type      = \"arrow\",                                                # Set default edge type                                                  # Display in fullscreen mode\n",
    "                 label_density          = 1,                                                      # Increase this to have more labels appear\n",
    "                 label_font             = \"Helvetica Neue\",                                       # Set label font\n",
    "                 max_categorical_colors = 30,                                                     # Max categorical colors for communities\n",
    "                 node_border_color_from = 'node',                                                 # Set node border color from 'node' attribute\n",
    "                 node_color             = \"community\",                                            # Set node colors\n",
    "                 node_label             = \"author\",                                               # Set node label from 'author' attribute                                         # Set node label size\n",
    "                 node_label_size_range  = (12, 36),                                               # Set node label size range\n",
    "                 node_metrics           = {\"community\": {\"name\": \"louvain\", \"resolution\": 1}},    # Specify node metrics                                        # Set node size based on the in_degree attribute\n",
    "                 node_size_range        = (3, 30),                                                # Set node size range\n",
    "                 #path                   = \"networks/references/2022_2023_sigma_grid.html\",       # Specify the output file path\n",
    "                 start_layout           = 10                                                       # Start the layout algorithm automatically and lasts 5 seconds\n",
    "                 #node_border_color     = \"black\",                                                # Set node border color\n",
    "                 #edge_color            = \"source\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac35748e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd294c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
